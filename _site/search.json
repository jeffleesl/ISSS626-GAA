[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "Welcome to ISSS626 Geospatial Analytics and Applications. In this website, you will find my coursework prepared for this course.\nMy name is Lee Shao Lin or you can call me Jeffrey.\nI enjoyed learning and Learning is a sure path to Happiness."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "LinkedIn\n\n\nI am passionate about data science and financial crime surveillance."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1.1 :Geospatial Data Wrangling with R",
    "section": "",
    "text": "Overview\nGetting Started\nInstall and launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "",
    "text": "This hands-on exercise covers 1 Geospatial Data Science with R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "1. Install and launching R packages",
    "text": "1. Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "2.1 Importing Geospatial Data",
    "text": "2.1 Importing Geospatial Data\nData are key to data analytics including geospatial analytics. Hence, before analysing, I need to assemble the necessary data. In this hands-on exercise, I am required to extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\n\n\n2.1.1 Importing polygon feature data in shapefile format - Master Plan 2014 Subzone Boundary (Web)\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n2.1.2 Importing polyline feature data in shapefile form - Cycling Path\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                        layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n2.1.3 Importing GIS data in kml format - Pre-Schools Location\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "3 Checking the Content of A Simple Feature Data Frame",
    "text": "3 Checking the Content of A Simple Feature Data Frame\nIn this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n3.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n3.2 Working with glimpse()\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time I will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n3.3 Working with head()\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThe result returns the first 5 objects by default, but the number of objects can be adjusted by specifying a value for n."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "4 Plotting the Geospatial Data",
    "text": "4 Plotting the Geospatial Data\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time I will find plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#working-with-projection",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "5 Working with Projection",
    "text": "5 Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, I will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n5.1 Assigning EPSG code to a simple feature data frame\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414. (The common issue I saw in my industry is that some analyst didn’t identify this issue and they don’t even know the correct code).\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n5.2 Transforming the projection of preschool from wgs84 to svy21.\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)\n\n\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)\n\n\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\n#6 Importing and Converting An Aspatial Data\nIn this hands-on exercise, I am required to extract the necessary data sets from the following sources:\n\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\n\n6.1 Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\n6.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "7 Geoprocessing with sf package",
    "text": "7 Geoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n7.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nMission Accomplished!\n\n\n7.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nWarning: You should not confuse with st_intersection().\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe solution:\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.1.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1.1 : Geospatial Data Wrangling with R",
    "section": "8. Exploratory Data Analysis (EDA)",
    "text": "8. Exploratory Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nThe solution: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "",
    "text": "LinkedIn\n\n\nI am passionate about data science and financial crime surveillance…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "",
    "text": "This hands-on exercise covers 2 Thematic Mapping and GeoVisualisation with R.\nIn general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few of them.\nGeovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible, enabling human’s most powerful information-processing abilities – those of spatial cognition associated with our eye–brain vision system – to be directly brought to bear.\nIn this chapter, I will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#install-and-launching-r-packages",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "Install and launching R packages",
    "text": "Install and launching R packages\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#the-data",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "2.1 The Data",
    "text": "2.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#importing-geospatial-data-into-r",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "2.2 Importing Geospatial Data into R",
    "text": "2.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n              layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\nIn R, data structures like data frames and sf objects have default print methods that limit the number of rows displayed. This is particularly useful when working with large datasets, as displaying the entire dataset can be overwhelming and impractical."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#importing-attribute-data-into-r",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "2.3 Importing Attribute Data into R",
    "text": "2.3 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\", show_col_types = FALSE)\n\nLook at the data\n\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   &lt;chr&gt; \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  &lt;chr&gt; \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  &lt;chr&gt; \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  &lt;dbl&gt; 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time &lt;dbl&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#data-preparation",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "2.4 Data Preparation",
    "text": "2.4 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.4.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n2.4.1.1 Mutate function\nMutate() is a function in R that creates new columns that are functions of existing variable. It can also modify or delete columns by using the same or NULL as the value.To use mutate(), you need to specify the dataframe and the name-value pair for the new column. For example, mutate(data, z = x + y) will create a new column z that is the sum of x and y in the data dataframe.\n\n\n\n2.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\nThing to learn from the code chunk above:\nR also has two native data formats—Rdata (sometimes shortened to RDA) and RDS. These formats are used when R objects are saved for later use. Rdata is used to save multiple R objects, while RDS is used to save a single R object. Find out more more about RDS."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "3.1 Plotting a choropleth map quickly by using qtm()",
    "text": "3.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "3.2 Creating a choropleth map by using tmap’s elements",
    "text": "3.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n3.2.1 Base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n3.2.2 Choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\n3.2.3 Choropleth map using tm_fill() and tm_border()\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#data-classification-methods-of-tmap",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "3.3 Data classification methods of tmap",
    "text": "3.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n3.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nDivides data into equal-sized groups based on quantiles.\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nDivides the range of data into equal intervals.\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\nUsing what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n3.3.1.1 Jenks\nUses Jenks natural breaks optimization to find the best classification.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n3.3.1.2 Standard Deviation\nClassifies data based on standard deviation from the mean.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n3.3.1.3 Pretty\nRounds breaks to nice numbers.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nPreparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw\n\n3.3.1.4 Two Classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n3.3.1.5 Six Classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n3.3.1.6 Ten Classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n3.3.1.7 Twenty Classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen the number of classes increases, not all dependencies are applied. Therefore, even with just 2 classes, different clusters can be illustrated.\n\n\n\n3.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#colour-scheme",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "3.4 Colour Scheme",
    "text": "3.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n3.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#map-layouts",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "3.5 Map Layouts",
    "text": "3.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n3.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n3.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n3.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "3.6 Drawing Small Multiple Choropleth Maps",
    "text": "3.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n3.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n3.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n3.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#mappping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex1.2.html#mappping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-On Exercise 1.2 : Choropleth Mapping with R",
    "section": "3.7 Mappping Spatial Object Meeting a Selection Criterion",
    "text": "3.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-code",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-code",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data",
    "title": "In-class Exercise 1",
    "section": "Working with Master Plan Planning Sub-zone Data",
    "text": "Working with Master Plan Planning Sub-zone Data\n\nThis code chunk imports shapefile.\n\nmpsz14_shp &lt;- st_read(dsn = \"data/\",\n                      layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nThis code chunk imports kml file.\n\n# mpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\"\n\nHowever, the above file is corrupted. The below method could convert shapefil to kml file.\n\nst_write(mpsz14_shp,\n        \"data/MP14_SUBZONE_WEB_PL.kml\",\n        delete_dsn = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#importing-data",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Importing data",
    "text": "4.1 Importing data\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", \n                 layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore analyzing the data, it’s crucial to ensure that all datasets are projected using the same coordinate reference system (CRS). Note that both mpsz_sf and sg_sf lack proper CRS information, unlike childcare_sf\n\nsg_sf &lt;- st_read(dsn = \"data\", \n                 layer=\"CostalOutline\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 Mapping the geospatial data sets",
    "text": "4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\nPlot a map to show their spatial patterns\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nChildcare Centres\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\nURA 2014 Master Plan Planning Subzone boundary data\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\nNational Boundary of Singapore\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Converting the Spatial* class into generic sp format",
    "text": "5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nDo you know what are the differences between Spatial* classes and generic sp object?\nEach Spatial class has a predefined structure, such as SpatialPoints, SpatialLines, SpatialPolygons, etc. This structure determines the type of geometric features represented (points, lines, polygons). Whereas,the sp object is a more generic representation of spatial data, capable of holding any type of geometric feature (points, lines, polygons). More details here."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#handling-duplicated-points",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Handling duplicated points",
    "text": "5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nDo you know how to spot the duplicate points from the map shown above?\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck if any duplicated point in this geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#creating-owin-object",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Creating owin object",
    "text": "5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.6 Combining point events object and owin object",
    "text": "5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlot the newly derived childcareSG_ppp as shown below.\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#kernel-density-estimation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#kernel-density-estimation",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.1 Kernel Density Estimation",
    "text": "6.1 Kernel Density Estimation\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n6.1.1 Computing kernel density estimation using automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n6.1.2 Rescalling KDE values\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#working-with-different-automatic-badwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#working-with-different-automatic-badwidth-methods",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.2 Working with different automatic badwidth methods",
    "text": "6.2 Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#working-with-different-kernel-methods",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.3 Working with different kernel methods",
    "text": "6.3 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.1 Computing KDE by using fixed bandwidth",
    "text": "7.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.2 Computing KDE by using adaptive bandwidth",
    "text": "7.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-kde-output-into-grid-object.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#converting-kde-output-into-grid-object.",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.3 Converting KDE output into grid object.",
    "text": "7.3 Converting KDE output into grid object.\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\n# gridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\n# spplot(gridded_kde_childcareSG_bw)\n\nThe above code doesn’t work and I have changed to the below code:\n\nraster_kde_childcareSG_bw &lt;- raster(kde_childcareSG.bw)\ngridded_kde_childcareSG_bw &lt;- as(raster_kde_childcareSG_bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n7.3.1 Converting gridded output into raster\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\n\n\n7.3.2 Assigning projection systems\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is completed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#visualising-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#visualising-the-output-in-tmap",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.4 Visualising the output in tmap",
    "text": "7.4 Visualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.5 Comparing Spatial Point Patterns using KDE",
    "text": "7.5 Comparing Spatial Point Patterns using KDE\nIn this section, you will learn how to compare KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n7.5.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 Creating owin object\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n7.5.3 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n7.5.4 Computing KDE\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n7.5.5 Computing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "8.1 Testing spatial point patterns using Clark and Evans Test",
    "text": "8.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nWhat conclusion can you draw from the test result?\nThe test result indicates a significant clustering of childcare centers in Singapore.\nR value: 0.55631 This value is significantly different from 0, suggesting a deviation from randomness. A higher R value indicates a stronger degree of clustering.\np-value: &lt; 2.2e-16 This extremely small p-value provides strong evidence against the null hypothesis of complete randomness. It indicates that the observed clustering is highly unlikely to be due to chance.\nBased on the test results, it can be concluded that the distribution of childcare centers in Singapore exhibits a significant degree of clustering. This suggests that there are factors influencing the location of childcare centers, such as population density, accessibility, or existing infrastructure."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "8.2 Clark and Evans Test: Choa Chu Kang planning area",
    "text": "8.2 Clark and Evans Test: Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.93251, p-value = 0.3133\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#clark-and-evans-test-tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.1.html#clark-and-evans-test-tampines-planning-area",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "8.3 Clark and Evans Test: Tampines planning area",
    "text": "8.3 Clark and Evans Test: Tampines planning area\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.7795, p-value = 6.905e-05\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#importing-the-spatial-data",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Importing the spatial data",
    "text": "4.1 Importing the spatial data\nIn this section, st_read() of sf package will be used to import these three geospatial data sets into R.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system. undefined\n\nsg_sf &lt;- st_read(dsn = \"data\", \n                 layer=\"CostalOutline\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 Mapping the geospatial data sets",
    "text": "4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\n\ntmap mode set to plotting\n\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#converting-from-sf-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#converting-from-sf-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Converting from sf format into spatstat’s ppp format",
    "text": "5.1 Converting from sf format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#handling-duplicated-points",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Handling duplicated points",
    "text": "5.2 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck if any duplicated point in this geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#creating-owin-object",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Creating owin object",
    "text": "5.3 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Combining point events object and owin object",
    "text": "5.4 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlot the newly derived childcareSG_ppp as shown below\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n5.4.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n5.4.2 Converting sf objects into owin objects\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n5.4.3 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "7.1 Choa Chu Kang planning area",
    "text": "7.1 Choa Chu Kang planning area\n\n7.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n7.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "7.2 Tampines planning area",
    "text": "7.2 Tampines planning area\n\n7.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n7.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area-1",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "8.1 Choa Chu Kang planning area",
    "text": "8.1 Choa Chu Kang planning area\n\n8.1.1 Computing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#performing-complete-spatial-randomness-test-2",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#performing-complete-spatial-randomness-test-2",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "8.2 Performing Complete Spatial Randomness Test",
    "text": "8.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area-1",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "8.3 Tampines planning area",
    "text": "8.3 Tampines planning area\n\n8.3.1 Computing F-function estimation\nMonte Carlo test with F-fucntion\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n8.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area-2",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "9.1 Choa Chu Kang planning area",
    "text": "9.1 Choa Chu Kang planning area\n\n9.1.1 Computing K-fucntion estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area-2",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "9.2 Tampines planning area",
    "text": "9.2 Tampines planning area\n\n9.2.1 Computing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#choa-chu-kang-planning-area-3",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "10.1 Choa Chu Kang planning area",
    "text": "10.1 Choa Chu Kang planning area\n\n10.1.1 Computing L Function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n10.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex2.2.html#tampines-planning-area-3",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "10.2 Tampines planning area",
    "text": "10.2 Tampines planning area\n\n10.2.1 Computing L-fucntion estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\nThen, plot the model output by using the code chun below.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "",
    "text": "Thailand’s roads are the deadliest in Southeast Asia and among the worst in the world, according to the World Health Organisation. About 20,000 people die in road accidents each year, or about 56 deaths a day (WHO).\nBetween 2014 and 2021, Thailand experienced a notable increase in accident frequencies. Specifically, 19% of all accidents in Thailand occurred on the national highways, which constituted the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network. Within the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed ‘black spots,’ distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes, respectively."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "maptools is retired and binary is removed from CRAN. However, I can download from Posit Public Package Manager snapshots by using the code chunk below.\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nAfter the installation is completed, it is important to edit the code chunk as shown below in order to avoid maptools being download and install repetitively every time the Quarto document been rendered."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issue-1-installing-maptools",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#issue-1-installing-maptools",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "install.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", \n                 layer=\"CostalOutline\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nIn order to ensure reproducibility, it is important to include the code chunk below before use\n\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html",
    "title": "Hands on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, I am going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network kernel density estimation (NKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html#preparing-the-lixels-objects",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html#preparing-the-lixels-objects",
    "title": "Hands on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.1 Preparing the lixels objects",
    "text": "6.1 Preparing the lixels objects\nBefore computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network3414, \n                         700, \n                         mindist = 375)\n\nWhat I learnt from the code chunk above:\n\nThe length of a lixel, lx_length is set to 700m, and\nThe minimum length of a lixel, mindist is set to 350m.\n\nAfter cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified\nNote: There is another function called lixelize_lines.mc() which provide multicore support."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html#generating-line-centre-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html#generating-line-centre-points",
    "title": "Hands on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.2 Generating line centre points",
    "text": "6.2 Generating line centre points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) \n\nThe points are located at center of the line based on the length of the line. This changes the geometry from linestring to point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html#performing-nkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex3.html#performing-nkde",
    "title": "Hands on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.3 Performing NKDE",
    "text": "6.3 Performing NKDE\nReady to computer the NKDE by using the code chunk below.\n\nchildcare3414 &lt;- st_zm(childcare3414)\n\n\ndensities &lt;- nkde(network3414, \n                  events = childcare3414,\n                  w = rep(1, nrow(childcare3414)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nWhat can we learn from the code chunk above?\n\nkernel_name argument indicates that quartic kernel is used. Are possible kernel methods supported by spNetwork are: triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform.\nmethod argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are:\n\nmethod=“simple”. This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.\nmethod=“discontinuous”. The method is proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels.\nmethod=“continuous”. If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divide the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\n\nThe user guide of spNetwork package provide a comprehensive discussion of nkde().\n\n6.3.1 Visualising NKDE\nBefore we can visualise the NKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nThe interactive map above effectively reveals road segments (darker color) with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres (lighter color)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-owin-object-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-owin-object-from-sf-data.frame",
    "title": "In-class Exercise 2",
    "section": "Creating owin object from sf data.frame",
    "text": "Creating owin object from sf data.frame\n\nPlotSummary\n\n\nIn the code chunk as.owin() of spatstat.geom is used to create an owin object class from polygon sf tibble data.frame.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\nNext, summary() function is used to display the summary information of the owin object class.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-Class Exercise 3",
    "section": "",
    "text": "spNetwork, which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, processing, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nUse the code chunk below to install and launch the four R packages.\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#preparing-the-lixels-objects",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#preparing-the-lixels-objects",
    "title": "In-Class Exercise 3",
    "section": "6.1 Preparing the lixels objects",
    "text": "6.1 Preparing the lixels objects\nBefore computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network3414, \n                         700, \n                         mindist = 350)\n\nWhat I learnt from the code chunk above:\n\nThe length of a lixel, lx_length is set to 700m, and\nThe minimum length of a lixel, mindist is set to 350m.\n\nAfter cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified\nNote: There is another function called lixelize_lines.mc() which provide multicore support."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#generating-line-centre-points",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#generating-line-centre-points",
    "title": "In-Class Exercise 3",
    "section": "6.2 Generating line centre points",
    "text": "6.2 Generating line centre points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) \n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) + \n  tm_lines() + \n  tm_shape(samples) +\n  tm_dots(size = 0.01)\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nThe points are located at center of the line based on the length of the line. This changes the geometry from linestring to point."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#performing-nkde",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#performing-nkde",
    "title": "In-Class Exercise 3",
    "section": "6.3 Performing NKDE",
    "text": "6.3 Performing NKDE\nReady to computer the NKDE by using the code chunk below.\n\nchildcare3414 &lt;- st_zm(childcare3414)\n\n\ndensities &lt;- nkde(network3414, \n                  events = childcare3414,\n                  w = rep(1, nrow(childcare3414)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nWhat can we learn from the code chunk above?\n\nkernel_name argument indicates that quartic kernel is used. Are possible kernel methods supported by spNetwork are: triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform.\nmethod argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are:\n\nmethod=“simple”. This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.\nmethod=“discontinuous”. The method is proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels.\nmethod=“continuous”. If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divide the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\n\nThe user guide of spNetwork package provide a comprehensive discussion of nkde().\n\n6.3.1 Visualising NKDE\nBefore we can visualise the NKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\ntmap_mode('plot')\n\nThe interactive map above effectively reveals road segments (darker color) with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres (lighter color)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, I will learn how to compute spatial weights using R. By the end to this hands-on exercise, I will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#getting-started",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "2.1 Getting Started",
    "text": "2.1 Getting Started\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "3.1 Import shapefile into r environment",
    "text": "3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "3.2 Import csv file into r environment",
    "text": "3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#performing-relational-join",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "3.3 Performing relational join",
    "text": "3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#computing-queen-contiguity-based-neighbours",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "5.1 Computing (QUEEN) contiguity based neighbours",
    "text": "5.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#creating-rook-contiguity-based-neighbours",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "5.2 Creating (ROOK) contiguity based neighbours",
    "text": "5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "5.3 Visualising contiguity weights",
    "text": "5.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n5.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n5.3.3 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#determine-the-cut-off-distance",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.1 Determine the cut-off distance",
    "text": "6.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.2 Computing fixed distance weight matrix",
    "text": "6.2 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nIt refers to the average number of neighboring points (or spatial units) that each point has within the specified distance threshold, which is 62 units in this case. The function dnearneigh identifies neighbors based on a minimum and maximum distance, and the result shows the spatial relationships between the points.\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n6.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.3 Computing adaptive distance weight matrix",
    "text": "6.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotice that each county has six neighbours, no less no more!\n\n6.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "9.1 Spatial lag with row-standardized weights",
    "text": "9.1 Spatial lag with row-standardized weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\nIn spatial econometrics, a spatial lag represents the weighted average of a variable from neighboring units (e.g., countries or regions). The weights are typically determined by some spatial proximity measure, like contiguity or distance, and are standardized so that the weights in each row of the spatial weights matrix sum to 1 (i.e., row-standardized weights).\n\nnb1 &lt;- wm_q[[1]]: This retrieves the first set of neighboring regions for a specific region (from the spatial weights list wm_q), indicating the neighbors of a particular unit (or country in this case).\nnb1 &lt;- hunan$GDPPC[nb1]: This step takes the GDP per capita (GDPPC) of the neighboring units and assigns them to nb1, meaning you now have the GDPPC values of the neighboring regions.\nThe spatial lag in this context would represent the average GDPPC of the neighboring regions, where the influence of each neighbor is weighted according to the row-standardized weights from the spatial weights matrix. This helps in understanding the relationship between a region’s own GDPPC and the average GDPPC of its neighbors.\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n9.2 Spatial lag as a sum of neighboring values\nI calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then I use glist = in the nb2listw function to explicitly assign these weights.\nI start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which I have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighboring values now?\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#spatial-window-average",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "9.3 Spatial window average",
    "text": "9.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nNote: For more effective comparison, it is advicible to use the core tmap mapping functions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex4.html#spatial-window-sum",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "9.4 Spatial window sum",
    "text": "9.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nNote: For more effective comparison, it is advisable to use the core tmap mapping functions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-ppp-objects-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-ppp-objects-from-sf-data.frame",
    "title": "In-class Exercise 2",
    "section": "Creating ppp objects from sf data.frame",
    "text": "Creating ppp objects from sf data.frame\nInstead of using the two steps approaches discussed in Hands-on Exercise 3 to create the ppp objects, in this section you will learn how to work with sf data.frame.\n\nPlotSummary\n\n\nIn the code chunk below, as.ppp() of spatstat.geom package is used to derive an ppp object layer directly from a sf tibble data.frame.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nNext, summary() can be used to reveal the properties of the newly created ppp objects.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-kde-using-tmap",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-kde-using-tmap",
    "title": "In-class Exercise 2",
    "section": "Visualising KDE using tmap",
    "text": "Visualising KDE using tmap\n\nkde_childcareSG_ad_raster &lt;- raster(gridded_kde_childcareSG_ad)\n\nThe code chunk below is used to plot the output raster by using tmap functions.\n\ntm_shape(kde_childcareSG_ad_raster) + \n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE,\n            bg.color = \"#E4D5C9\")\n\nWarning: Currect projection of shape kde_childcareSG_ad_raster unknown. Long\nlat (epsg 4326) coordinates assumed.\n\n\n\n\n\n\n\n\n\nExtracting study area using sf objects\n\nThe TaskThe code\n\n\nExtract and create an ppp object showing child care services and within Punggol Planning Area\n\n\nOn the other hand, filter() of dplyr package should be used to extract the target planning areas as shown in the code chunk below.\n\npg_owin &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)  \n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#the-analytical-question",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#the-study-area-and-data",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "2.2 The Study Area and Data",
    "text": "2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#setting-the-analytical-tools",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#setting-the-analytical-tools",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "2.3 Setting the Analytical Tools",
    "text": "2.3 Setting the Analytical Tools\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.1 Import shapefile into r environment",
    "text": "3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.2 Import csv file into r environment",
    "text": "3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#performing-relational-join",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.3 Performing relational join",
    "text": "3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.4 Visualising Regional Development Indicator",
    "text": "3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "4.1 Computing Contiguity Spatial Weights",
    "text": "4.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "4.2 Row-standardised weights matrix",
    "text": "4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\n\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#marons-i-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#marons-i-test",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "5.1 Maron’s I test",
    "text": "5.1 Maron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n5.1.1 Question: What statistical conclusion can you draw from the output above?\n\nMoran’s I statistic is 0.30075, which suggests positive spatial autocorrelation. A positive value of Moran’s I means that areas with similar values (in this case, GDP per capita) are clustered together—i.e., areas with high GDP per capita are near other areas with high GDP per capita, and vice versa\nThe p-value is 1.095e-06, which is extremely small (less than 0.05). This indicates that the spatial autocorrelation observed is statistically significant, and we can reject the null hypothesis of no spatial autocorrelation.\nHypothesis:\nThe alternative hypothesis is that the Moran’s I statistic is greater than expected under the null hypothesis. Since the p-value is very small, we conclude that there is strong evidence to support the alternative hypothesis of positive spatial autocorrelation.\nIn term of the Z-score or Moran I statistic standard deviate, this is quite large and indicates that the observed spatial autocorrelation is much greater than what would be expected under random spatial distribution.\nTherefore, there is strong evidence of significant positive spatial autocorrelation in the GDP per capita across the regions. This means that regions with similar GDP per capita tend to be spatially clustered rather than randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#computing-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#computing-monte-carlo-morans-i",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "5.2 Computing Monte Carlo Moran’s I",
    "text": "5.2 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n5.2.1 Question: What statistical conclustion can you draw from the output above?\n\nThe Moran’s I statistic is 0.30075, which indicates positive spatial autocorrelation (similar to the previous test). This means that regions with similar values of GDP per capita tend to be spatially clustered together.\nThe test uses a Monte Carlo approach with 1000 simulations to compare the observed Moran’s I value against a distribution of Moran’s I values generated under the null hypothesis (random spatial distribution).\nThe observed rank is 1000, which means that the observed Moran’s I statistic (0.30075) is the highest value among all 1000 simulations. This suggests that the observed spatial autocorrelation is much stronger than what would be expected under random spatial distribution.\nThe p-value is 0.001, which is very small (less than 0.05), indicating that the observed Moran’s I statistic is statistically significant. This provides strong evidence against the null hypothesis of no spatial autocorrelation.\nAlternative Hypothesis:\nThe alternative hypothesis states that the observed Moran’s I is greater than what would be expected under a random spatial distribution. Given the low p-value, we can confidently accept this alternative hypothesis and reject the null hypothesis.\nTherefore, there is strong evidence of significant positive spatial autocorrelation in GDP per capita across the regions in the dataset. The Monte Carlo simulation confirms that the observed spatial clustering is unlikely to be due to random chance, with the observed Moran’s I being among the highest compared to the simulations."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#visualising-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#visualising-monte-carlo-morans-i",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "5.3 Visualising Monte Carlo Moran’s I",
    "text": "5.3 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n5.3.1 Question: What statistical observation can you draw from the output above?\n\nThe mean of the simulated Moran’s I values is -0.01505, which is close to zero, as expected under the null hypothesis of no spatial autocorrelation. This suggests that under random spatial arrangement, the average Moran’s I would be close to zero.\nThe variance of the simulated Moran’s I values is 0.00437, which indicates the spread or dispersion of the simulated values around the mean.\nThe minimum value is -0.18339, and the maximum value is 0.27593. This shows that while most simulated Moran’s I values are clustered near zero, the range allows for both negative and positive autocorrelation values.\nThe median of -0.02125 is close to zero, consistent with the randomization assumption.\nThe 1st quartile and 3rd quartile values suggest that most of the simulated Moran’s I values fall between -0.06168 and 0.02611.\nLastly, the histogram shows the distribution of the simulated Moran’s I values, which is centered near zero with most values within the range of -0.18 to 0.28. The red vertical line at 0 emphasizes that the bulk of simulated values are near zero, consistent with a null hypothesis of no spatial autocorrelation.\n\n\n\n5.3.2 Challenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n# Load necessary libraries\nlibrary(ggplot2)\n\n# Create a data frame from the simulated values\nsimulated_data &lt;- data.frame(Morans_I = bperm$res[1:999])\n\n# Plot the histogram using ggplot2\nggplot(simulated_data, aes(x = Morans_I)) +\n  geom_histogram(binwidth = 0.02, fill = \"steelblue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = 0, color = \"firebrick\", linetype = \"dashed\") +\n  labs(title = \"Distribution of Simulated Moran's I Values\", \n       x = \"Simulated Moran's I\", \n       y = \"Frequency\") +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#gearys-c-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#gearys-c-test",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "6.1 Geary’s C test",
    "text": "6.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n6.1.1 Question: What statistical conclusion can you draw from the output above?\n\nThe Geary’s C statistic is 0.69072. A value of Geary’s C less than 1 indicates positive spatial autocorrelation, meaning that areas with similar values (here, GDP per capita) are located near each other. Values close to 1 suggest no spatial autocorrelation, while values greater than 1 indicate negative spatial autocorrelation.\nThe p-value is 0.0001526, which is much smaller than the conventional significance level of 0.05. This indicates that the observed spatial autocorrelation is statistically significant, and we can reject the null hypothesis of no spatial autocorrelation.\nThe Geary C statistic standard deviate (Z-score) is 3.6108, which indicates that the observed spatial autocorrelation is much stronger than what would be expected under the null hypothesis of random spatial distribution. The Z-score is large, further confirming the statistical significance.\nHypothesis:\nThe alternative hypothesis here is that the expectation (which is 1.0 under the null hypothesis of no spatial autocorrelation) is greater than the observed statistic. Since the observed Geary’s C value is 0.69072, and the p-value is very small, we conclude that the spatial autocorrelation is significantly different from random distribution.\nPositive spatial autocorrelation is evident because Geary’s C is less than 1 and the result is statistically significant. Regions with similar GDP per capita values tend to cluster together spatially.\nTherefore, there is strong evidence of significant positive spatial autocorrelation in GDP per capita across the regions in the dataset. The Geary’s C statistic suggests that neighboring regions tend to have similar GDP per capita values, and this clustering is not due to random chance."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#computing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#computing-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "6.2 Computing Monte Carlo Geary’s C",
    "text": "6.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n6.2.1 Question: What statistical conclusion can you draw from the output above?\n\nThe observed Geary’s C statistic is 0.69072. Since Geary’s C is less than 1, this suggests positive spatial autocorrelation. This means that regions with similar GDP per capita values are spatially clustered together.\nThe Monte Carlo simulation was performed with 999 simulations (plus 1 observed value, making it a total of 1000 iterations) to assess how extreme the observed Geary’s C value is under random spatial arrangements. This method helps test the significance of spatial autocorrelation more robustly than traditional methods.\nThe observed rank of 1 indicates that the observed Geary’s C value (0.69072) is the lowest among all the simulated values. This suggests that the observed statistic is highly unusual when compared to the random simulations, and hence, the observed spatial clustering is stronger than what would be expected under a random distribution.\nThe p-value is 0.001, which is much smaller than the standard significance level of 0.05. This indicates that the observed spatial autocorrelation is statistically significant. We can reject the null hypothesis of no spatial autocorrelation (which assumes Geary’s C to be around 1).\nHypothesis:\nThe alternative hypothesis is that the Geary’s C statistic is less than its expectation (which is 1 under the null hypothesis of no spatial autocorrelation). Since the observed Geary’s C is significantly lower than 1 (with a p-value of 0.001), we conclude that there is strong evidence of positive spatial autocorrelation in the GDP per capita data.\nTherefore, the Monte Carlo simulation confirms the presence of significant positive spatial autocorrelation in the GDP per capita values across the regions. The observed Geary’s C value is much lower than expected under random distribution, with a p-value of 0.001, showing that regions with similar GDP per capita values tend to be spatially clustered."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#visualising-the-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#visualising-the-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "6.3 Visualising the Monte Carlo Geary’s C",
    "text": "6.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\n6.3.1 Question: What statistical observation can you draw from the output?\n\nThe mean of the simulated Geary’s C values is 1.0044, which is very close to the expected value of 1 under the null hypothesis of no spatial autocorrelation. This suggests that under random spatial arrangements, the Geary’s C statistic should be near 1.\nThe median is 1.0052, also close to 1, indicating that half of the simulated values are slightly below or above 1, again consistent with the null hypothesis.\nThe variance of the simulated Geary’s C values is 0.00744, which reflects the spread of the simulated values around the mean. This small variance suggests that the simulated values are relatively tightly clustered around 1.\nThe minimum simulated Geary’s C value is 0.7142, and the maximum is 1.2722, indicating that the simulated values fall within a reasonable range around 1.\nThe 1st quartile (0.9502) and 3rd quartile (1.0595) suggest that most of the simulated values lie within this interquartile range, again near 1.\nFor the histogram, the distribution of the simulated Geary’s C values, centered around 1. The majority of the simulated values are clustered around this expected value, with a relatively symmetrical distribution.\nThe red vertical line at 1 highlights the expected Geary’s C under the null hypothesis (no spatial autocorrelation). The histogram shows that the observed distribution of simulated values is generally consistent with this expectation.\nThe observed Geary’s C statistic from the previous test was 0.69072, which is much lower than the mean and median of the simulated values (both around 1). This indicates that the observed spatial autocorrelation is stronger than what is expected under random conditions, providing evidence of positive spatial autocorrelation.\nThe histogram and statistical summary confirm that the simulated values of Geary’s C are centered around 1, as expected under the null hypothesis. However, the observed Geary’s C value (0.69072) is significantly lower than the simulated distribution, further reinforcing the conclusion of significant positive spatial autocorrelation in the GDP per capita data across the regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "7.1 Compute Moran’s I correlogram",
    "text": "7.1 Compute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n9.7.1 Question: What statistical observation can you draw from the plot above?\nThe output of the spatial correlogram for Moran’s I at different lags (from 1 to 6) provides insight into the spatial autocorrelation of GDP per capita (GDPPC) across varying distances. Here are the key observations:\n\nLag 1:\n\nMoran’s I = 0.30075, with a p-value of 2.189e-06 (***).\nThis is highly significant and indicates positive spatial autocorrelation at short distances (neighbors). Regions with similar GDPPC are spatially clustered.\n\nLag 2:\n\nMoran’s I = 0.20601, with a p-value of 2.029e-06 (***).\nThis lag also shows strong positive spatial autocorrelation, though less pronounced than at lag 1, but still highly significant.\n\nLag 3:\n\nMoran’s I = 0.06683, with a p-value of 0.0404 (*).\nThe autocorrelation is still positive but weaker. The significance is lower than at lags 1 and 2, indicating some degree of spatial clustering, though weaker at larger distances.\n\nLag 4:\n\nMoran’s I = 0.02995, with a p-value of 0.226 (not significant).\nAt this distance, the spatial autocorrelation is weak and statistically insignificant, suggesting no clear spatial clustering beyond a certain range.\n\nLag 5:\n\nMoran’s I = -0.15305, with a p-value of 5.984e-05 (***).\nHere, we see negative spatial autocorrelation, meaning regions with dissimilar GDP per capita values are spatially near each other. This negative autocorrelation is statistically significant.\n\nLag 6:\n\nMoran’s I = -0.11871, with a p-value of 0.008886 (**).\nAt this lag, the spatial autocorrelation is negative, and regions with different GDPPC values tend to be neighbors, though the effect is slightly weaker than at lag 5 but still significant.\n\n\nBased on the observations:\n\nLags 1 and 2 show strong positive spatial autocorrelation, meaning that at closer distances, regions with similar GDP per capita tend to be spatially clustered.\nLag 3 shows weak positive autocorrelation, but it is still statistically significant.\nLags 4 to 6 show a shift toward negative spatial autocorrelation, meaning that at greater distances, regions with dissimilar GDP per capita values are more likely to be neighbors. Lags 5 and 6 are statistically significant, with a clear negative spatial relationship.\nTherefore, the correlogram suggests that spatial autocorrelation is strong and positive at short distances but weakens as the distance between regions increases. Beyond lag 3, the autocorrelation becomes negative, meaning dissimilar regions are neighbors at larger distances. These results provide evidence of varying spatial patterns depending on distance, with clustering of similar regions at shorter distances and dissimilar regions at longer distances."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#compute-gearys-c-correlogram-and-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.1.html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "7.2 Compute Geary’s C correlogram and plot",
    "text": "7.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the map. In this sense, they are not summary statistics but scores that allow us to learn more about the spatial structure in our data. The general intuition behind the metrics however is similar to that of global ones. Some of them are even mathematically connected, where the global version can be decomposed into a collection of local ones. One such example are Local Indicators of Spatial Association (LISA). Beside LISA, Getis-Ord’s Gi-statistics will be introduce as an alternative LMSA statistics that present complementary information or allow us to obtain similar insights for geographically referenced data.\nIn this hands-on exercise, you will learn how to compute Local Measures of Spatial Autocorrelation (LMSA) by using spdep package. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#the-analytical-question",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#the-study-area-and-data",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "2.2 The Study Area and Data",
    "text": "2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#setting-the-analytical-toolls",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#setting-the-analytical-toolls",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "2.3 Setting the Analytical Toolls",
    "text": "2.3 Setting the Analytical Toolls\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "3.1 Import shapefile into r environment",
    "text": "3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "3.2 Import csv file into r environment",
    "text": "3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#performing-relational-join",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "3.3 Performing relational join",
    "text": "3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "3.4 Visualising Regional Development Indicator",
    "text": "3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "4.1 Computing Contiguity Spatial Weights",
    "text": "4.1 Computing Contiguity Spatial Weights\nBefore we can compute the local spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "4.2 Row-standardised weights matrix",
    "text": "4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#computing-local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#computing-local-morans-i",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "4.3 Computing local Moran’s I",
    "text": "4.3 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n4.3.1 Mapping the local Moran’s I\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n4.3.2 Mapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.3.3 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.3.4 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "5.1 Plotting Moran scatterplot",
    "text": "5.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "5.2 Plotting Moran scatterplot with standardised variable",
    "text": "5.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#preparing-lisa-map-classes",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "5.3 Preparing LISA map classes",
    "text": "5.3 Preparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])         \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4          \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0     \n\nIn fact, we can combined all the steps into one single code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#plotting-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#plotting-lisa-map",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "5.4 Plotting LISA map",
    "text": "5.4 Plotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)    \n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2) \n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\n5.4.1 Question: What statistical observations can you draw from the LISA map above?\nBy examining both the LISA and p-value maps side by side:\n\nSignificant clusters (regions with dark blue in the p-values map) that also appear as high-high or low-low clusters in the LISA map suggest areas of strong and statistically significant economic clustering, where local economies are similar to their neighbors.\nAreas with insignificant clusters (regions with high p-values) in the LISA map are less reliable in suggesting a true spatial relationship and could indicate that the clustering seen is not statistically meaningful.\n\nIn summary, the LISA map helps identify spatial patterns of economic performance, while the p-value map provides evidence of how confident we can be in those patterns, allowing for a more robust interpretation of the spatial relationships within the dataset."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "6.1 Getis and Ord’s G-Statistics",
    "text": "6.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#deriving-distance-based-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#deriving-distance-based-weight-matrix",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "6.2 Deriving distance-based weight matrix",
    "text": "6.2 Deriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n6.2.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n6.2.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n6.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "6.3 Computing adaptive distance weight matrix",
    "text": "6.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#gi-statistics-using-fixed-distance",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#gi-statistics-using-fixed-distance",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "7.1 Gi statistics using fixed distance",
    "text": "7.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#mapping-gi-values-with-fixed-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#mapping-gi-values-with-fixed-distance-weights",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "7.2 Mapping Gi values with fixed distance weights**",
    "text": "7.2 Mapping Gi values with fixed distance weights**\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n7.2.1 Question: What statistical observation can you draw from the Gi map above?\n\nThe Redder areas represent stronger, statistically significant hot spots, where the observed high GDPPC values are not likely due to random chance.\nBluer areas represent statistically significant cold spots, where low GDPPC values form a pattern.\n\nBy comparing the GDPPC map with the Gi map:\n\nThe Gi map highlights not only where GDPPC is high or low but also where these high or low values are statistically clustered.\nFor example, a region with moderately high GDPPC might not be classified as a hot spot if its neighbors also have high GDPPC values, while a region with very high GDPPC surrounded by lower GDPPC areas would likely be identified as a hot spot.\n\nSince the Gi values are derived using a fixed distance weight matrix, this means that the analysis considers neighbors within a fixed distance when calculating the statistic. As a result, the hot and cold spots are influenced by nearby regions within that predefined distance, making the spatial patterns scale-dependent.\nIn summary, the Gi map provides a more refined view of the spatial clustering of economic performance, identifying areas where high or low GDPPC values are concentrated, and signaling the presence of statistically significant hot and cold spots based on the spatial distribution of economic activity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#gi-statistics-using-adaptive-distance",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#gi-statistics-using-adaptive-distance",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "7.3 Gi statistics using adaptive distance",
    "text": "7.3 Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#mapping-gi-values-with-adaptive-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex5.2.html#mapping-gi-values-with-adaptive-distance-weights",
    "title": "Hands-on Exercise 5.2: Lobal Measures of Spatial Autocorrelation",
    "section": "7.4 Mapping Gi values with adaptive distance weights",
    "text": "7.4 Mapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n7.4.1 Question: What statistical observation can you draw from the Gi map above?\nThe Gi map based on adaptive distance weights highlights the spatial clustering of high and low GDP per capita (GDPPC) in the study area, similar to the previous Gi map derived from fixed distance weights but with a key difference in how the neighbors are determined.\nFor the Fixed Distance Gi Map, we can see how different weighting strategies affect the clustering patterns.\nIn areas with a more irregular or sparse distribution of regions, the adaptive distance weights provide a more tailored clustering pattern, possibly identifying hot and cold spots that are more region-specific or sensitive to local variations in neighbor proximity.\nWhereas, the GDPPC map provides the raw values of economic performance, while the Gi map adds statistical significance, highlighting where high or low GDPPC values are clustered in a way that is not likely due to chance.\nThe adaptive distance weight Gi map allows for a more flexible interpretation of spatial clusters, particularly in areas with uneven geographic distributions. It refines the identification of hot and cold spots by adjusting to the spatial context of each region, providing a potentially more accurate depiction of where economically significant clusters exist based on local conditions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "In this in-class exercise, sf, spdep, tmap, tidyverse, knitr and GWmodel will be used.\nUsing the step you leanred from previous hands-in, install and load the necessary R packages in R environment.\n\npacman::p_load(sf, ggstatsplot, tmap, tidyverse, knitr, GWmodel)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-hunan-shapefile",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-hunan-shapefile",
    "title": "In-class Exercise 4",
    "section": "2.1 Importing Hunan shapefile",
    "text": "2.1 Importing Hunan shapefile\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-hunan_2012-table",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-hunan_2012-table",
    "title": "In-class Exercise 4",
    "section": "2.2 Importing Hunan_2012 table",
    "text": "2.2 Importing Hunan_2012 table\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#joining-hunan-and-hunan_2012",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#joining-hunan-and-hunan_2012",
    "title": "In-class Exercise 4",
    "section": "2.3 Joining Hunan and Hunan_2012",
    "text": "2.3 Joining Hunan and Hunan_2012\n\nhunan_sf &lt;- left_join(hunan_sf, hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-adaptive-bandwidth",
    "title": "In-class Exercise 4",
    "section": "5.1 Determine adaptive bandwidth",
    "text": "5.1 Determine adaptive bandwidth\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = TRUE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nbw_CV\n\n[1] 22\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach =\"AIC\",\n             adaptive = TRUE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nbw_AIC\n\n[1] 22"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#computing-geographically-wieghted-summary-statistics",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#computing-geographically-wieghted-summary-statistics",
    "title": "In-class Exercise 4",
    "section": "5.2 Computing geographically wieghted summary statistics",
    "text": "5.2 Computing geographically wieghted summary statistics\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-output-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-output-data",
    "title": "In-class Exercise 4",
    "section": "5.3 Preparing the output data",
    "text": "5.3 Preparing the output data\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-fixed-bandwidth",
    "title": "In-class Exercise 4",
    "section": "7.1 Determine fixed bandwidth",
    "text": "7.1 Determine fixed bandwidth\n\nCross-validationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach =\"AIC\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\nbw_AIC\n\n[1] 160.5517"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#computing-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#computing-adaptive-bandwidth",
    "title": "In-class Exercise 4",
    "section": "7.2 Computing adaptive bandwidth",
    "text": "7.2 Computing adaptive bandwidth\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = FALSE,\n               longlat = T)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-output-data-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-output-data-1",
    "title": "In-class Exercise 4",
    "section": "7.3 Preparing the output data",
    "text": "7.3 Preparing the output data\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-geographically-weighted-summary-statistics-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-geographically-weighted-summary-statistics-1",
    "title": "In-class Exercise 4",
    "section": "7.4 Visualising geographically weighted summary statistics",
    "text": "7.4 Visualising geographically weighted summary statistics\n\nThe Geographically Weighted Mean\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically wieghted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#conventional-statistical-solution",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#conventional-statistical-solution",
    "title": "In-class Exercise 4",
    "section": "8.1 Conventional statistical solution",
    "text": "8.1 Conventional statistical solution\n\nggscatterstats(\n  data = hunan2012, \n  x = Agri, \n  y = GDPPC,\n  xlab = \"Gross Agriculture Output\", ## label for the x-axis\n  ylab = \"GDP per capita\", \n  label.var = County, \n  label.expression = Agri &gt; 10000 & GDPPC &gt; 50000, \n  point.label.args = list(alpha = 0.7, size = 4, color = \"grey50\"),\n  xfill = \"#CC79A7\", \n  yfill = \"#009E73\", \n  title = \"Relationship between GDP PC and Gross Agriculture Output\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geospatial-analytics-solution",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geospatial-analytics-solution",
    "title": "In-class Exercise 4",
    "section": "8.2 Geospatial analytics solution",
    "text": "8.2 Geospatial analytics solution\n\nDetermine the bandwidthComputing gwCorrelationExtracting the result\n\n\n\nbw &lt;- bw.gwr(GDPPC ~ GIO, \n             data = hunan_sp, \n             approach = \"AICc\", \n             adaptive = TRUE)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1870.235 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1870.852 \nAdaptive bandwidth (number of nearest neighbours): 72 AICc value: 1869.744 \nAdaptive bandwidth (number of nearest neighbours): 78 AICc value: 1869.713 \nAdaptive bandwidth (number of nearest neighbours): 82 AICc value: 1869.604 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \nAdaptive bandwidth (number of nearest neighbours): 86 AICc value: 1869.647 \nAdaptive bandwidth (number of nearest neighbours): 83 AICc value: 1869.567 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \n\n\n\n\n\ngwstats &lt;- gwss(hunan_sp, \n                vars = c(\"GDPPC\", \"GIO\"), \n                bw = bw,\n                kernel = \"bisquare\",\n                adaptive = TRUE, \n                longlat = T)\n\n\n\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\ngwstat_df &lt;- as.data.frame(gwstats$SDF) %&gt;%\n  select(c(12,13)) %&gt;%\n  rename(gwCorr = Corr_GDPPC.GIO,\n         gwSpearman = Spearman_rho_GDPPC.GIO)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\nhunan_Corr &lt;- cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#local-correlation-coefficient",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#local-correlation-coefficient",
    "title": "In-class Exercise 4",
    "section": "9.1 Local Correlation Coefficient",
    "text": "9.1 Local Correlation Coefficient\n\ntm_shape(hunan_Corr) +\n  tm_fill(\"gwCorr\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Local Correlation Coefficient\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#local-spearman-coefficient",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#local-spearman-coefficient",
    "title": "In-class Exercise 4",
    "section": "9.2 Local Spearman Coefficient",
    "text": "9.2 Local Spearman Coefficient\n\ntm_shape(hunan_Corr) +\n  tm_fill(\"gwSpearman\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Local Spearman Coefficient\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#thailand-road-accident-2019--2022",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#thailand-road-accident-2019--2022",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "5.1 Thailand Road Accident (2019 -2022)",
    "text": "5.1 Thailand Road Accident (2019 -2022)\n\nrdacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;% \n  mutate(Month_fac = month(incident_datetime,\n                       label = TRUE,\n                       abbr = TRUE)) %&gt;% \n  mutate(dayofweek = day(incident_datetime)) %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"),crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\n\nhead(rdacc)\n\nWe will filer the province and zoom into the road traffic accidents in the Bangkok Metropolitan Region BMR (Bangkok, Nonthaburi, Nakhon Pathom,Pathum Thani, Samut Prakan, Samut Sakhon) .\n\n# Filter for BMR region\nrdacc_bmr &lt;- rdacc %&gt;% \n            filter(province_en %in% c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \n                            \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\"))\nhead(rdacc_bmr)\n\nSimple feature collection with 6 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 627012.3 ymin: 1502876 xmax: 693488.9 ymax: 1533381\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 6 × 20\n  acc_code incident_datetime   report_datetime     province_th  province_en  \n     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;        &lt;chr&gt;        \n1   571882 2019-01-01 02:25:00 2019-01-02 17:32:00 นครปฐม       Nakhon Pathom\n2   600001 2019-01-01 03:00:00 2019-01-05 10:33:00 นนทบุรี        Nonthaburi   \n3   605043 2019-01-01 03:00:00 2019-03-29 08:22:00 สมุทรปราการ   Samut Prakan \n4   629691 2019-01-01 03:05:00 2019-01-01 03:05:00 กรุงเทพมหานคร Bangkok      \n5   571887 2019-01-01 04:30:00 2019-01-02 17:32:00 นครปฐม       Nakhon Pathom\n6   599234 2019-01-01 04:45:00 2019-01-02 08:28:00 สมุทรปราการ   Samut Prakan \n# ℹ 15 more variables: agency &lt;chr&gt;, route &lt;chr&gt;, vehicle_type &lt;chr&gt;,\n#   presumed_cause &lt;chr&gt;, accident_type &lt;chr&gt;,\n#   number_of_vehicles_involved &lt;dbl&gt;, number_of_fatalities &lt;dbl&gt;,\n#   number_of_injuries &lt;dbl&gt;, weather_condition &lt;chr&gt;, road_description &lt;chr&gt;,\n#   slope_description &lt;chr&gt;, Month_num &lt;dbl&gt;, Month_fac &lt;ord&gt;, dayofweek &lt;int&gt;,\n#   geometry &lt;POINT [m]&gt;\n\n\n\nplot(rdacc_bmr)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#thailand-roads-openstreetmap-export",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#thailand-roads-openstreetmap-export",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "5.2 Thailand Roads (OpenStreetMap Export)",
    "text": "5.2 Thailand Roads (OpenStreetMap Export)\n\nhotosm &lt;- st_read(dsn = \"data/rawdata\", \n                layer = \"hotosm_tha_roads_lines_shp\")\n\nReading layer `hotosm_tha_roads_lines_shp' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Take-Home_Ex\\Take-Home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2792590 features and 14 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 97.34457 ymin: 5.643645 xmax: 105.6528 ymax: 20.47168\nCRS:           NA\n\n\n\n# Check if hotosm has assigned any CRS\nst_crs(hotosm)\n\nCoordinate Reference System: NA\n\n# If CRS is missing, assign the correct CRS (assuming it's in WGS84, EPSG:4326)\nif (is.na(st_crs(hotosm))) {\n  hotosm &lt;- st_set_crs(hotosm, 4326)  # Set CRS to WGS84 if missing\n}\n\n# Now transform to UTM Zone 47N (EPSG:32647)\nhotosm &lt;- st_transform(hotosm, crs = 32647)\n\n# Check if transformation was successful\nst_crs(hotosm)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nunique(hotosm$highway)\n\n [1] \"secondary\"      \"residential\"    \"secondary_link\" \"service\"       \n [5] \"tertiary\"       \"path\"           \"footway\"        \"track\"         \n [9] \"unclassified\"   \"trunk\"          \"trunk_link\"     \"primary\"       \n[13] \"primary_link\"   \"steps\"          \"motorway_link\"  \"cycleway\"      \n[17] \"pedestrian\"     \"tertiary_link\"  \"motorway\"       \"construction\"  \n[21] \"road\"           \"raceway\"        \"corridor\"       \"living_street\" \n[25] \"escape\"         \"proposed\"       \"busway\"         \"bridleway\"     \n[29] \"abandoned\"      \"parth\"          \"barrier\"        \"paved\"         \n\n\n\nhotosm_road_types &lt;- hotosm %&gt;% \n  filter(highway %in% c(\"motorway\", \"motorway_link\", \"primary\", \"primary_link\", \n                            \"secondary\", \"secondary_link\", \"tertiary\" , \"tertiary_link\"))\nglimpse(hotosm_road_types)\n\nRows: 93,863\nColumns: 15\n$ name       &lt;chr&gt; \"ถนนฉลองกรุง\", NA, \"ถนนฉลองกรุง\", \"ถนนเอราวัณ 1\", NA, \"ถนนลำลูก…\n$ name_en    &lt;chr&gt; \"Chalong Krung Road\", NA, \"Chalong Krung Road\", \"Erawan 1 R…\n$ highway    &lt;chr&gt; \"secondary\", \"secondary_link\", \"secondary\", \"tertiary\", \"te…\n$ surface    &lt;chr&gt; \"paved\", NA, \"concrete\", NA, NA, NA, \"asphalt\", \"asphalt\", …\n$ smoothness &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ width      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ lanes      &lt;chr&gt; NA, NA, \"2\", NA, NA, \"3\", NA, NA, \"3\", \"3\", \"3\", NA, NA, NA…\n$ oneway     &lt;chr&gt; \"yes\", \"yes\", \"yes\", NA, NA, \"yes\", \"yes\", \"yes\", \"yes\", \"y…\n$ bridge     &lt;chr&gt; NA, NA, \"yes\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ layer      &lt;chr&gt; NA, NA, \"1\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ source     &lt;chr&gt; NA, NA, \"Bing\", NA, NA, NA, NA, NA, NA, NA, NA, \"DOH RoadNe…\n$ name_th    &lt;chr&gt; \"ถนนฉลองกรุง\", NA, \"ถนนฉลองกรุง\", \"ถนนเอราวัณ 1\", NA, \"ถนนลำลูก…\n$ osm_id     &lt;dbl&gt; 1125681229, 472283206, 116847248, 378672881, 347141451, 131…\n$ osm_type   &lt;chr&gt; \"ways_line\", \"ways_line\", \"ways_line\", \"ways_line\", \"ways_l…\n$ geometry   &lt;MULTILINESTRING [m]&gt; MULTILINESTRING ((693686.1 ..., MULTILINEST…"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#thailand---subnational-administrative-boundaries",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#thailand---subnational-administrative-boundaries",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "5.3 Thailand - Subnational Administrative Boundaries",
    "text": "5.3 Thailand - Subnational Administrative Boundaries\n\n# thaadm0 &lt;- st_read(dsn = \"data/rawdata\", \n                #layer = \"tha_admbnda_adm0_rtsd_20220121\") %&gt;%\n  # st_transform(crs = 32647)\n  ## No BMR information\n\nthaadm1 &lt;- st_read(dsn = \"data/rawdata\", \n                layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Take-Home_Ex\\Take-Home_Ex01\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\ntsab_bmr &lt;- thaadm1 %&gt;%\n  filter(ADM1_EN %in% c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \n                            \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\"))\n\n# thaadm2 &lt;- st_read(dsn = \"data/rawdata\", \n                #layer = \"tha_admbnda_adm2_rtsd_20220121\") %&gt;%\n  # st_transform(crs = 32647) %&gt;%\n                #filter(ADM2_EN %in% c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \n                                    #\"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\"))\n                                    ## No BMR information\n\n# thaadm3 &lt;- st_read(dsn = \"data/rawdata\", \n               # layer = \"tha_admbnda_adm3_rtsd_20220121\") %&gt;%\n # st_transform(crs = 32647) %&gt;%\n # filter(ADM3_EN %in% c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \n                          #  \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\"))\n                          ## No BMR information\n\n# thaadmall &lt;- st_read(dsn = \"data/rawdata\", \n              #  layer = \"tha_admbndl_admALL_rtsd_itos_20220121\") %&gt;%\n  # st_transform(crs = 32647)\n  ## No BMR information\n\n# thaadmlu &lt;- st_read(dsn = \"data/rawdata\", \n                # layer = \"tha_admbndt_adminUnitLookup\")\n                ## No BMR information\n\n\nplot(tsab_bmr)\n\n\n\n\n\n\n\n\n\nBMR &lt;- st_transform(tsab_bmr, crs = st_crs(hotosm_road_types))\n\nroad_bmr &lt;-st_intersection(hotosm_road_types, BMR)\n\nplot(st_geometry(road_bmr))\n\n\n\n\n\n\n\n\n\nroad_owin &lt;- as.owin(tsab_bmr)\n\nroad_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n\nclass(road_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#spatial-point-pattern-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#spatial-point-pattern-analysis",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "6.1 Spatial Point Pattern Analysis",
    "text": "6.1 Spatial Point Pattern Analysis\nAnalyze the distribution of road accidents in BMR. This includes calculating point densities, identifying accident hotspots (black spots), and testing for spatial clustering.\n\n# Bounding box from the BMR region (create a spatial window)\nbmr_window &lt;- as.owin(st_bbox(rdacc_bmr))\n\n# Extract coordinates of the road accidents for point pattern analysis\ncoords_accidents &lt;- st_coordinates(rdacc_bmr)\n\n# Create ppp object\nppp_accidents &lt;- ppp(x = coords_accidents[,1], \n                     y = coords_accidents[,2], \n                     window = bmr_window)\n\n# Plot the point pattern\nplot(ppp_accidents, main = \"Road Traffic Accidents in BMR\")\n\n\n\n\n\n\n\n\n\n6.1.1 Using a Kernel Density Estimation (KDE) to identify high-risk areas.\nThe code chunk below is used to identify high-risk areas.\n\n# Kernel density estimation\naccident_density &lt;- density(ppp_accidents, sigma = 1000)  # Adjust sigma for smoothing\n\n# Plot density map\nplot(accident_density, main = \"Accident Density in BMR\")\n\n\n\n\n\n\n\n\n\n\n6.1.2 Adding provinces to the Kernel Density Estimation (KDE) to identify high-risk areas.\nThe previous plot did not allow us to identify the provinces clearly. In the code chunk below, we are able to determine that Bangkok is one of the areas with the highest accident risk, while Nakhon Pathom has one of the lowest accident rates.\n\n# Kernel density estimation\naccident_density &lt;- density(ppp_accidents, sigma = 1000)  # Adjust sigma for smoothing\n\n# Plot density map\nplot(accident_density, main = \"Accident Density in BMR\")\n\n# Overlay province boundaries on the density plot\nplot(st_geometry(tsab_bmr), add = TRUE, border = \"lightsalmon\", lwd = 2)\n\n# Add province names at the centroid of each province polygon\ncentroids &lt;- st_centroid(tsab_bmr)  # Get centroids of provinces\n\n# Loop over each province to add labels\ntext(st_coordinates(centroids), labels = tsab_bmr$ADM1_EN, cex = 0.8, col = \"snow\")\n\n\n\n\n\n\n\n\n\n\n6.1.3 Base Map with Accident Points\n\n# Snap accident points to the nearest road\ntm_shape(tsab_bmr) + \n  tm_polygons() +  # Administrative boundaries of BMR\n  tm_shape(hotosm_road_types) + \n  tm_lines(col = \"aquamarine4\") +  # Road network (in aquarmine4)\n  tm_layout(main.title = \"Road Network in Bangkok Metropolitan Region\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#extracting-road-accident-by-month",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#extracting-road-accident-by-month",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "9.1. Extracting road accident by Month",
    "text": "9.1. Extracting road accident by Month\n\nrdacc_month &lt;- rdacc_bmr %&gt;% \n  select(Month_num)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#creating-ppp",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#creating-ppp",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "9.2 Creating ppp",
    "text": "9.2 Creating ppp\n\nrdacc_month_ppp &lt;- as.ppp(rdacc_month)\nrdacc_month_ppp\n\nMarked planar point pattern: 12986 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#check",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#check",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "9.3 Check",
    "text": "9.3 Check\nThe code chunk below is used to check the output is in the correct object class.\n\nsummary(rdacc_month_ppp)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.218049e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   4.000   7.000   6.666  10.000  12.000 \n\nWindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n                    (118900 x 89670 units)\nWindow area = 10661300000 square units\n\n\nNext, we will check if there are duplicated point events by using the code chunk below.\n\nany(duplicated(rdacc_month_ppp))\n\n[1] TRUE\n\n\nWe have identified duplicates. To count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nsum(multiplicity(rdacc_month_ppp)&gt;1)\n\n[1] 639"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#solution",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#solution",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "9.4 Solution",
    "text": "9.4 Solution\nWe will use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\n\nrdacc_month_ppp_jit &lt;- rjitter(rdacc_month_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck if any duplicated point in this geospatial data.\n\nany(duplicated(rdacc_month_ppp_jit))\n\n[1] FALSE\n\n\nIncluding Owin object\nThe code chunk below is used to combine origin_am_ppp and am_owin objects into one.\n\nrdacc_month_owin &lt;- rdacc_month_ppp_jit[road_owin]\nsummary(rdacc_month_owin)\n\nMarked planar point pattern:  12979 points\nAverage intensity 1.6924e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   4.000   7.000   6.667  10.000  12.000 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\n\nAs a good practice, plot() is used to plot ff_owin so that we can examine the correctness of the output object.\n\nplot(rdacc_month_owin)\n\n\n\n\n\n\n\n\n\nst_kde &lt;- spattemp.density(rdacc_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 4255.367 (spatial)\n  lambda = 0.0114 (temporal)\n\nNo. of observations\n  12979 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [587893.5, 712440.5] x [1484414, 1579076]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [4.83487e-18, 6.233343e-09]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#behavioral-factors-and-environmental-factors",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#behavioral-factors-and-environmental-factors",
    "title": "Take Home Exercise 1 : Geospatial Analytics for Public Good",
    "section": "10. Behavioral factors and Environmental factors",
    "text": "10. Behavioral factors and Environmental factors\n\n# Checking unique values in the presumed_cause column\nunique(rdacc_bmr$presumed_cause)\n\n [1] \"speeding\"                                      \n [2] \"running red lights/traffic signals\"            \n [3] \"other\"                                         \n [4] \"driving under the influence of alcohol\"        \n [5] \"cutting in closely by people/vehicles/animals\" \n [6] \"vehicle equipment failure\"                     \n [7] \"falling asleep\"                                \n [8] \"illegal overtaking\"                            \n [9] \"tailgating\"                                    \n[10] \"failure to yield/signal\"                       \n[11] \"abrupt lane change\"                            \n[12] \"debris/obstruction on the road\"                \n[13] \"driving in the wrong lane\"                     \n[14] \"failure to signal enter/exit parking\"          \n[15] \"failure to yield right of way\"                 \n[16] \"unfamiliarity with the route/unskilled driving\"\n[17] \"dangerous curve\"                               \n[18] \"medical condition\"                             \n[19] \"sudden stop\"                                   \n[20] \"worn-out/tire blowout\"                         \n[21] \"disabled vehicle without proper signals/signs\" \n[22] \"overloaded vehicle\"                            \n[23] \"reversing vehicle\"                             \n[24] \"straddling lanes\"                              \n[25] \"insufficient light\"                            \n[26] \"vehicle electrical system failure\"             \n[27] \"road in poor condition\"                        \n[28] \"disabled vehicle without proper signals\"       \n[29] \"slippery road\"                                 \n[30] \"obstruction in sight\"                          \n[31] \"using mobile phone while driving\"              \n[32] \"ignoring stop sign while leaving intersection\" \n[33] \"brake/anti-lock brake system failure\"          \n[34] \"no traffic signs\"                              \n[35] \"repair/construction on the road\"               \n[36] \"no presumed cause related to driver\"           \n[37] \"no road divider lines\"                         \n[38] \"inadequate visibility\"                         \n[39] \"using psychoactive substances\"                 \n[40] \"loss of control\"                               \n\n# Filter behavioral factors\nbehavioral_factors &lt;- rdacc_bmr %&gt;%\n  filter(presumed_cause %in% c(\"abrupt lane change\", \"agressive driving/overtaking\", \"driving in the wrong lane\", \"driving under the influence of alcohol\", \"driving without headlights/illumination\", \"failure to signal enter/exit parking\", \"failure to yield right of way\", \"failure to yield/signal\", \"falling asleep\", \"ignoring stop sign while leaving intersection\", \"illegal overtaking\", \"inadequate visibility\", \"internal disturbance\", \"loss of control\", \"medical condition\", \"overloaded vehicle\", \"speeding\", \"sudden stop\", \"tailgating\", \"running red lights/traffic signals\", \"unfamilarity with the route/unskilled driving\", \"using mobile phone while driving\", \"using psychoactive substances\"))\n\nspeeding_accidents &lt;- rdacc_bmr %&gt;%\n  filter(presumed_cause == \"speeding\")\n\n\n# Checking unique values in the weather_condition and slope_description column\nunique(rdacc_bmr$weather_condition)\n\n[1] \"clear\"            \"other\"            \"rainy\"            \"dark\"            \n[5] \"land slide\"       \"foggy\"            \"natural disaster\"\n\n\n\n# Filter environmental factors (weather conditions and slope)\nenvironmental_factors &lt;- rdacc_bmr %&gt;%\n  filter(weather_condition %in% c(\"dark\", \"foggy\", \"landslide\", \"natural disaster\", \"rainy\"))\n\nrainy_accidents &lt;- rdacc_bmr %&gt;%\n  filter(weather_condition == \"rainy\")\n\n\n# Map accidents by BNehavioral factors (e.g., speeding)\ntm_shape(tsab_bmr) +\n  tm_polygons() +\n  tm_shape(behavioral_factors) +\n  tm_dots(size = 0.01, col = \"firebrick2\") + \n  tm_layout(title = \"Behavioral Factor\")\n\n\n\n\n\n\n\n# Map accidents by Environmental factors\ntm_shape(tsab_bmr) +\n  tm_polygons() +\n  tm_shape(environmental_factors) +\n  tm_dots(size = 0.01, col = \"royalblue4\") + \n  tm_layout(title = \"Environmental Factor\")\n\n\n\n\n\n\n\n# Map accidents by Speeding\ntm_shape(tsab_bmr) +\n  tm_polygons() +\n  tm_shape(speeding_accidents) +\n  tm_dots(size = 0.01, col = \"coral\") + \n  tm_layout(title = \"Behavioral Factor: Speeding Accidents\")\n\n\n\n\n\n\n\n# Map accidents by Rainy conditions\ntm_shape(tsab_bmr) +\n  tm_polygons() +\n  tm_shape(rainy_accidents) +\n  tm_dots(size = 0.01, col = \"chartreuse4\") + \n  tm_layout(title = \"Environmental Factor: Rainy Condition Accidents\")\n\n\n\n\n\n\n\n\n\n# Combined map for environmental and behavioral factors\ntm_shape(tsab_bmr) +\n  tm_polygons() +\n  tm_shape(environmental_factors) +\n  tm_dots(size = 0.01, col = \"royalblue4\", title = \"Environmental Factors\") + \n  tm_shape(behavioral_factors) +\n  tm_dots(size = 0.01, col = \"firebrick2\", title = \"Behavioral Factors\") +\n  tm_shape(speeding_accidents) +\n  tm_dots(size = 0.01, col = \"coral\", title =  \"Speeding Accidents\") + \n  tm_shape(rainy_accidents) +\n  tm_dots(size = 0.01, col = \"chartreuse4\", title =  \"Rainy Condition Accidents\") + \n  tm_layout(title = \"Environmental vs Behavioral Factors in Car Accidents\")\n\n\n\n\n\n\n\n\nContingency Table A contingency table will show how often both types of factors occur together.\n\n# Create a combined dataset with both environmental and behavioral factors\ncombined_factors &lt;- rdacc_bmr %&gt;%\n  mutate(is_behavioral = presumed_cause %in% c(\"speeding\", \"abrupt lane change\", \"agressive driving/overtaking\", \n                                               \"driving in the wrong lane\", \"driving under the influence of alcohol\", \n                                               \"driving without headlights/illumination\", \"failure to signal enter/exit parking\", \n                                               \"failure to yield right of way\", \"failure to yield/signal\", \n                                               \"falling asleep\", \"ignoring stop sign while leaving intersection\", \n                                               \"illegal overtaking\", \"inadequate visibility\", \"internal disturbance\", \n                                               \"loss of control\", \"medical condition\", \"overloaded vehicle\", \n                                               \"speeding\", \"sudden stop\", \"tailgating\", \"running red lights/traffic signals\", \n                                               \"unfamilarity with the route/unskilled driving\", \n                                               \"using mobile phone while driving\", \"using psychoactive substances\"),\n         is_environmental = weather_condition %in% c(\"dark\", \"foggy\", \"landslide\", \"natural disaster\", \"rainy\") |\n                            slope_description == \"slope area\" |\n                            road_description == \"sharp curve\")\n\n# Create a contingency table\ntable(combined_factors$is_behavioral, combined_factors$is_environmental)\n\n       \n        FALSE TRUE\n  FALSE  1949  156\n  TRUE   9596 1285\n\n\nOutput is saved in rds format for future used.\n\nwrite_rds(rdacc_bmr,\"data/rds/acc.rds\")\n\nThe code chunk below will be used to import the save origin6_9.rds into R environment.\n\nacc &lt;- read_rds(\"data/rds/acc.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "",
    "text": "Introducing sfdep.\nsfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep.\nsfdep utilizes list columns extensively to make this interface possible.”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "7.1 Step 1: Deriving Queen’s contiguity weights: sfdep methods",
    "text": "7.1 Step 1: Deriving Queen’s contiguity weights: sfdep methods\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNotice that st_weights() provides tree arguments, they are:\n\nnb: A neighbor list object as created by st_neighbors().\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors.\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-global-moran-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-global-moran-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "7.2 Computing Global Moran’ I",
    "text": "7.2 Computing Global Moran’ I\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from spdep package, the output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-moransi-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-moransi-test",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "7.3 Performing Global Moran’sI test",
    "text": "7.3 Performing Global Moran’sI test\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”. randomization, and\nBy default the randomization argument is TRUE. If FALSE, under the assumption of normality."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-morani-permutation-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-morani-permutation-test",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "7.4 Global Moran’I permutation test",
    "text": "7.4 Global Moran’I permutation test\nIn practice, Monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by  globel_moran_perm()\n\nStep 1Step 2The report\n\n\nIt is always a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\nset.seed(1234)\n\n\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nThe statistical report on previous tab shows that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n\n\n\n\n\nReminder\n\n\n\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "8.1 Computing local Moran’s I",
    "text": "8.1 Computing local Moran’s I\nIn this section, you will learn how to compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package.\n\nThe codeThe output\n\n\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "8.2 Visualising local Moran’s I",
    "text": "8.2 Visualising local Moran’s I\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "8.3 Visualising p-value of local Moran’s I",
    "text": "8.3 Visualising p-value of local Moran’s I\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the p_ii_sim field.\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"p-values of local Moran's I\",\n    main.title.size = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i-and-p-value",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i-and-p-value",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "8.4 Visualising local Moran’s I and p-value",
    "text": "8.4 Visualising local Moran’s I and p-value\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) + \n  tm_fill(\"ii\")+\n  tm_borders(alpha=0.5)+\n  tm_layout(main.title=\"p-value\",\n            main.title.size=2)\n\ntmap_mode(\"plot\")\nmap2 &lt;- tm_shape(lisa) + \n  tm_fill(\"p_ii_sim\")+\n  tm_borders(alpha=0.5)+\n  tm_layout(main.title=\"p-value\",\n            main.title.size=2)\n\ntmap_arrange(map1, \n             map2, \n             asp=1, #Aspect Ratio\n             ncol=2)\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "8.5 Plotting LISA map",
    "text": "8.5 Plotting LISA map\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig &lt;- lisa %&gt;%\n  filter(p_ii &lt; 0.05) #filter only significant p values\n\ntmap_mode(\"plot\")\ntm_shape(lisa)+\n  tm_polygons()+\n  tm_borders(alpha=0.5)+\ntm_shape(lisa_sig)+\n  tm_fill(\"mean\")+\n  tm_borders(alpha=0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "9. Hot Spot and Cold Spot Area Analysis (HCSA)",
    "text": "9. Hot Spot and Cold Spot Area Analysis (HCSA)\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-gi-statistics",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-gi-statistics",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "10. Computing local Gi* statistics",
    "text": "10. Computing local Gi* statistics\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan_GDPPC %&gt;% \n  mutate(nb = st_contiguity(geometry) ,\n         wts = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha =1),\n         .before = 1)\n\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\n\n\n\n\n\n\nNote\n\n\n\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\nSince we are going to compute Gi* statistics, include_self()is used.\n\n\n\nNow, we will compute the local Gi* by using the code chunk below.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-gi",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-gi",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "10.1 Visualising Gi*",
    "text": "10.1 Visualising Gi*\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA)+\n  tm_fill(\"gi_star\")+\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-p-value-of-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "10.2 Visualising p-value of HCSA",
    "text": "10.2 Visualising p-value of HCSA\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visuaising-local-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visuaising-local-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "10.3 Visuaising local HCSA",
    "text": "10.3 Visuaising local HCSA\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-hot-spot-and-cold-spot-areas",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-hot-spot-and-cold-spot-areas",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "10.4 Visualising hot spot and cold spot areas",
    "text": "10.4 Visualising hot spot and cold spot areas\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\nNote\n\n\n\nFigure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nWe will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#learning-outcome",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "We will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#the-analytical-question",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#importing-geospatial-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#importing-geospatial-data-into-r-environment",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.1 Importing geospatial data into R environment",
    "text": "4.1 Importing geospatial data into R environment\nIn this section, you will import Myanmar Township Boundary GIS data and its associated attrbiute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#importing-aspatial-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#importing-aspatial-data-into-r-environment",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.2 Importing aspatial data into R environment",
    "text": "4.2 Importing aspatial data into R environment\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveal the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the tibble data.frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#derive-new-variables-using-dplyr-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#derive-new-variables-using-dplyr-package",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.3 Derive new variables using dplyr package",
    "text": "4.3 Derive new variables using dplyr package\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "5.1 EDA using statistical graphics",
    "text": "5.1 EDA using statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nWhat can you observed from the distributions reveal in the histogram and boxplot.\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#eda-using-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#eda-using-choropleth-map",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "5.2 EDA using choropleth map",
    "text": "5.2 EDA using choropleth map\n\n5.2.1 Joining geospatial data with aspatial data\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\nThe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n5.2.2 Preparing a choropleth map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\nCan you identify the differences?\nThis new choropleth map shows that areas with a low number of households also have high radio penetration rates."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#extracting-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#extracting-clustering-variables",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.1 Extracting clustering variables",
    "text": "7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#data-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#data-standardisation",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.2 Data Standardisation",
    "text": "7.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#min-max-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#min-max-standardisation",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.3 Min-Max standardisation",
    "text": "7.3 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#z-score-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#z-score-standardisation",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.4 Z-score standardisation",
    "text": "7.4 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\n\n\n\n\n\n\nNote\n\n\n\ndescribe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nZ-score standardisation method should only be used if we would assume all variables come from some normal distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visualising-the-standardised-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visualising-the-standardised-clustering-variables",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.5 Visualising the standardised clustering variables",
    "text": "7.5 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\nWhat statistical conclusion can you draw from the histograms above?\nThe three histograms show a right skewed distribution. Outliers in the raw data will still be present in the Z-score transformation, but they may be easier to spot due to their extreme Z-scores. Min-Max scaling keeps the relative distribution intact, while Z-score scaling normalizes the data based on the mean and standard deviation. This could help in comparing RADIO_PR with other variables or in clustering analysis.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-proximity-matrix",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.6 Computing proximity matrix",
    "text": "7.6 Computing proximity matrix\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-hierarchical-clustering",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.7 Computing hierarchical clustering",
    "text": "7.7 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#selecting-the-optimal-clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#selecting-the-optimal-clustering-algorithm",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.8 Selecting the optimal clustering algorithm",
    "text": "7.8 Selecting the optimal clustering algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#determining-optimal-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#determining-optimal-clusters",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.9 Determining Optimal Clusters",
    "text": "7.9 Determining Optimal Clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n7.9.1 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#interpreting-the-dendrograms",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#interpreting-the-dendrograms",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.10 Interpreting the dendrograms",
    "text": "7.10 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visually-driven-hierarchical-clustering-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visually-driven-hierarchical-clustering-analysis",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.11 Visually-driven hierarchical clustering analysis",
    "text": "7.11 Visually-driven hierarchical clustering analysis\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n7.11.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n7.11.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#mapping-the-clusters-formed",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#mapping-the-clusters-formed",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.12 Mapping the clusters formed",
    "text": "7.12 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#converting-into-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#converting-into-spatialpolygonsdataframe",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.1 Converting into SpatialPolygonsDataFrame",
    "text": "8.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-neighbour-list",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-neighbour-list",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.2 Computing Neighbour List",
    "text": "8.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-minimum-spanning-tree",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-minimum-spanning-tree",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.3 Computing minimum spanning tree",
    "text": "8.3 Computing minimum spanning tree\n\n8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-minimum-spanning-tree-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-minimum-spanning-tree-1",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.4 Computing minimum spanning tree",
    "text": "8.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-spatially-constrained-clusters-using-skater-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#computing-spatially-constrained-clusters-using-skater-method",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.5 Computing spatially constrained clusters using SKATER method",
    "text": "8.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visualising-the-clusters-in-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visualising-the-clusters-in-choropleth-map",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.6 Visualising the clusters in choropleth map",
    "text": "8.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#a-short-note-about-clustgeo-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#a-short-note-about-clustgeo-package",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.1 A short note about ClustGeo package",
    "text": "9.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.2 Ward-like hierarchical clustering: ClustGeo",
    "text": "9.2 Ward-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() you learned in previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\n9.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#spatially-constrained-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#spatially-constrained-hierarchical-clustering",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.3 Spatially Constrained Hierarchical Clustering",
    "text": "9.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.3 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster object.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visualising-individual-clustering-variable",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visualising-individual-clustering-variable",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "10.1 Visualising individual clustering variable",
    "text": "10.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#multivariate-visualisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#multivariate-visualisation",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "10.2 Multivariate Visualisation",
    "text": "10.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "Tourism is one of Thailand’s largest industries, accounting for some 20% of the gross domestic product (GDP). In 2019, Thailand earned 90 billion US$ from domestic and international tourism, but the COVID-19 pandemic caused revenues to crash to 24 billion US$ in 2020.\nFigure below shows the total revenue receipt from tourism sector from January 2019 until Feb 2023. The figure reveals that the revenue from tourism industry have been recovered gradually since September 2021.\n\nHowever, it is important to note that the tourism economy of Thailand are not evenly distributed. Figure below reveals that the tourism economy of Thailand are mainly focus on five provinces, namely Bangkok, Phuket, Chiang Mai, Sukhothai and Phetchaburi."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#import-shapefile-into-r-environment",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#import-shapefile-into-r-environment",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "6.1 Import shapefile into r environment",
    "text": "6.1 Import shapefile into r environment\n\n6.1.1 Thailand Domestic Tourism Statistics\n\ntourism_data &lt;- read_csv(\"data/rawdata/thailand_domestic_tourism_2019_2023_ver2.csv\") \n# Update with actual path\n\n\nglimpse(tourism_data)\n\nRows: 30,800\nColumns: 7\n$ date          &lt;date&gt; 2019-01-01, 2019-01-01, 2019-01-01, 2019-01-01, 2019-01…\n$ province_thai &lt;chr&gt; \"กรุงเทพมหานคร\", \"ลพบุรี\", \"พระนครศรีอยุธยา\", \"สระบุรี\", \"ชัยนาท…\n$ province_eng  &lt;chr&gt; \"Bangkok\", \"Lopburi\", \"Phra Nakhon Si Ayutthaya\", \"Sarab…\n$ region_thai   &lt;chr&gt; \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"…\n$ region_eng    &lt;chr&gt; \"central\", \"central\", \"central\", \"central\", \"central\", \"…\n$ variable      &lt;chr&gt; \"ratio_tourist_stay\", \"ratio_tourist_stay\", \"ratio_touri…\n$ value         &lt;dbl&gt; 93.37, 61.32, 73.37, 67.33, 79.31, 71.70, 64.65, 71.21, …\n\n\nVariables:\n\n\n\n\n\n\n\nno_tourist_all\nThe total number of domestic tourists who visited the province\n\n\nno_tourist_foreign\nThe number of foreign tourists who visited the province\n\n\nno_tourist_stay\nThe number of tourists who stay over-night\n\n\nno_tourist_thai\nThe number of Thai tourists who visited the province\n\n\nratio_tourist_stay\nThe ratio of tourist stay over-night.\n\n\nrevenue_all\nThe revenue generated by the tourism industry in the province, in Thai Baht\n\n\nrevenue_foreign\nThe revenue generated by foreign tourists in the province, in Thai Baht\n\n\nrevenue_thai\nThe revenue generated by Thai tourists in the province, in Thai Baht\n\n\n\n\n6.1.1.2 Reshape the Data\nUse pivot_wider to create new columns based on the variables in Column F, using Column G as the values.\n\ntourism_data_wide &lt;- tourism_data %&gt;%\n  pivot_wider(\n    names_from = variable,\n    values_from = value,\n    values_fill = NA  # Fill missing values with NA \n    )  #%&gt;% \n  #filter(!is.na(revenue_all) & revenue_all != 0)\n\ntourism_data_wide\n\n# A tibble: 3,850 × 13\n   date       province_thai province_eng             region_thai region_eng\n   &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;                    &lt;chr&gt;       &lt;chr&gt;     \n 1 2019-01-01 กรุงเทพมหานคร  Bangkok                  ภาคกลาง     central   \n 2 2019-01-01 ลพบุรี          Lopburi                  ภาคกลาง     central   \n 3 2019-01-01 พระนครศรีอยุธยา Phra Nakhon Si Ayutthaya ภาคกลาง     central   \n 4 2019-01-01 สระบุรี         Saraburi                 ภาคกลาง     central   \n 5 2019-01-01 ชัยนาท         Chainat                  ภาคกลาง     central   \n 6 2019-01-01 นครปฐม        Nakhon Pathom            ภาคกลาง     central   \n 7 2019-01-01 สิงห์บุรี         Sing Buri                ภาคกลาง     central   \n 8 2019-01-01 อ่างทอง        Ang Thong                ภาคกลาง     central   \n 9 2019-01-01 นนทบุรี         Nonthaburi               ภาคกลาง     central   \n10 2019-01-01 ปทุมธานี        Pathum Thani             ภาคกลาง     central   \n# ℹ 3,840 more rows\n# ℹ 8 more variables: ratio_tourist_stay &lt;dbl&gt;, no_tourist_stay &lt;dbl&gt;,\n#   no_tourist_all &lt;dbl&gt;, no_tourist_thai &lt;dbl&gt;, no_tourist_foreign &lt;dbl&gt;,\n#   revenue_all &lt;dbl&gt;, revenue_thai &lt;dbl&gt;, revenue_foreign &lt;dbl&gt;\n\n\n\n\n6.1.1.2 Select Relevant Columns\nAfter reshaping, select only the relevant columns for your analysis. Also, create new columns for month, month factor and month-year.\n\ntourism_data_new &lt;- tourism_data_wide %&gt;%\n  select(date, province_thai, province_eng, region_eng, \n         no_tourist_all, no_tourist_foreign, \n         no_tourist_stay, no_tourist_thai, \n         ratio_tourist_stay, revenue_all, \n         revenue_foreign, revenue_thai) %&gt;%\n  mutate(\n    Month_num = month(date),  # Extract numeric month\n    Month_fac = month(date, label = TRUE, abbr = TRUE),  # Extract abbreviated month as factor\n    Month_year = paste0(Month_fac, \"-\", year(date))  # Create 'month-year' column\n  )\n\nprint(tourism_data_new)\n\n# A tibble: 3,850 × 15\n   date       province_thai province_eng             region_eng no_tourist_all\n   &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;                    &lt;chr&gt;               &lt;dbl&gt;\n 1 2019-01-01 กรุงเทพมหานคร  Bangkok                  central           5959075\n 2 2019-01-01 ลพบุรี          Lopburi                  central            268664\n 3 2019-01-01 พระนครศรีอยุธยา Phra Nakhon Si Ayutthaya central            730329\n 4 2019-01-01 สระบุรี         Saraburi                 central            207236\n 5 2019-01-01 ชัยนาท         Chainat                  central             79073\n 6 2019-01-01 นครปฐม        Nakhon Pathom            central            296107\n 7 2019-01-01 สิงห์บุรี         Sing Buri                central             49438\n 8 2019-01-01 อ่างทอง        Ang Thong                central            104097\n 9 2019-01-01 นนทบุรี         Nonthaburi               central            323717\n10 2019-01-01 ปทุมธานี        Pathum Thani             central            233295\n# ℹ 3,840 more rows\n# ℹ 10 more variables: no_tourist_foreign &lt;dbl&gt;, no_tourist_stay &lt;dbl&gt;,\n#   no_tourist_thai &lt;dbl&gt;, ratio_tourist_stay &lt;dbl&gt;, revenue_all &lt;dbl&gt;,\n#   revenue_foreign &lt;dbl&gt;, revenue_thai &lt;dbl&gt;, Month_num &lt;dbl&gt;,\n#   Month_fac &lt;ord&gt;, Month_year &lt;chr&gt;\n\n\n\n\n\n6.1.2 Thailand - Subnational Administrative Boundaries\n\n# Load province boundaries\n\nprovinces &lt;- st_read(dsn = \"data/rawdata\", \n                layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(ADM1_EN = recode(ADM1_EN, # Update province boundaries' name\n    \"Lop Buri\" = \"Lopburi\",\n    \"Chai Nat\" = \"Chainat\",\n    \"Chon Buri\" = \"Chonburi\",\n    \"Prachin Buri\" = \"Prachinburi\",\n    \"Phangnga\" = \"Phang Nga\",\n    \"Buri Ram\" = \"Buriram\",\n    \"Si Sa Ket\" = \"Sisaket\",\n    \"Nong Bua Lam Phu\" = \"Nong Bua Lamphu\"\n  ))\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Take-Home_Ex\\Take-Home_Ex02\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\n# Load province boundaries\n\nglimpse(provinces)\n\nRows: 77\nColumns: 17\n$ Shape_Leng &lt;dbl&gt; 2.417227, 1.695100, 1.251111, 1.884945, 3.041716, 1.739908,…\n$ Shape_Area &lt;dbl&gt; 0.13133873, 0.07926199, 0.05323766, 0.12698345, 0.21393797,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", \"P…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"สมุทรปราการ\", \"นนทบุรี\", \"ปทุมธานี\", \"พระนครศรีอ…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH11\", \"TH12\", \"TH13\", \"TH14\", \"TH15\", \"TH16\", \"TH…\n$ ADM1_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; -001-11-30, -001-11-30, -001-11-30, -001-11-30, -001-11-30…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((674339.8 15..., MULTIPOLYGON (…\n\n\n\ntm_shape(provinces) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n## Convert to multipolygon to individual polygon\nprovinces_sf &lt;- provinces %&gt;% \n  st_cast(\"POLYGON\") %&gt;% \n  mutate(area = st_area(.))\n\n\n## Group by the unique name and select the largest polygon by area\nprovinces_cleaned &lt;- provinces_sf %&gt;% \n  group_by(ADM1_EN) %&gt;% \n  filter(area == max(area)) %&gt;% \n  ungroup() %&gt;% \n  select(-area) %&gt;% \n  select(ADM1_EN)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Ex 6: Emerging Hot Spot Analysis",
    "section": "",
    "text": "As usual, p_load () of pacman packages will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.\nFive R packages are need for this in-class exercise, they are: sf, sfdep, tmap, ploty, and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse, Kendall)\n\n\n\n\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile formart, and\nHunan_GDPPC, an attribute data set in csv format.\n\nBefore getting started, reveal the content of Hunan_GDPPC.csv by using Notepad and MS Excel.\n\n\n\nIn the code chunk below, st_read() of sf package is used to import Hunan shapefile into R.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nIn the code chunk below, read_csv() of readr is used to import Hunan_GDPPC.csv into R.\n\nGDPPC &lt;-read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "title": "In-class Ex 6: Emerging Hot Spot Analysis",
    "section": "",
    "text": "As usual, p_load () of pacman packages will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.\nFive R packages are need for this in-class exercise, they are: sf, sfdep, tmap, ploty, and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse, Kendall)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "title": "In-class Ex 6: Emerging Hot Spot Analysis",
    "section": "",
    "text": "For the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile formart, and\nHunan_GDPPC, an attribute data set in csv format.\n\nBefore getting started, reveal the content of Hunan_GDPPC.csv by using Notepad and MS Excel."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "title": "In-class Ex 6: Emerging Hot Spot Analysis",
    "section": "",
    "text": "In the code chunk below, st_read() of sf package is used to import Hunan shapefile into R.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "title": "In-class Ex 6: Emerging Hot Spot Analysis",
    "section": "",
    "text": "In the code chunk below, read_csv() of readr is used to import Hunan_GDPPC.csv into R.\n\nGDPPC &lt;-read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#importing-geospatial-data",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.1 Importing geospatial data",
    "text": "5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#updating-crs-information",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.2 Updating CRS information",
    "text": "5.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, we can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, we will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.1 Importing the aspatial data",
    "text": "6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure of will do the job.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#converting-aspatial-data-frame-into-a-sf-object",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#converting-aspatial-data-frame-into-a-sf-object",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.2 Converting aspatial data frame into a sf object",
    "text": "6.2 Converting aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.1 EDA using statistical graphics",
    "text": "7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.2 Multiple Histogram Plots distribution of variables",
    "text": "7.2 Multiple Histogram Plots distribution of variables\nIn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#drawing-statistical-point-map",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.3 Drawing Statistical Point Map",
    "text": "7.3 Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntmap_options(check.and.fix = TRUE)\n\ntm_shape(mpsz_svy21) +\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style = \"quantile\") +\n  tm_view(set.zoom.limits = c(11, 14))\n\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.1 Simple Linear Regression Method",
    "text": "8.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.2 Multiple Linear Regression Method",
    "text": "8.2 Multiple Linear Regression Method\n\n8.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#preparing-publication-quality-table-olsrr-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.4 Preparing Publication Quality Table: olsrr method",
    "text": "8.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#preparing-publication-quality-table-gtsummary-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#preparing-publication-quality-table-gtsummary-method",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.5 Preparing Publication Quality Table: gtsummary method",
    "text": "8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\nThe glue and broom.helpers packages have been installed to ensure gtsummary can run.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nFor more customisation options, refer to Tutorial: tbl_regression\n\n8.5.1 Checking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.5.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chunk below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code chunk below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nThe code chunk below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nRemember to switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.1 Building Fixed Bandwidth GWR Model",
    "text": "9.1 Building Fixed Bandwidth GWR Model\n\n9.1.1 Computing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. (Quiz: Do you know why it is in metre?)\n\n\n9.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-12 17:26:01.720444 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-12 17:26:02.592127 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#building-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.2 Building Adaptive Bandwidth GWR Model",
    "text": "9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n9.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n9.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below can be used to display the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-12 17:26:09.075547 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-12 17:26:10.18913 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#visualising-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#visualising-gwr-output",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.3 Visualising GWR Output",
    "text": "9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#converting-sdf-into-sf-data.frame",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#converting-sdf-into-sf-data.frame",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.4 Converting SDF into sf data.frame",
    "text": "9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output)) \n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#visualising-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#visualising-local-r2",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.5 Visualising local R2",
    "text": "9.5 Visualising local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#visualising-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex7.html#visualising-coefficient-estimates",
    "title": "Hands-on Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.6 Visualising coefficient estimates",
    "text": "9.6 Visualising coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n9.6.1 By URA Plannign Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-relational-join",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-relational-join",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "6.2 Performing relational join",
    "text": "6.2 Performing relational join\nThe code chunk below will be used to update the attribute table of provinces’ SpatialPolygonsDataFrame with the attribute fields of tourismdatanew dataframe. This is performed by using left_join() of dplyr package.\n\n6.2.1 Using Province in English\n\n# Left join to add geometries from thailand bundaries shapefile\ntourism_sf &lt;- tourism_data_new %&gt;%\n  left_join(provinces_cleaned, by = c(\"province_eng\" = \"ADM1_EN\")) \n\n# Ensure the data is a valid sf object\ntourism_sf &lt;- st_as_sf(tourism_sf)\n\n# Check if transformation was successful\nst_crs(tourism_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n6.2.2 Using Province in Thai (Showing Other Method)\n\n# Left join to add geometries from thailand bundaries shapefile\n# tourism_sf_th &lt;- tourism_data_new %&gt;%\n  # left_join(provinces, by = c(\"province_thai\" = \"ADM1_TH\"))\n\n# Ensure the data is a valid sf object\n#tourism_sf_th &lt;- st_as_sf(tourism_sf_th)\n\n# Check if transformation was successful\n# st_crs(tourism_sf_th)\n\n\n\n6.2.3 Tourism Data and Information\n\nThe total number of domestic tourists who visited the provinceThe number of foreign tourists who visited the provinceThe number of tourists who stay over-nightThe number of Thai tourists who visited the provinceThe ratio of tourist stay over-nightThe revenue generated by the tourism industry in the province, in Thai BahtThe revenue generated by foreign tourists in the province, in Thai BahtThe revenue generated by Thai tourists in the province, in Thai Baht\n\n\n\nno_tourist_all_sf &lt;- tourism_sf %&gt;%\n  select(1:5, 15:16)\n\n\n\n\nno_tourist_foreign_sf &lt;- tourism_sf %&gt;%\n  select(1:4, 6, 15:16)\n\n\n\n\nno_tourist_stay_sf &lt;- tourism_sf %&gt;%\n  select(1:4, 7, 15:16)\n\n\n\n\nno_tourist_thai_sf &lt;- tourism_sf %&gt;%\n  select(1:4, 8, 15:16)\n\n\n\n\nratio_tourist_stay_sf &lt;- tourism_sf %&gt;%\n  select(1:4, 9, 15:16)\n\n\n\n\nrevenue_all_sf &lt;- tourism_sf %&gt;%\n  select(1:4, 10, 15:16)\n\n\n\n\nrevenue_foreign_sf &lt;- tourism_sf %&gt;%\n  select(1:4, 11, 15:16)\n\n\n\n\nrevenue_thai_sf &lt;- tourism_sf %&gt;%\n  select(1:4, 15:16)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#plotting-a-choropleth-map",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#plotting-a-choropleth-map",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "7.1 Plotting a choropleth map",
    "text": "7.1 Plotting a choropleth map\nPlot a choropleth map showing the distribution of revenue generated by the tourism industry in the different province, in Thai Baht\n\ntmap_mode(\"plot\")\ntm_shape(tourism_sf) +\n  tm_fill(\"revenue_all\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Total Revenue\") +\n  tm_borders(col = \"grey\") +\n  tm_facets(\"Month_year\") +\n  tm_layout(main.title = \"Distribution of revenue generated by the tourism industry in the different province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)\n\n\n\n\n\n\n\n\n\n7.1.1 Calculate the Average Revenue for Each Province\n\n# Calculate the average revenue_all for each province\ntourism_sf_avg &lt;- tourism_sf %&gt;%\n  group_by(province_thai) %&gt;%\n  summarize(average_revenue_all = mean(revenue_all, na.rm = TRUE))\n\n\n\n7.1.2 Join the Average Revenue Back to the Spatial Data\n\n# Join the average revenue back to the spatial data\ntourism_sf_avg &lt;- left_join(st_drop_geometry(tourism_sf), tourism_sf_avg, by = \"province_thai\")\ntourism_sf_avg &lt;- st_as_sf(tourism_sf_avg)\n\n\n\n7.1.3 Modify the Plot Code to Use average_revenue_all\n\nset.seed(1234)\ntmap_mode(\"plot\")\ntm_shape(tourism_sf_avg) +\n  tm_fill(\"average_revenue_all\",   # Use average revenue\n          style = \"quantile\",      # Use quantile classification\n          palette = \"Blues\",       # Choose color palette\n          title = \"Average Revenue (All)\") +\n  tm_borders(col = \"grey\") +\n  tm_facets(\"Month_year\") +\n  tm_layout(main.title = \"Average Revenue Generated by Tourism Industry in Different Provinces\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-regional-development-indicator",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-regional-development-indicator",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "7.2 Visualising Regional Development Indicator",
    "text": "7.2 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of the revenue by using qtm() of tmap package.\n\n7.2.1 Equal interval classification and Equal quantile classification\n\nset.seed(1234)\n\n# Equal interval classification\nequal &lt;- tm_shape(tourism_sf) +\n  tm_fill(\"revenue_all\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_facets(\"Month_year\") +\n  tm_layout(main.title = \"Equal interval classification\",\n            legend.width = 1.2)  # Increase the legend width\n\n# Quantile classification\nquantile &lt;- tm_shape(tourism_sf) +\n  tm_fill(\"revenue_all\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_facets(\"Month_year\") +\n  tm_layout(main.title = \"Equal quantile classification\",\n            legend.width = 1.2)  # Increase the legend width\n\n# Arrange the two maps side by side\ntmap_arrange(equal, \n             quantile, \n             asp = 1, \n             ncol = 2)\n\n\n\n\n\n\n\n\n\n\n7.2.2 Equal interval classification Y2023 and Equal quantile classification Y2023\n\nset.seed(1234)\ntourism_sf_2023 &lt;- tourism_sf %&gt;%\n  filter(year(date) == 2023)\n\nequal_2023 &lt;- tm_shape(tourism_sf_2023) +\n  tm_fill(\"revenue_all\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_facets(\"Month_year\") +\n  tm_layout(main.title = \"Equal interval classification Y2023\",\n            legend.width = 1.2)\n\nquantile_2023 &lt;- tm_shape(tourism_sf_2023) +\n  tm_fill(\"revenue_all\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_facets(\"Month_year\") +\n  tm_layout(main.title = \"Equal quantile classification Y2023\",\n            legend.width = 1.2)\n\ntmap_arrange(equal_2023, \n             quantile_2023, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "8.1 Step 1: Deriving Queen’s contiguity weights: sfdep methods",
    "text": "8.1 Step 1: Deriving Queen’s contiguity weights: sfdep methods\n\n#wm_q &lt;- tourism_sf %&gt;%\n  #mutate(nb = st_contiguity(geometry),\n         #wt = st_weights(nb,\n                         #style = \"W\"),\n         #.before = 1)\n\n\n# Create weights for spatial autocorrelation\n#tourism_neighbors &lt;- tourism_sf %&gt;%\n  #st_contiguity()\n\n\n# Create weights for spatial autocorrelation\n#tourism_neighbors &lt;- tourism_sf %&gt;%\n  #st_contiguity()\n\n\n# Global Moran's I for tourism data\n#global_moran_test &lt;- tourism_sf %&gt;%\n  #global_moran(variable = \"no_tourist_all\", nb = tourism_neighbors)\n\n# Print the results\n#global_moran_test"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Ex 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, ggpubr, \n               sf, spdep, GWmodel, tmap,\n               tidyverse, gtsummary, performance,\n               see, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-fixed-bandwidth-gwr-model",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-fixed-bandwidth-gwr-model",
    "title": "In-class Ex 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "14.1 Building Fixed Bandwidth GWR Model",
    "text": "14.1 Building Fixed Bandwidth GWR Model\n\nComputing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach agreement.\n\nbw_fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                  PROX_CBD + PROX_CHILDCARE + \n                  PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                  NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale_sf,\n                approach = \"CV\",\n                kernel = \"gaussian\",\n                adaptive=FALSE,\n                longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. (Quiz: Do you know why it is in metre?)\nThe bandwidth is in meters because the spatial data we’re working with is likely projected in a coordinate reference system (CRS) that uses meters as the unit of measurement. When performing Geographically Weighted Regression (GWR), the spatial distances between data points are crucial in determining the influence of nearby observations, and the choice of unit (meters) depends on the CRS used for the geospatial data.\nIn this case, since longlat=FALSE is specified, it indicates that the data is projected in a planar CRS (such as UTM) rather than using geographic coordinates (latitude and longitude), which are typically in degrees. Planar CRS systems use meters or feet as units, so the bandwidth is optimized and reported in meters to match the spatial scale of the data.\n\n\nGWModel method - fixed bandwidth\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr_fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                  PROX_CBD + PROX_CHILDCARE + \n                  PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                  NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale_sf,\n                bw=bw_fixed,\n                kernel = \"gaussian\",\n                longlat=FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr_fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-16 23:23:58.0379 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-16 23:23:59.103503 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the global multiple linear regression model of 42967.1."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-adaptive-bandwidth-gwr-model",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-adaptive-bandwidth-gwr-model",
    "title": "In-class Ex 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "14.2 Building Adaptive Bandwidth GWR Model",
    "text": "14.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\nComputing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw_adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale_sf, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\nConstructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale_sf, bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below can be used to display the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-16 23:24:05.636141 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-16 23:24:06.605435 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#by-ura-plannign-region",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#by-ura-plannign-region",
    "title": "In-class Ex 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "18.1 By URA Plannign Region",
    "text": "18.1 By URA Plannign Region\n\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(gwr_sf_adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.\n\n\nWe will learn how to build predictive model by using geographical random forest method. By the end of this hands-on exercise, you will acquire the skills of:\n\npreparing training and test data sets by using appropriate data sampling methods,\ncalibrating predictive models by using both geospatial statistical learning and machine learning methods,\ncomparing and selecting the best model for predicting the future outcome,\npredicting the future outcomes by using the best model calibrated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#learning-outcome",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "",
    "text": "We will learn how to build predictive model by using geographical random forest method. By the end of this hands-on exercise, you will acquire the skills of:\n\npreparing training and test data sets by using appropriate data sampling methods,\ncalibrating predictive models by using both geospatial statistical learning and machine learning methods,\ncomparing and selecting the best model for predicting the future outcome,\npredicting the future outcomes by using the best model calibrated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#reading-data-file-to-rds",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#reading-data-file-to-rds",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.1 Reading data file to rds",
    "text": "4.1 Reading data file to rds\nReading the input data sets. It is in simple feature data frame.\n\nmdata &lt;- read_rds(\"data/mdata.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#data-sampling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#data-sampling",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.2 Data Sampling",
    "text": "4.2 Data Sampling\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/train_data.rds\")\nwrite_rds(test_data, \"data/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-correlation-matrix",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "5 Computing Correlation Matrix",
    "text": "5 Computing Correlation Matrix\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe correlation matrix above shows that all the correlation values are below 0.8. Hence, there is no sign of multicolinearity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#converting-the-sf-data.frame-to-spatialpointdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#converting-the-sf-data.frame-to-spatialpointdataframe",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.1 Converting the sf data.frame to SpatialPointDataFrame",
    "text": "8.1 Converting the sf data.frame to SpatialPointDataFrame\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-adaptive-bandwidth",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.2 Computing adaptive bandwidth",
    "text": "8.2 Computing adaptive bandwidth\nNext, bw.gwr() of GWmodel package will be used to determine the optimal bandwidth to be used.\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below is used to determine adaptive bandwidth and CV method is used to determine the optimal bandwidth.\n\n\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 6395 CV score: 3.60536e+13 \nAdaptive bandwidth: 3960 CV score: 3.320316e+13 \nAdaptive bandwidth: 2455 CV score: 2.928339e+13 \nAdaptive bandwidth: 1524 CV score: 2.550957e+13 \nAdaptive bandwidth: 950 CV score: 1.95632e+13 \nAdaptive bandwidth: 593 CV score: 1.58347e+13 \nAdaptive bandwidth: 375 CV score: 1.310042e+13 \nAdaptive bandwidth: 237 CV score: 1.113152e+13 \nAdaptive bandwidth: 155 CV score: 9.572037e+12 \nAdaptive bandwidth: 101 CV score: 8.457003e+12 \nAdaptive bandwidth: 71 CV score: 7.605058e+12 \nAdaptive bandwidth: 49 CV score: 6.965752e+12 \nAdaptive bandwidth: 38 CV score: 8.249935e+12 \nAdaptive bandwidth: 58 CV score: 7.275234e+12 \nAdaptive bandwidth: 45 CV score: 6.871439e+12 \nAdaptive bandwidth: 41 CV score: 6.7928e+12 \nAdaptive bandwidth: 40 CV score: 6.780447e+12 \nAdaptive bandwidth: 38 CV score: 8.249935e+12 \nAdaptive bandwidth: 40 CV score: 6.780447e+12 \n\n\nThe result shows that 40 neighbour points will be the optimal bandwidth to be used if adaptive bandwidth is used for this data set.\n\nwrite_rds(bw_adaptive, \"data/bw_adaptive.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#constructing-the-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#constructing-the-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.3 Constructing the adaptive bandwidth gwr model",
    "text": "8.3 Constructing the adaptive bandwidth gwr model\nFirst, let us call the save bandwidth by using the code chunk below.\n\nbw_adaptive &lt;- read_rds(\"data/bw_adaptive.rds\")\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data_sp,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\nThe code chunk below will be used to save the model in rds format for future use.\n\nwrite_rds(gwr_adaptive, \"data/gwr_adaptive.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#retrieve-gwr-output-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#retrieve-gwr-output-object",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.4 Retrieve gwr output object",
    "text": "8.4 Retrieve gwr output object\n\ngwr_adaptive &lt;- read_rds(\"data/gwr_adaptive.rds\")\n\nThe code below can be used to display the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-21 00:08:39.754313 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data_sp, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2478e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2195e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1632e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1823e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2411e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5188e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0231e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.9 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209.1 \n   Residual sum of squares: 4.829191e+12 \n   R-square value:  0.967657 \n   Adjusted R-square value:  0.9611534 \n\n   ***********************************************************************\n   Program stops at: 2024-10-21 00:10:01.642013"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#converting-the-test-data-from-sf-data.frame-to-spatialpointdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#converting-the-test-data-from-sf-data.frame-to-spatialpointdataframe",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.5 Converting the test data from sf data.frame to SpatialPointDataFrame",
    "text": "8.5 Converting the test data from sf data.frame to SpatialPointDataFrame\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-adaptive-bandwidth-for-the-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-adaptive-bandwidth-for-the-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.6 Computing adaptive bandwidth for the test data",
    "text": "8.6 Computing adaptive bandwidth for the test data\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 3447 CV score: 1.902155e+13 \nAdaptive bandwidth: 2138 CV score: 1.752645e+13 \nAdaptive bandwidth: 1328 CV score: 1.556299e+13 \nAdaptive bandwidth: 828 CV score: 1.357498e+13 \nAdaptive bandwidth: 518 CV score: 1.030751e+13 \nAdaptive bandwidth: 327 CV score: 8.348364e+12 \nAdaptive bandwidth: 208 CV score: 6.860544e+12 \nAdaptive bandwidth: 135 CV score: 5.969504e+12 \nAdaptive bandwidth: 89 CV score: 5.242221e+12 \nAdaptive bandwidth: 62 CV score: 4.742767e+12 \nAdaptive bandwidth: 43 CV score: 4.357839e+12 \nAdaptive bandwidth: 34 CV score: 4.125848e+12 \nAdaptive bandwidth: 25 CV score: 4.04299e+12 \nAdaptive bandwidth: 23 CV score: 1.549626e+13 \nAdaptive bandwidth: 30 CV score: 4.074906e+12 \nAdaptive bandwidth: 25 CV score: 4.04299e+12"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-predicted-values-of-the-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#computing-predicted-values-of-the-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.7 Computing predicted values of the test data",
    "text": "8.7 Computing predicted values of the test data\n\n8.7.1 Inspect the Spatial Coordinates\nWe need to confirm that your train_data_sp and test_data_sp objects have valid, non-empty spatial coordinates. We can check the coordinates using the below code chunk.\n\nhead(coordinates(train_data_sp))\n\n     coords.x1 coords.x2\n[1,]  39421.99  37094.13\n[2,]  36395.05  31714.45\n[3,]  41466.54  38691.58\n[4,]  35027.93  43052.26\n[5,]  27363.82  48032.56\n[6,]  28871.91  46265.93\n\nhead(coordinates(test_data_sp))\n\n     coords.x1 coords.x2\n[1,]  28423.42  39745.94\n[2,]  30550.38  39588.77\n[3,]  28240.06  39477.60\n[4,]  30637.92  39516.90\n[5,]  30347.48  38995.85\n[6,]  28325.75  39700.70\n\n\nThis will help us see if there are actual coordinate points in the data.\n\n\n8.7.2 Check for Overlapping Points\nOne common issue is that some points in your test_data_sp may not have corresponding points close enough in train_data_sp to perform GWR. This can happen if the test data points are outside the area covered by the training data.\nWe can check if test_data_sp points fall within the spatial extent of train_data_sp using the below code chunk.\n\nbbox(train_data_sp)\n\n               min      max\ncoords.x1 11597.31 42623.63\ncoords.x2 28217.39 48741.06\n\nbbox(test_data_sp)\n\n               min      max\ncoords.x1 11597.31 42623.63\ncoords.x2 28287.80 48669.59\n\n\nMake sure the bounding boxes (extents) of your training and test data overlap.\n\n\n8.7.3 Check if the Data is Too Sparse\nIf the data is very sparse or scattered, the selected bandwidth (bw=40) may be too small to cover any points for some locations. In such a case, we could:\n\nIncrease the bandwidth to cover more points.\nUse an adaptive bandwidth (adaptive=TRUE) with a larger range. This adapts the bandwidth to ensure each regression point has enough neighbors.\n\n\n\n8.7.4 Test a Small Sample\nWe could try using a smaller subset of your data (both train_data_sp and test_data_sp) to see if the issue is caused by a particular part of your dataset. We can randomly sample a few points for testing.\n\ntrain_sample &lt;- train_data_sp[sample(1:nrow(train_data_sp), 100), ]\ntest_sample &lt;- test_data_sp[sample(1:nrow(test_data_sp), 50), ]\n\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                                 floor_area_sqm + storey_order +\n                                 remaining_lease_mths + PROX_CBD + \n                                 PROX_ELDERLYCARE + PROX_HAWKER + \n                                 PROX_MRT + PROX_PARK + PROX_MALL + \n                                 PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                                 WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                                 WITHIN_1KM_PRISCH, \n                               data=train_sample, \n                               predictdata = test_sample, \n                               bw=40, \n                               kernel = 'gaussian', \n                               adaptive=TRUE, \n                               longlat = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#extracting-coordinates-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#extracting-coordinates-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "9.1 Extracting coordinates data",
    "text": "9.1 Extracting coordinates data\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nBefore continue, we write all the output into rds for future used.\n\ncoords_train &lt;- write_rds(coords_train, \"data/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/coords_test.rds\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#droping-geometry-field",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#droping-geometry-field",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "9.2 Droping geometry field",
    "text": "9.2 Droping geometry field\nFirst, we will drop geometry column of the sf data.frame by using st_drop_geometry() of sf package.\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#calibrating-using-training-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#calibrating-using-training-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "11.1 Calibrating using training data",
    "text": "11.1 Calibrating using training data\nThe code chunk below calibrate a geographic ranform forest model by using grf() of SpatialML package.\n\nset.seed(1234)\n\ntrain_sample &lt;- train_data[sample(1:nrow(train_data), 100), ]  # Select 100 random rows\ncoords_sample &lt;- coords_train[sample(1:nrow(coords_train), 100), ]\n\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                              remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                              PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                              PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                              WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                              WITHIN_1KM_PRISCH,\n                            dframe = train_sample, \n                            bw = 55,\n                            kernel = \"adaptive\",\n                            coords = coords_sample)\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_sample, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      100 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       5117322740 \nR squared (OOB):                  0.5755322 \n          floor_area_sqm             storey_order     remaining_lease_mths \n             73623908352             112564545878             193798920761 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            329190514912             126433351861              39908320280 \n                PROX_MRT                PROX_PARK                PROX_MALL \n             42929532875              44689246051              38006750535 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n             48269369872              11262414493              21472348287 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n             29833749925              21678554121 \n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-189841  -63195  -23035   -2356   44440  379786 \n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-30325.7  -7565.5  -2092.7    195.5   6405.0  61607.3 \n                                 Min          Max         Mean         StD\nfloor_area_sqm            8907048410  96411360080  33176223893 25087408764\nstorey_order             11505368822 219510158197  64939881876 70730929998\nremaining_lease_mths     15136295713 239825073747  90571950227 78264722831\nPROX_CBD                 70366740612 261668577980 149022125762 56418220920\nPROX_ELDERLYCARE         34654119694 128263862589  65856466959 25391719050\nPROX_HAWKER              14869195104  71395165481  39916329777 15933256621\nPROX_MRT                 10771637537  67817159573  27385395195 17259064961\nPROX_PARK                 9643476972  77520338798  33693368304 15507900524\nPROX_MALL                 9750435785  53908526850  25545868981  8769947166\nPROX_SUPERMARKET         18333010935  52013994587  30042093157  8325340144\nWITHIN_350M_KINDERGARTEN  2364872571  43471919780  10713251108  9122261123\nWITHIN_350M_CHILDCARE     6036843938  34196426417  14310495138  8430267554\nWITHIN_350M_BUS          10133623617  35951454792  19544963213  6010940660\nWITHIN_1KM_PRISCH         6774039313  45136073952  21724141890 11846915978\n\n\nLet’s save the model output by using the code chunk below.\n\nwrite_rds(gwRF_adaptive, \"data/gwRF_adaptive.rds\")\n\nThe code chunk below can be used to retrieve the save model in future.\n\ngwRF_adaptive &lt;- read_rds(\"data/gwRF_adaptive.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#predicting-by-using-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#predicting-by-using-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "11.2 Predicting by using test data",
    "text": "11.2 Predicting by using test data\n\n11.2.1 Preparing the test data\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n11.2.2 Predicting with test data\nNext, predict.grf() of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\nBefore moving on, let us save the output into rds file for future use.\n\nGRF_pred &lt;- write_rds(gwRF_pred, \"data/GRF_pred.rds\")\n\n\n\n11.2.3 Converting the predicting output into a data frame\nThe output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.\n\nGRF_pred &lt;- read_rds(\"data/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\nIn the code chunk below, cbind() is used to append the predicted values onto test_datathe\n\ntest_data_p &lt;- cbind(test_data, GRF_pred_df)\n\n\nwrite_rds(test_data_p, \"data/test_data_p.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#calculating-root-mean-square-error",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#calculating-root-mean-square-error",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "11.3 Calculating Root Mean Square Error",
    "text": "11.3 Calculating Root Mean Square Error\nThe root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\n\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n\n[1] 93600.15"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#visualising-the-predicted-values",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex8.html#visualising-the-predicted-values",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "11.4 Visualising the predicted values",
    "text": "11.4 Visualising the predicted values\nAlternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "",
    "text": "pacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse,\n               knitr)\nmdata &lt;- read_rds(\"data/mdata.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#correlation-matrix",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#correlation-matrix",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "2.1 Correlation Matrix",
    "text": "2.1 Correlation Matrix\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\nggstatsplot::ggcorrmat(mdata_nogeo[, 2:17])\n\n\n\n\n\n\n\n\nWhen building a predictive model, use only the training data for calibration, and later use the test data for evaluation. For an explanatory model, you can use all the data.\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16\n\nolsrr::ols_regress(price_mlr) # analyze a multiple linear regression model stored in price_mlr\n\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.859       RMSE                    61604.120 \nR-Squared                   0.737       MSE                3800583670.022 \nAdj. R-Squared              0.737       Coef. Var                  14.193 \nPred R-Squared              0.737       AIC                    257320.224 \nMAE                     47485.556       SBC                    257436.117 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares           DF       Mean Square       F          Sig. \n--------------------------------------------------------------------------------\nRegression    1.100899e+14           14      7.863561e+12     2069.04    0.0000 \nResidual      3.922202e+13        10320    3800583670.022                       \nTotal         1.493119e+14        10334                                         \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                 \n------------------------------------------------------------------------------------------------------------------\n                   model          Beta    Std. Error    Std. Beta       t        Sig          lower         upper \n------------------------------------------------------------------------------------------------------------------\n             (Intercept)    107601.073     10601.261                  10.150    0.000     86820.546    128381.599 \n          floor_area_sqm      2780.698        90.579        0.164     30.699    0.000      2603.146      2958.251 \n            storey_order     14299.298       339.115        0.234     42.167    0.000     13634.567     14964.029 \n    remaining_lease_mths       344.490         4.592        0.442     75.027    0.000       335.489       353.490 \n                PROX_CBD    -16930.196       201.254       -0.586    -84.124    0.000    -17324.693    -16535.700 \n        PROX_ELDERLYCARE    -14441.025       994.867       -0.079    -14.516    0.000    -16391.157    -12490.893 \n             PROX_HAWKER    -19265.648      1273.597       -0.083    -15.127    0.000    -21762.144    -16769.151 \n                PROX_MRT    -32564.272      1744.232       -0.105    -18.670    0.000    -35983.305    -29145.240 \n               PROX_PARK     -5712.625      1483.885       -0.021     -3.850    0.000     -8621.328     -2803.922 \n               PROX_MALL    -14717.388      2007.818       -0.044     -7.330    0.000    -18653.100    -10781.675 \n        PROX_SUPERMARKET    -26881.938      4189.624       -0.035     -6.416    0.000    -35094.414    -18669.462 \nWITHIN_350M_KINDERGARTEN      8520.472       632.812        0.072     13.464    0.000      7280.038      9760.905 \n   WITHIN_350M_CHILDCARE     -4510.650       354.015       -0.074    -12.741    0.000     -5204.589     -3816.711 \n         WITHIN_350M_BUS       813.493       222.574        0.020      3.655    0.000       377.205      1249.781 \n       WITHIN_1KM_PRISCH     -8010.834       491.512       -0.102    -16.298    0.000     -8974.293     -7047.376 \n------------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multicollinearity-check-with-vif",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multicollinearity-check-with-vif",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "2.2 Multicollinearity check with VIF",
    "text": "2.2 Multicollinearity check with VIF\n\nvif &lt;-performance::check_collinearity(price_mlr)\nkable(vif,\n       caption = \"Variance Inflation Factor (VIF) Results\") #%&gt;%\n\n\nVariance Inflation Factor (VIF) Results\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\n\nfloor_area_sqm\n1.126308\n1.104360\n1.152871\n1.061276\n0.8878567\n0.8673997\n0.9055016\n\n\nstorey_order\n1.206586\n1.181102\n1.235657\n1.098447\n0.8287846\n0.8092862\n0.8466672\n\n\nremaining_lease_mths\n1.363528\n1.331762\n1.398335\n1.167702\n0.7333919\n0.7151363\n0.7508850\n\n\nPROX_CBD\n1.905054\n1.852553\n1.960788\n1.380237\n0.5249196\n0.5099991\n0.5397957\n\n\nPROX_ELDERLYCARE\n1.178400\n1.154108\n1.206522\n1.085541\n0.8486080\n0.8288284\n0.8664703\n\n\nPROX_HAWKER\n1.187828\n1.163132\n1.216262\n1.089875\n0.8418729\n0.8221915\n0.8597474\n\n\nPROX_MRT\n1.240457\n1.213579\n1.270718\n1.113758\n0.8061545\n0.7869568\n0.8240092\n\n\nPROX_PARK\n1.195883\n1.170847\n1.224588\n1.093564\n0.8362021\n0.8166011\n0.8540825\n\n\nPROX_MALL\n1.409846\n1.376277\n1.446409\n1.187369\n0.7092975\n0.6913675\n0.7265978\n\n\nPROX_SUPERMARKET\n1.154751\n1.131493\n1.182124\n1.074594\n0.8659873\n0.8459353\n0.8837880\n\n\nWITHIN_350M_KINDERGARTEN\n1.125809\n1.103886\n1.152360\n1.061042\n0.8882499\n0.8677846\n0.9058910\n\n\nWITHIN_350M_CHILDCARE\n1.335594\n1.304923\n1.369351\n1.155679\n0.7487304\n0.7302729\n0.7663289\n\n\nWITHIN_350M_BUS\n1.148544\n1.125564\n1.175729\n1.071701\n0.8706679\n0.8505364\n0.8884435\n\n\nWITHIN_1KM_PRISCH\n1.550879\n1.511876\n1.592853\n1.245343\n0.6447958\n0.6278044\n0.6614298\n\n\n\n\n  #kable_styling(font_size = 18)\n\nAnything below 5 is acceptable.\n\nplot(vif)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\ntheme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 45\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#computing-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#computing-adaptive-bandwidth",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "3.1 Computing adaptive bandwidth",
    "text": "3.1 Computing adaptive bandwidth\nYou only need to run it once, save the result, and load it back in without rendering. The output is all that’s needed to fit into GWR.\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data, #Use the training data instead of the full dataset.\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nWhen calibrating the model, use bw_adaptive.\nMulticollinearity check with VIF\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,  #use training data\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ... \n\n\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ... \n\n\nUse a bandwidth of 40, the same as the training data.\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                          data=train_data_sp, \n                          predictdata = test_data_sp, \n                          bw=40, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          p = 2,\n                          theta = 0,\n                          longlat = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#preparing-coordinate-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#preparing-coordinate-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.1 Preparing coordinate data",
    "text": "4.1 Preparing coordinate data\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#dropping-geometry-field",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#dropping-geometry-field",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.2 Dropping geometry field",
    "text": "4.2 Dropping geometry field\n\ntrain_data_nogeom &lt;- train_data %&gt;% \n  st_drop_geometry # convert simpleframe to dataframe"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrating-rf-model",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrating-rf-model",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.3 Calibrating RF model",
    "text": "4.3 Calibrating RF model\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrating-with-grf",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrating-with-grf",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.4 Calibrating with grf()",
    "text": "4.4 Calibrating with grf()\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                              remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                              PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                              PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                              WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                              WITHIN_1KM_PRISCH,\n                            dframe = train_data_nogeom, \n                            bw = 55,\n                            kernel = \"adaptive\",\n                            coords = coords_train)\n\n\nNumber of Observations: 10335\n\n\nNumber of Independent Variables: 14\n\n\nKernel: Adaptive\nNeightbours: 55\n\n\n\n--------------- Global ML Model Summary ---------------\n\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       700081018 \nR squared (OOB):                  0.9515468 \n\n\n\nImportance:\n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.376510e+12             1.413229e+13             2.991844e+13 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            5.312697e+13             7.017513e+12             5.506719e+12 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.446857e+12             4.825986e+12             4.173165e+12 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            2.879598e+12             1.028775e+12             1.701318e+12 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            1.564038e+12             7.214027e+12 \n\n\n\nMean Square Error (Not OOB): 173279991.32\n\n\nR-squared (Not OOB) %: 98.801\n\n\nAIC (Not OOB): 196089.283\n\n\nAICc (Not OOB): 196089.33\n\n\n\n--------------- Local Model Summary ---------------\n\n\n\nResiduals OOB:\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-236112.0  -13033.7     444.4     593.8   14831.5  358041.7 \n\n\n\nResiduals Predicted (Not OOB):\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-79279.83  -3510.70     54.56     50.98   3909.85  83074.08 \n\n\n\nLocal Variable Importance:\n\n\n                               Min          Max        Mean         StD\nfloor_area_sqm                   0 401562922035 18210850992 41426270899\nstorey_order             302736445 243728744368 16368419468 23620589843\nremaining_lease_mths     696564138 546463600727 34119912443 70328183398\nPROX_CBD                  55173040 382484896335 12154563393 29293290548\nPROX_ELDERLYCARE          45182031 344081962746 10597657883 24546405941\nPROX_HAWKER               43516026 342597797419 10551807020 23408387903\nPROX_MRT                  54234551 299075025906  9873129985 21055852211\nPROX_PARK                 49919822 322633843469  9353956995 19517077658\nPROX_MALL                 43296133 433263607933 11247374493 27537334970\nPROX_SUPERMARKET          52665827 417310417234 10802122271 26572460731\nWITHIN_350M_KINDERGARTEN         0 186468064682  2848177740 12928886968\nWITHIN_350M_CHILDCARE            0 255236737234  5526292324 18109971102\nWITHIN_350M_BUS                  0 193828795378  4747552546 11886064288\nWITHIN_1KM_PRISCH                0 178360608427  1778262602  7163381668\n\n\n\nMean squared error (OOB): 930426169.333\n\n\nR-squared (OOB) %: 93.56\n\n\nAIC (OOB): 213459.669\n\n\nAICc (OOB): 213459.716\n\n\nMean squared error Predicted (Not OOB): 73859413.696\n\n\nR-squared Predicted (Not OOB) %: 99.489\n\n\nAIC Predicted (Not OOB): 187276.161\n\n\nAICc Predicted (Not OOB): 187276.208\n\n\n\nCalculation time (in seconds): 5.9621"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#preparing-the-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#preparing-the-test-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.1 Preparing the test data",
    "text": "5.1 Preparing the test data\n\ntest_data_nogeom &lt;- cbind(\n  test_data, coords_test) %&gt;% \n  st_drop_geometry()\n\nNote that the testing data has no geometry. If you ignore the previous step, you won’t obtain the x and y coordinates. If you do not combine it with coords_test, which contains the x and y coordinates, you will not be able to retrieve the x and y for this step."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predicting-with-the-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predicting-with-the-test-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.2 Predicting with the test data",
    "text": "5.2 Predicting with the test data\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive,\n                         test_data_nogeom,\n                         x.var.name=\"X\",\n                         y.var.name = \"Y\",\n                         local.w = 1,\n                         global.w = 0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#creating-df",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#creating-df",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.3 Creating DF",
    "text": "5.3 Creating DF\n\nGRF_pred &lt;- read_rds(\"data/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\ntest_data_pred &lt;- cbind(test_data, GRF_pred_df)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#deriving-queens-contiguity-weights-sfdep-methods",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#deriving-queens-contiguity-weights-sfdep-methods",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "9.1 Deriving Queen’s contiguity weights: sfdep methods",
    "text": "9.1 Deriving Queen’s contiguity weights: sfdep methods\n\n#wm_q &lt;- tourism_st %&gt;%\n  #mutate(nb = st_contiguity(geometry),\n         #wt = st_weights(nb, style = \"W\"),\n         #.before = 1)\n\n\n#wm_q &lt;- tourism_sf %&gt;%\n  #mutate(nb = st_contiguity(geometry),\n       #  wt = st_weights(nb, style = \"W\")) %&gt;%\n#  select(nb, wt, everything()) \n\n\n#tourism_q &lt;- st_contiguity (tourism_sf, queen=TRUE)\n#summary(wm_q)\n\n\n#tourism_wm_rs &lt;- st_weights(tourism_q, style=\"W\")\n\n\n#wm_q &lt;- tourism_sf %&gt;%\n # mutate(nb = tourism_q,\n   #      wt = tourism_wm_rs,\n   #      .before = 1) \n\n\n#wm_q"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-global-moran-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-global-moran-i",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "9.2 Computing Global Moran’ I",
    "text": "9.2 Computing Global Moran’ I\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from spdep package, the output is a tibble data.frame.\n\n#moranI &lt;- global_moran(wm_q$revenue_all,\n      #                 wm_q$nb,\n      #                 wm_q$wt)\n#glimpse(moranI)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-global-moransi-test",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-global-moransi-test",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "9.3 Performing Global Moran’sI test",
    "text": "9.3 Performing Global Moran’sI test\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\n#global_moran_test(wm_q$revenue_all,\n            #      wm_q$nb,\n           #       wm_q$wt)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#global-morani-permutation-test",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#global-morani-permutation-test",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "9.4 Global Moran’I permutation test",
    "text": "9.4 Global Moran’I permutation test\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\n#global_moran_perm(wm_q$revenue_all,\n             #     wm_q$nb,\n             #     wm_q$wt,\n             #     nsim =99)\n\nThe statistical report on previous tab shows that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of total revenue are resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n# Global Moran's I for tourism data\n#global_moran_test &lt;- tourism_sf %&gt;%\n  #global_moran(variable = \"no_tourist_all\", nb = tourism_neighbors)\n\n# Print the results\n#global_moran_test"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-morans-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-morans-i",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "10.1 Computing local Moran’s I",
    "text": "10.1 Computing local Moran’s I\nIn this section, we compute Local Moran’s I of total revenue at province level by using local_moran() of sfdep package.\n\n#lisa &lt;- wm_q %&gt;%\n # mutate(local_moran = local_moran(\n  #  revenue_all, nb, wt, nsim = 99),\n  #  .before = 1) %&gt;%\n # unnest(local_moran)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-local-morans-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-local-morans-i",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "10.2 Visualising local Moran’s I",
    "text": "10.2 Visualising local Moran’s I\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\n#tmap_mode(\"plot\")\n#tm_shape(lisa) +\n # tm_fill(\"ii\") +\n  #tm_borders(alpha = 0.5) +\n # tm_facets(\"Month_year\") +\n # tm_view(set.zoom.limits = c(6,8)) +\n # tm_layout(\n  #  main.title = \"local Moran's I of Total Revenue\",\n  #  main.title.size = 2)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-p-value-of-local-morans-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-p-value-of-local-morans-i",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "10.3 Visualising p-value of local Moran’s I",
    "text": "10.3 Visualising p-value of local Moran’s I\n\n#tmap_mode(\"plot\")\n#tm_shape(lisa) +\n  #tm_fill(\"p_ii_sim\") +\n  #tm_borders(alpha = 0.5) +\n  #tm_facets(\"Month_year\") +\n  #tm_layout(\n  #  main.title = \"p-values of local Moran's I\",\n  #  main.title.size = 2)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-local-morans-i-and-p-value",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-local-morans-i-and-p-value",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "10.4 Visualising local Moran’s I and p-value",
    "text": "10.4 Visualising local Moran’s I and p-value\n\n#tmap_mode(\"plot\")\n#map1 &lt;- tm_shape(lisa) +\n#  tm_fill(\"ii\") + \n # tm_borders(alpha = 0.5) +\n # tm_facets(\"Month_year\") +\n # tm_view(set.zoom.limits = c(6,8)) +\n # tm_layout(main.title = \"local Moran's I of Total Revenue\",\n   #         main.title.size = 0.8)\n\n#map2 &lt;- tm_shape(lisa) +\n  #tm_fill(\"p_ii\",\n   #       breaks = c(0, 0.001, 0.01, 0.05, 1),\n    #          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n # tm_borders(alpha = 0.5) +\n#  tm_facets(\"Month_year\") +\n#  tm_layout(main.title = \"p-value of local Moran's I\",\n         #   main.title.size = 0.8)\n\n#tmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#plotting-lisa-map",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#plotting-lisa-map",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "10.5 Plotting LISA map",
    "text": "10.5 Plotting LISA map\n\n#lisa_sig &lt;- lisa %&gt;%\n # filter(p_ii &lt; 0.05) #filter only significant p values\n\n#tmap_mode(\"plot\")\n#tm_shape(lisa)+\n # tm_polygons()+\n # tm_borders(alpha=0.5)+\n#tm_shape(lisa_sig)+\n#  tm_fill(\"mean\")+\n#  tm_borders(alpha=0.4)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-gi-statistics",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-gi-statistics",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "10.6 Computing local Gi* statistics",
    "text": "10.6 Computing local Gi* statistics\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\n#wm_idw &lt;- revenue_all_sf %&gt;% \n # mutate(nb = st_contiguity(geometry) ,\n     #    wts = st_inverse_distance(nb, geometry,\n       #                           scale = 1,\n       #                           alpha =1),\n       #  .before = 1)\n\n\n#wm_idw &lt;- revenue_all_sf %&gt;%\n # mutate(nb = include_self(\n  #  st_contiguity(geometry)),\n  #  wts = st_inverse_distance(nb, \n        #                      geometry, \n        #                      scale = 1,\n        #                      alpha = 1),\n        # .before = 1)\n\nNow, we will compute the local Gi* by using the code chunk below.\n\n# HCSA &lt;- wm_idw %&gt;% \n  #mutate(local_Gi = local_gstar_perm(\n   #revenue_all, nb, wts, nsim = 99),\n    #     .before = 1) %&gt;%\n # unnest(local_Gi)\n#HCSA\n\n\n10.6.1 Visualising Gi*\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\n#tmap_mode(\"plot\")\n#tm_shape(HCSA)+\n#  tm_fill(\"gi_star\")+\n#  tm_borders(alpha = 0.5) +\n # tm_view(set.zoom.limits = c(6,8))\n\n\n\n10.6.2 Visualising p-value of HCSA\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\n#tmap_mode(\"plot\")\n#tm_shape(HCSA) +\n # tm_fill(\"p_sim\") + \n # tm_borders(alpha = 0.5)\n\n\n\n10.6.3 Visuaising local HCSA\n\n# tmap_mode(\"plot\")\n#map1 &lt;- tm_shape(HCSA) +\n#  tm_fill(\"gi_star\") + \n # tm_borders(alpha = 0.5) +\n # tm_view(set.zoom.limits = c(6,8)) +\n # tm_layout(main.title = \"Gi* of GDPPC\",\n   #         main.title.size = 0.8)\n\n#map2 &lt;- tm_shape(HCSA) +\n # tm_fill(\"p_value\",\n  #        breaks = c(0, 0.001, 0.01, 0.05, 1),\n     #         labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n#  tm_borders(alpha = 0.5) +\n#  tm_layout(main.title = \"p-value of Gi*\",\n   #         main.title.size = 0.8)\n\n#tmap_arrange(map1, map2, ncol = 2)\n\n\n\n10.6.4 Visualising hot spot and cold spot areas\n\n#HCSA_sig &lt;- HCSA  %&gt;%\n # filter(p_sim &lt; 0.05)\n#tmap_mode(\"plot\")\n#tm_shape(HCSA) +\n # tm_polygons() +\n # tm_borders(alpha = 0.5) +\n#tm_shape(HCSA_sig) +\n # tm_fill(\"cluster\") + \n  #tm_borders(alpha = 0.4)\n\nFigure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-gi",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-gi",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.1 Computing Gi*",
    "text": "11.1 Computing Gi*\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\n#tourism_nb &lt;- tourism_st %&gt;% \n#  activate(\"geometry\") %&gt;% # activate the geometry context\n # mutate(nb = include_self( #mutate to create two new columns nb and wt, include itself\n  #  st_contiguity(geometry)),\n  #  wt = st_inverse_distance(nb,\n     #                        geometry,\n     #                        scale = 1,\n      #                       alpha = 1),\n  #  .before = 1) %&gt;% #new derived variable in front of the table\n  #set_nbs(\"nb\") %&gt;% \n  #set_wts(\"wt\")\n\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\n#gi_stars &lt;- tourism_nb %&gt;% \n # group_by(Year) %&gt;% \n # mutate(gi_star = local_gstar_perm(\n #   revenue_all, nb, wt)) %&gt;% \n # tidyr::unnest(gi_star)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#mann-kendall-test-of-gi",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#mann-kendall-test-of-gi",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.2 Mann-Kendall Test of GI",
    "text": "11.2 Mann-Kendall Test of GI\nWith these Gi* measures we can then evaluate each location for a trend using the Mann-Kendall test. The code chunk below uses Changsha county.\nA monotonic series or function is one that only increases (or decreases) and never changes direction. So long as the function either stays flat or continues to increase, it is monotonic.\nH0: No monotonic trend\nH1: Monotonic trend is present\nInterpretation\n\nReject the null-hypothesis null if the p-value is smaller than the alpha value (i.e. 1-confident level)\nTau ranges between -1 and 1 where:\n\n-1 is a perfectly decreasing series, and\n1 is a perfectly increasing series.\n\n\n\n#cbg &lt;- gi_stars %&gt;% \n # ungroup () %&gt;% \n # filter(province_eng == \"Bangkok\") %&gt;%\n # select(province_eng, Year, gi_star)\n\nNext, we plot the result by using ggplot2 functions.\n\n#ggplot(data = cbg,\n    #   aes(x = Year,\n    #       y = gi_star)) +\n#  geom_line() +\n#  theme_light()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#interactive-mann-kendall-plot",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#interactive-mann-kendall-plot",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.3 Interactive Mann-Kendall Plot",
    "text": "11.3 Interactive Mann-Kendall Plot\nWe can also create an interactive plot by using ggplotly() of plotly package.\n\n#gp &lt;- ggplot(data = cbg,\n #           aes(x = Year,\n  #              y = gi_star))+\n # geom_line()+\n#  theme_light()\n\n#ggplotly(p)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#printing-mann-kendall-test-report",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#printing-mann-kendall-test-report",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.4 Printing Mann-Kendall test report",
    "text": "11.4 Printing Mann-Kendall test report\n\n#cbg %&gt;% \n # summarise(mk = list(\n  #  unclass(\n  #    Kendall::MannKendall(gi_star)))) %&gt;% \n # tidyr::unnest_wider(mk)\n\nIn the above result, sl is the p-value. With reference to the results, we will reject the hypothesis null and infer that a slight upward trend."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#mann-kendall-test-data.frame",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#mann-kendall-test-data.frame",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.5 Mann-Kendall test data.frame",
    "text": "11.5 Mann-Kendall test data.frame\nWe can replicate this for each location by using group_by() of dplyr package.\n\n#ehsa &lt;- gi_stars %&gt;% \n # group_by(province_eng) %&gt;% \n # summarise(mk = list(\n #   unclass(\n #     Kendall::MannKendall(gi_star)))) %&gt;% \n # tidyr::unnest_wider(mk)\n# head(ehsa)\n\nWe can also sort to show significant emerging hot/cold spots\n\n#emerging &lt;- ehsa %&gt;% \n # arrange(sl, abs(tau)) %&gt;% \n # slice(1:10)\n#head(emerging)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-emerging-hotspot-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-emerging-hotspot-analysis",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.6 Performing Emerging Hotspot Analysis",
    "text": "11.6 Performing Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. Total Revenue) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\n#ehsa &lt;- emerging_hotspot_analysis(\n # x = tourism_st,\n # .var = \"GDPPC\",\n#  k = 1,\n#  nsim = 99\n#)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-the-distribution-of-ehsa-classes",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-the-distribution-of-ehsa-classes",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.7 Visualising the distribution of EHSA classes",
    "text": "11.7 Visualising the distribution of EHSA classes\nIn the code chunk below, ggplot2 functions is used to reveal the distribution of EHSA classes as a bar chart.\n\n#ggplot(data = ehsa,\n #      aes(x = classification)) +\n # geom_bar()\n\nFigure above shows that sporadic cold spots class has the high numbers of county."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-ehsa",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-ehsa",
    "title": "Take Home Exercise 2 : Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "11.8 Visualising EHSA",
    "text": "11.8 Visualising EHSA\n\n#tourism_ehsa &lt;- tourism_st %&gt;% \n#  left_join(ehsa,\n  #          by = join_by(province_ == location))\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\n#tourism_sig &lt;- tourism_ehsa %&gt;%\n#  filter(p_value &lt; 0.05)\n#tmap_mode(\"plot\")\n#tm_shape(hunan_ehsa) +\n#  tm_polygons()+\n#  tm_borders(alpha = 0.5) +\n#tm_shape(ehsa_sig)+\n#  tm_fill(\"classification\")+\n#  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able:\n\nto import GIS polygon data into R and save them as simple feature data frame by using appropriate functions of sf package of R;\nto import aspatial data into R and save them as simple feature data frame by using appropriate functions of sf package of R;\nto computer accessibility measure by using Hansen’s potential model and Spatial Accessibility Measure (SAM); and\nto visualise the accessibility measures by using tmap and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#importing-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.1 Importing geospatial data",
    "text": "4.1 Importing geospatial data\nThree geospatial data will be imported from the data/geospatial sub-folder. They are MP14_SUBZONE_NO_SEA_PL, hexagons and ELDERCARE.\nThe code chunk below is used to import these three data sets shapefile by using st_read() of sf packages.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands_on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\", layer = \"hexagons\") \n\nReading layer `hexagons' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands_on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\n\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") \n\nReading layer `ELDERCARE' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands_on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#updating-crs-information",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.2 Updating CRS information",
    "text": "4.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz &lt;- st_transform(mpsz, 3414)\neldercare &lt;- st_transform(eldercare, 3414)\nhexagons &lt;- st_transform(hexagons, 3414)\n\nAfter transforming the projection metadata, you can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.3 Cleaning and updating attribute fields of the geospatial data",
    "text": "4.3 Cleaning and updating attribute fields of the geospatial data\nThere are many redundant fields in the data tables of both eldercare and hexagons. The code chunks below will be used to exclude those redundant fields. At the same time, a new field called demand and a new field called capacity will be added into the data table of hexagons and eldercare sf data frame respectively. Both fields are derive using mutate() of dplyr package.\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\nNotice that for the purpose of this hands-on exercise, a constant value of 100 is used. In practice, actual demand of the hexagon and capacity of the eldercare centre should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#importing-distance-matrix",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#importing-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.1 Importing Distance Matrix",
    "text": "5.1 Importing Distance Matrix\nThe code chunk below uses read_cvs() of readr package to import OD_Matrix.csv into RStudio. The imported object is a tibble data.frame called ODMatrix.\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#tidying-distance-matrix",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#tidying-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.2 Tidying distance matrix",
    "text": "5.2 Tidying distance matrix\nThe imported ODMatrix organised the distance matrix columnwise.\n\nOn the other hands, most of the modelling packages in R is expecting a matrix look similar to the figure below.\n\nThe rows represent origins (i.e. also know as from field) and the columns represent destination (i.e. also known as to field.)\nThe code chunk below uses spread() of tidyr package is used to transform the O-D matrix from a thin format into a fat format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\nNote: Since tidyr version 1.0 a new function called pivot_wider() is introduce. You should use pivot_wider() instead of spread()\nCurrently, the distance is measured in metre because SVY21 projected coordinate system is used. The code chunk below will be used to convert the unit f measurement from metre to kilometre.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#computing-hansens-accessibility",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#computing-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.1 Computing Hansen’s accessibility",
    "text": "6.1 Computing Hansen’s accessibility\nNow, we ready to compute Hansen’s accessibility by using ac() of SpatialAcc package. Before getting started, you are encourage to read the arguments of the function at least once in order to ensure that the required inputs are available.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_Handsen.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\nThe default field name is very messy, we will rename it to accHansen by using the code chunk below.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nNotice that the field name is much more tidier now.\n\nNext, we will convert the data table into tibble format by using the code chunk below.\n\n# acc_Hansen &lt;- tbl_df(acc_Hansen)\nacc_Hansen &lt;- tibble::as_tibble(acc_Hansen)\n\nLastly, bind_cols() of dplyr will be used to join the acc_Hansen tibble data frame with the hexagons simple feature data frame. The output is called hexagon_Hansen.\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\nNotice that hexagon_Hansen is a simple feature data frame and not a typical tibble data frame.\n\nActually, the steps above can be perform by using a single code chunk as shown below.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n# acc_Hansen &lt;- tbl_df(acc_Hansen)\nacc_Hansen &lt;- tibble::as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#visualising-hansens-accessibility",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#visualising-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.2 Visualising Hansen’s accessibility",
    "text": "6.2 Visualising Hansen’s accessibility\n\n6.2.1 Extracting map extend\nFirstly, we will extract the extend of hexagons simple feature data frame by by using st_bbox() of sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.3 Statistical graphic visualisation",
    "text": "6.3 Statistical graphic visualisation\nIn this section, we are going to compare the distribution of Hansen’s accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into haxegon_Hansen simple feature data frame by using the code chunk below.\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#computing-kd2sfcas-accessibility",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#computing-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.1 Computing KD2SFCA’s accessibility",
    "text": "7.1 Computing KD2SFCA’s accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_KD2SFCA. Notice that KD2SFCA is used for family argument.\n\n# Calculate accessibility score and store in a data frame\nacc_KD2SFCA &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"KD2SFCA\"))\n\n# Rename column and convert to tibble\ncolnames(acc_KD2SFCA) &lt;- \"accKD2SFCA\"\n#acc_KD2SFCA &lt;- tbl_df(acc_KD2SFCA)\nacc_KD2SFCA &lt;- tibble::as_tibble(acc_KD2SFCA)\n\n# Bind columns to create hexagon_KD2SFCA\nhexagon_KD2SFCA &lt;- bind_cols(hexagons, acc_KD2SFCA)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_KD2SFCA,\n         bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: KD2SFCA method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-1",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-1",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.3 Statistical graphic visualisation",
    "text": "7.3 Statistical graphic visualisation\nNow, we are going to compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code chunk below.\n\nhexagon_KD2SFCA &lt;- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#computing-sam-accessibility",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#computing-sam-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.1 Computing SAM accessibility",
    "text": "8.1 Computing SAM accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_SAM. Notice that SAM is used for family argument.\n\n# Calculate accessibility score and store in a data frame\nacc_SAM &lt;- data.frame(ac(hexagons$demand,\n                         eldercare$capacity,\n                         distmat_km, \n                         d0 = 50,\n                         power = 2, \n                         family = \"SAM\"))\n\n# Rename column and convert to tibble\ncolnames(acc_SAM) &lt;- \"accSAM\"\n#acc_SAM &lt;- tbl_df(acc_SAM)\nacc_SAM &lt;- tibble::as_tibble(acc_SAM)\n\n# Bind columns to create hexagon_SAM\nhexagon_SAM &lt;- bind_cols(hexagons, acc_SAM)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#visualising-sams-accessibility",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#visualising-sams-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.2 Visualising SAM’s accessibility",
    "text": "8.2 Visualising SAM’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_SAM,\n         bbox = mapex) + \n  tm_fill(col = \"accSAM\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: SAM method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 3),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-2",
    "href": "Hands-on_Ex/Hands_on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-2",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.3 Statistical graphic visualisation",
    "text": "8.3 Statistical graphic visualisation\nNow, we are going to compare the distribution of SAM accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_SAM simple feature data frame by using the code chunk below.\n\nhexagon_SAM &lt;- st_join(hexagon_SAM, mpsz, \n                       join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, \n           x= REGION_N)) +\n  geom_boxplot() +\n  stat_summary(fun = \"mean\", \n               geom = \"point\", \n               colour = \"red\", \n               size = 2)\n\n\n\n\n\n\n\n  #geom_point(stat=\"summary\", \n             #fun.y=\"mean\", \n             #colour =\"red\", \n             #size=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able:\n\nto import GIS polygon data into R and save them as simple feature data frame by using appropriate functions of sf package of R;\nto import aspatial data into R and save them as simple feature data frame by using appropriate functions of sf package of R;\nto computer accessibility measure by using Hansen’s potential model and Spatial Accessibility Measure (SAM); and\nto visualise the accessibility measures by using tmap and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#importing-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.1 Importing geospatial data",
    "text": "4.1 Importing geospatial data\nThree geospatial data will be imported from the data/geospatial sub-folder. They are MP14_SUBZONE_NO_SEA_PL, hexagons and ELDERCARE.\nThe code chunk below is used to import these three data sets shapefile by using st_read() of sf packages.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\", layer = \"hexagons\") \n\nReading layer `hexagons' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\n\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") \n\nReading layer `ELDERCARE' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#updating-crs-information",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.2 Updating CRS information",
    "text": "4.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz &lt;- st_transform(mpsz, 3414)\neldercare &lt;- st_transform(eldercare, 3414)\nhexagons &lt;- st_transform(hexagons, 3414)\n\nAfter transforming the projection metadata, you can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.3 Cleaning and updating attribute fields of the geospatial data",
    "text": "4.3 Cleaning and updating attribute fields of the geospatial data\nThere are many redundant fields in the data tables of both eldercare and hexagons. The code chunks below will be used to exclude those redundant fields. At the same time, a new field called demand and a new field called capacity will be added into the data table of hexagons and eldercare sf data frame respectively. Both fields are derive using mutate() of dplyr package.\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\nNotice that for the purpose of this hands-on exercise, a constant value of 100 is used. In practice, actual demand of the hexagon and capacity of the eldercare centre should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#importing-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#importing-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.1 Importing Distance Matrix",
    "text": "5.1 Importing Distance Matrix\nThe code chunk below uses read_cvs() of readr package to import OD_Matrix.csv into RStudio. The imported object is a tibble data.frame called ODMatrix.\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#tidying-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#tidying-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.2 Tidying distance matrix",
    "text": "5.2 Tidying distance matrix\nThe imported ODMatrix organised the distance matrix columnwise.\n\nOn the other hands, most of the modelling packages in R is expecting a matrix look similar to the figure below.\n\nThe rows represent origins (i.e. also know as from field) and the columns represent destination (i.e. also known as to field.)\nThe code chunk below uses spread() of tidyr package is used to transform the O-D matrix from a thin format into a fat format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\nNote: Since tidyr version 1.0 a new function called pivot_wider() is introduce. You should use pivot_wider() instead of spread()\nCurrently, the distance is measured in metre because SVY21 projected coordinate system is used. The code chunk below will be used to convert the unit f measurement from metre to kilometre.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#computing-hansens-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#computing-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.1 Computing Hansen’s accessibility",
    "text": "6.1 Computing Hansen’s accessibility\nNow, we ready to compute Hansen’s accessibility by using ac() of SpatialAcc package. Before getting started, you are encourage to read the arguments of the function at least once in order to ensure that the required inputs are available.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_Handsen.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\n\nThe default field name is very messy, we will rename it to accHansen by using the code chunk below.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nNotice that the field name is much more tidier now.\n\nNext, we will convert the data table into tibble format by using the code chunk below.\n\n# acc_Hansen &lt;- tbl_df(acc_Hansen)\nacc_Hansen &lt;- tibble::as_tibble(acc_Hansen)\n\nLastly, bind_cols() of dplyr will be used to join the acc_Hansen tibble data frame with the hexagons simple feature data frame. The output is called hexagon_Hansen.\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\nNotice that hexagon_Hansen is a simple feature data frame and not a typical tibble data frame.\n\nActually, the steps above can be perform by using a single code chunk as shown below.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n# acc_Hansen &lt;- tbl_df(acc_Hansen)\nacc_Hansen &lt;- tibble::as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#visualising-hansens-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#visualising-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.2 Visualising Hansen’s accessibility",
    "text": "6.2 Visualising Hansen’s accessibility\n\n6.2.1 Extracting map extend\nFirstly, we will extract the extend of hexagons simple feature data frame by by using st_bbox() of sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.3 Statistical graphic visualisation",
    "text": "6.3 Statistical graphic visualisation\nIn this section, we are going to compare the distribution of Hansen’s accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into haxegon_Hansen simple feature data frame by using the code chunk below.\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#computing-kd2sfcas-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#computing-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.1 Computing KD2SFCA’s accessibility",
    "text": "7.1 Computing KD2SFCA’s accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_KD2SFCA. Notice that KD2SFCA is used for family argument.\n\n# Calculate accessibility score and store in a data frame\nacc_KD2SFCA &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"KD2SFCA\"))\n\n# Rename column and convert to tibble\ncolnames(acc_KD2SFCA) &lt;- \"accKD2SFCA\"\n#acc_KD2SFCA &lt;- tbl_df(acc_KD2SFCA)\nacc_KD2SFCA &lt;- tibble::as_tibble(acc_KD2SFCA)\n\n# Bind columns to create hexagon_KD2SFCA\nhexagon_KD2SFCA &lt;- bind_cols(hexagons, acc_KD2SFCA)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_KD2SFCA,\n         bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: KD2SFCA method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-1",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.3 Statistical graphic visualisation",
    "text": "7.3 Statistical graphic visualisation\nNow, we are going to compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code chunk below.\n\nhexagon_KD2SFCA &lt;- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#computing-sam-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#computing-sam-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.1 Computing SAM accessibility",
    "text": "8.1 Computing SAM accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_SAM. Notice that SAM is used for family argument.\n\n# Calculate accessibility score and store in a data frame\nacc_SAM &lt;- data.frame(ac(hexagons$demand,\n                         eldercare$capacity,\n                         distmat_km, \n                         d0 = 50,\n                         power = 2, \n                         family = \"SAM\"))\n\n# Rename column and convert to tibble\ncolnames(acc_SAM) &lt;- \"accSAM\"\n#acc_SAM &lt;- tbl_df(acc_SAM)\nacc_SAM &lt;- tibble::as_tibble(acc_SAM)\n\n# Bind columns to create hexagon_SAM\nhexagon_SAM &lt;- bind_cols(hexagons, acc_SAM)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#visualising-sams-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#visualising-sams-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.2 Visualising SAM’s accessibility",
    "text": "8.2 Visualising SAM’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_SAM,\n         bbox = mapex) + \n  tm_fill(col = \"accSAM\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: SAM method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 3),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-2",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex9.html#statistical-graphic-visualisation-2",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.3 Statistical graphic visualisation",
    "text": "8.3 Statistical graphic visualisation\nNow, we are going to compare the distribution of SAM accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_SAM simple feature data frame by using the code chunk below.\n\nhexagon_SAM &lt;- st_join(hexagon_SAM, mpsz, \n                       join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, \n           x= REGION_N)) +\n  geom_boxplot() +\n  stat_summary(fun = \"mean\", \n               geom = \"point\", \n               colour = \"red\", \n               size = 2)\n\n\n\n\n\n\n\n  #geom_point(stat=\"summary\", \n             #fun.y=\"mean\", \n             #colour =\"red\", \n             #size=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class Exercise 09",
    "section": "",
    "text": "pacman::p_load(tmap, SpatialAcc, sf, \n               ggstatsplot, reshape2,\n               tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#geospatial-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#geospatial-data",
    "title": "In-class Exercise 09",
    "section": "3.1 Geospatial Data",
    "text": "3.1 Geospatial Data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_NO_SEA_PL\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\", \n                    layer = \"hexagons\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `hexagons' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", \n                     layer = \"ELDERCARE\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `ELDERCARE' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#od-matrix",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#od-matrix",
    "title": "In-class Exercise 09",
    "section": "3.2 OD Matrix",
    "text": "3.2 OD Matrix\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", \n                     skip = 0)\n\nRows: 375000 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): origin_id, destination_id, entry_cost, network_cost, exit_cost, tot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# entry = the entry point\n# network = distance from the start to the end\n# exit = the exit point"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#supply",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#supply",
    "title": "In-class Exercise 09",
    "section": "4.1 Supply",
    "text": "4.1 Supply\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#demand",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#demand",
    "title": "In-class Exercise 09",
    "section": "4.2 Demand",
    "text": "4.2 Demand\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#od-matrix-1",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#od-matrix-1",
    "title": "In-class Exercise 09",
    "section": "4.3 OD Matrix",
    "text": "4.3 OD Matrix\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#the-base-code",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#the-base-code",
    "title": "In-class Exercise 09",
    "section": "5.1 The base code",
    "text": "5.1 The base code\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50, set to constraints\n                            power = 2, \n                            family = \"Hansen\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#tidy-the-output",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#tidy-the-output",
    "title": "In-class Exercise 09",
    "section": "5.2 Tidy the output",
    "text": "5.2 Tidy the output\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\n# acc_Hansen &lt;- tbl_df(acc_Hansen)\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#combine-code-chunk",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#combine-code-chunk",
    "title": "In-class Exercise 09",
    "section": "5.3 Combine code chunk",
    "text": "5.3 Combine code chunk\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n# acc_Hansen &lt;- tbl_df(acc_Hansen)\n# acc_Hansen &lt;- tibble::as_tibble(acc_Hansen)\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#the-code",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#the-code",
    "title": "In-class Exercise 09",
    "section": "2.1 The Code",
    "text": "2.1 The Code\nELDERCARE is in shapefile format, the code chunk below will be used:\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", \n                     layer = \"ELDERCARE\") %&gt;% \n  st_transform(crs = 3414)\n\nReading layer `ELDERCARE' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\nThe code chunk below is used to import kml file.\n\nCHAS &lt;- st_read(\"data/rawdata/CHASClinics.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\In-class_Ex\\In-class_Ex09\\data\\rawdata\\CHASClinics.kml' \n  using driver `KML'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#buffering",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#buffering",
    "title": "In-class Exercise 09",
    "section": "2.2 Buffering",
    "text": "2.2 Buffering\nNext, st_buffer() of sf package is used to create a buffer of 1km around each eldercare features\n\nbuffer_1km &lt;- st_buffer(eldercare, \n                        dist = 1000)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualising",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualising",
    "title": "In-class Exercise 09",
    "section": "2.3 Visualising",
    "text": "2.3 Visualising\nThe code chunk below is used to plot the newly created buffers and the CHAS clinics.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(buffer_1km) +\n  tm_polygons() +\ntm_shape(CHAS) +\n  tm_dots()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#counting-points",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#counting-points",
    "title": "In-class Exercise 09",
    "section": "2.4 Counting points",
    "text": "2.4 Counting points\nLastly, the code chunk below is used to count the number of CHAS clinics with 1km of each eldercare centre.\n\nbuffer_1km$pts_count &lt;- lengths(\n  st_intersects(buffer_1km, CHAS))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#the-code-1",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#the-code-1",
    "title": "In-class Exercise 09",
    "section": "6.1 The Code",
    "text": "6.1 The Code\n\nmapex &lt;- st_bbox(hexagons)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#statistical-graphic",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#statistical-graphic",
    "title": "In-class Exercise 09",
    "section": "6.2 Statistical graphic",
    "text": "6.2 Statistical graphic\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\n\nggbetweenstats(\n  data = hexagon_Hansen,\n  x = REGION_N,\n  y = accHansen,\n  type = \"p\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "",
    "text": "pacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse,\n               knitr, kableExtra)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "",
    "text": "pacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse,\n               knitr, kableExtra)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#vif",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#vif",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "6.1 VIF",
    "text": "6.1 VIF\n\nvif &lt;- performance::check_collinearity(price_mlr)\nkable(vif, \n      caption = \"Variance Inflation Factor (VIF) Results\") %&gt;%\n  kable_styling(font_size = 18) \n\n\nVariance Inflation Factor (VIF) Results\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\n\nfloor_area_sqm\n1.146686\n1.085743\n1.250945\n1.070834\n0.8720785\n0.7993954\n0.9210287\n\n\nstorey_order\n1.206020\n1.135720\n1.312734\n1.098189\n0.8291736\n0.7617690\n0.8804986\n\n\nremaining_lease_mths\n1.343645\n1.254833\n1.463410\n1.159157\n0.7442440\n0.6833358\n0.7969186\n\n\nPROX_CBD\n1.887898\n1.733977\n2.074096\n1.374008\n0.5296898\n0.4821378\n0.5767088\n\n\nPROX_ELDERLYCARE\n1.140418\n1.080572\n1.244716\n1.067904\n0.8768712\n0.8033960\n0.9254357\n\n\nPROX_HAWKER\n1.183865\n1.116887\n1.289223\n1.088056\n0.8446907\n0.7756609\n0.8953457\n\n\nPROX_MRT\n1.211390\n1.140307\n1.318485\n1.100632\n0.8254980\n0.7584464\n0.8769566\n\n\nPROX_PARK\n1.186122\n1.118797\n1.291599\n1.089092\n0.8430839\n0.7742340\n0.8938169\n\n\nPROX_MALL\n1.435504\n1.335252\n1.565736\n1.198125\n0.6966193\n0.6386771\n0.7489224\n\n\nPROX_SUPERMARKET\n1.226727\n1.153448\n1.335000\n1.107577\n0.8151773\n0.7490638\n0.8669656\n\n\nWITHIN_350M_KINDERGARTEN\n1.123989\n1.067172\n1.228865\n1.060183\n0.8896886\n0.8137594\n0.9370564\n\n\nWITHIN_350M_CHILDCARE\n1.387119\n1.292841\n1.511748\n1.177760\n0.7209189\n0.6614860\n0.7734902\n\n\nWITHIN_350M_BUS\n1.193498\n1.125056\n1.299398\n1.092473\n0.8378731\n0.7695869\n0.8888447\n\n\nWITHIN_1KM_PRISCH\n1.508943\n1.399770\n1.647930\n1.228390\n0.6627154\n0.6068219\n0.7144029"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#plotting-vif",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#plotting-vif",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "6.2 Plotting VIF",
    "text": "6.2 Plotting VIF\n\nplot(vif) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nVariable `Component` is not in your data frame :/"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#computing-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#computing-adaptive-bandwidth",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "7.1 Computing adaptive bandwidth",
    "text": "7.1 Computing adaptive bandwidth\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nAdaptive bandwidth: 625 CV score: 3.459032e+12 \nAdaptive bandwidth: 394 CV score: 3.231786e+12 \nAdaptive bandwidth: 250 CV score: 2.914736e+12 \nAdaptive bandwidth: 162 CV score: 2.610897e+12 \nAdaptive bandwidth: 107 CV score: 2.240188e+12 \nAdaptive bandwidth: 73 CV score: 1.971641e+12 \nAdaptive bandwidth: 52 CV score: 1.797271e+12 \nAdaptive bandwidth: 39 CV score: 1.659472e+12 \nAdaptive bandwidth: 31 CV score: 1.573963e+12 \nAdaptive bandwidth: 26 CV score: 1.550147e+12 \nAdaptive bandwidth: 23 CV score: 1.542544e+12 \nAdaptive bandwidth: 21 CV score: 1.518885e+12 \nAdaptive bandwidth: 19 CV score: 1.515965e+12 \nAdaptive bandwidth: 19 CV score: 1.515965e+12 \n\n\n\nbw_adaptive\n\n[1] 19"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#model-calibration",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#model-calibration",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "7.2 Model calibration",
    "text": "7.2 Model calibration\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-11-01 00:47:17.198423 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 1000\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-167624  -37265    -415   34811  224601 \n\n   Coefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              115703.7    34303.4   3.373 0.000773 ***\n   floor_area_sqm             2778.6      292.3   9.507  &lt; 2e-16 ***\n   storey_order              12698.2     1071.0  11.857  &lt; 2e-16 ***\n   remaining_lease_mths        350.2       14.6  23.997  &lt; 2e-16 ***\n   PROX_CBD                 -16225.6      630.1 -25.751  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -11330.9     3220.8  -3.518 0.000455 ***\n   PROX_HAWKER              -19964.1     4021.1  -4.965 8.10e-07 ***\n   PROX_MRT                 -39652.5     5412.3  -7.326 4.92e-13 ***\n   PROX_PARK                -15878.3     4609.2  -3.445 0.000595 ***\n   PROX_MALL                -15910.9     6438.1  -2.471 0.013628 *  \n   PROX_SUPERMARKET         -18928.5    13305.0  -1.423 0.155150    \n   WITHIN_350M_KINDERGARTEN   9309.7     2024.3   4.599 4.80e-06 ***\n   WITHIN_350M_CHILDCARE     -1619.5     1181.0  -1.371 0.170572    \n   WITHIN_350M_BUS            -447.7      738.7  -0.606 0.544624    \n   WITHIN_1KM_PRISCH        -10698.0     1543.5  -6.931 7.55e-12 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61270 on 985 degrees of freedom\n   Multiple R-squared: 0.7424\n   Adjusted R-squared: 0.7387 \n   F-statistic: 202.7 on 14 and 985 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.698259e+12\n   Sigma(hat): 60874.22\n   AIC:  24901.01\n   AICc:  24901.56\n   BIC:  24090.05\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 19 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -1850662.06  -213226.88    18750.18   257759.31\n   floor_area_sqm              -4400.58     1227.91     2020.59     3305.91\n   storey_order                 3226.46     8118.79    10349.25    13840.12\n   remaining_lease_mths         -567.87      343.26      422.16      502.70\n   PROX_CBD                  -107227.77   -23329.41   -10632.77     -983.94\n   PROX_ELDERLYCARE          -262405.86   -25815.67    -5892.75    18397.75\n   PROX_HAWKER               -217237.20   -36313.19    -9931.90    21441.49\n   PROX_MRT                  -305069.89   -92410.01   -57000.64   -20410.27\n   PROX_PARK                 -256758.99   -33742.57   -16756.73     8462.87\n   PROX_MALL                 -274223.06   -35730.88     6953.21    49221.11\n   PROX_SUPERMARKET          -176209.93   -43225.75    -7954.90    30114.02\n   WITHIN_350M_KINDERGARTEN   -43387.03    -9117.13    -2525.06     5559.95\n   WITHIN_350M_CHILDCARE      -15152.19    -2203.26     1242.91     3469.04\n   WITHIN_350M_BUS            -10848.37    -1806.81      523.89     2318.23\n   WITHIN_1KM_PRISCH          -50593.97    -4155.12      348.43     4951.49\n                                  Max.\n   Intercept                1668279.80\n   floor_area_sqm              7834.73\n   storey_order               26827.97\n   remaining_lease_mths         792.01\n   PROX_CBD                  130929.41\n   PROX_ELDERLYCARE          178770.13\n   PROX_HAWKER               146976.62\n   PROX_MRT                  126271.80\n   PROX_PARK                  90469.23\n   PROX_MALL                 342520.92\n   PROX_SUPERMARKET          189007.16\n   WITHIN_350M_KINDERGARTEN   40812.13\n   WITHIN_350M_CHILDCARE      15729.60\n   WITHIN_350M_BUS            11766.10\n   WITHIN_1KM_PRISCH          32922.16\n   ************************Diagnostic information*************************\n   Number of data points: 1000 \n   Effective number of parameters (2trace(S) - trace(S'S)): 419.14 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 580.86 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 24103.65 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 23393.52 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 24424.31 \n   Residual sum of squares: 5.99674e+11 \n   R-square value:  0.9582264 \n   Adjusted R-square value:  0.9280312 \n\n   ***********************************************************************\n   Program stops at: 2024-11-01 00:47:17.992583"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#predicting-with-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#predicting-with-test-data",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "8.1 Predicting with test data",
    "text": "8.1 Predicting with test data\nTest data bw\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nAdaptive bandwidth: 316 CV score: 1.752181e+12 \nAdaptive bandwidth: 203 CV score: 1.635856e+12 \nAdaptive bandwidth: 132 CV score: 1.452381e+12 \nAdaptive bandwidth: 89 CV score: 1.292305e+12 \nAdaptive bandwidth: 61 CV score: 1.115867e+12 \nAdaptive bandwidth: 45 CV score: 1.007764e+12 \nAdaptive bandwidth: 34 CV score: 886240690082 \nAdaptive bandwidth: 28 CV score: 859792519354 \nAdaptive bandwidth: 23 CV score: 856247388819 \nAdaptive bandwidth: 21 CV score: 846203688028 \nAdaptive bandwidth: 19 CV score: 837013751208 \nAdaptive bandwidth: 18 CV score: 8.32968e+11 \nAdaptive bandwidth: 17 CV score: 834218488856 \nAdaptive bandwidth: 18 CV score: 8.32968e+11 \n\n\nPredicting\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#data-preparation",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#data-preparation",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "9.1 Data Preparation",
    "text": "9.1 Data Preparation\nFirstly, code chunk below is used to extract the coordinates of training and test data sets\n\ncoords &lt;- st_coordinates(HDB_sample)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nNext, code chunk below is used to drop the geometry column of both training and test data sets.\n\ntrain_data_nogeom &lt;- train_data %&gt;%\n  st_drop_geometry()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#calibrating-rf-model",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#calibrating-rf-model",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "9.2 Calibrating RF model",
    "text": "9.2 Calibrating RF model\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#model-output",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#model-output",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "9.3 Model output",
    "text": "9.3 Model output\n\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1000 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       2289284270 \nR squared (OOB):                  0.8406868"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#preparing-the-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#preparing-the-test-data",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "11.1 Preparing the test data",
    "text": "11.1 Preparing the test data\n\ntest_data_nogeom &lt;- cbind(\n  test_data, coords_test) %&gt;%\n  st_drop_geometry()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#predicting-with-the-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#predicting-with-the-test-data",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "11.2 Predicting with the test data",
    "text": "11.2 Predicting with the test data\nIn the code chunk below, predict.grf() of spatialML for predicting re-sale prices in the test data set (i.e. test_data_nogeom)\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data_nogeom, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\nstr(gwRF_pred) \n\n num [1:500] 424497 495806 376473 372622 377314 ..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#creating-df",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08b.html#creating-df",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "11.3 Creating DF",
    "text": "11.3 Creating DF\nNext, the code chunk below is used to convert the output from predict.grf() into a data.frame.\n\nGRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\n\nnrow(GRF_pred_df)\n\n[1] 500\n\n\nThen, cbind() is used to append fields in GRF_pred_df data.frame onto test_data.\n\ntest_data_pred &lt;- cbind(test_data, \n                        GRF_pred_df)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "",
    "text": "Spatial interaction represent the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.\nEach spatial interaction, as an analogy for a set of movements, is composed of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where rows are related to the locations (centroids) of origin, while columns are related to locations (centroids) of destination. Such a matrix is commonly known as an origin/destination matrix, or a spatial interaction matrix.\nIn this hands-on exercise, we will learn how to build an OD matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall. By the end of this hands-on exercise, you will be able:\n\nto import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#importing-the-od-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#importing-the-od-data",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "3.1 Importing the OD data",
    "text": "3.1 Importing the OD data\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202210.csv\")\n\nLet use display the odbus tibble data table by using the code chunk below.\n\nglimpse(odbus)\n\nRows: 5,122,925\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2022-10\", \"2022-10\", \"2022-10\", \"2022-10\", \"2022-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 10, 10, 7, 11, 16, 16, 20, 7, 7, 11, 11, 8, 11, 11…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;dbl&gt; 65239, 65239, 23519, 52509, 54349, 54349, 43371, 8…\n$ DESTINATION_PT_CODE &lt;dbl&gt; 65159, 65159, 23311, 42041, 53241, 53241, 14139, 9…\n$ TOTAL_TRIPS         &lt;dbl&gt; 2, 1, 2, 1, 1, 4, 1, 3, 1, 5, 2, 5, 15, 40, 1, 1, …\n\n\nA quick check of odbus tibble data frame shows that the values in OROGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#extracting-the-study-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#extracting-the-study-data",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "3.2 Extracting the study data",
    "text": "3.2 Extracting the study data\nFor the purpose of this exercise, we will extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nTable below shows the content of odbus6_9\n\ndatatable(odbus6_9)\n\n\n\n\n\nWe will save the output in rds format for future used.\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\n\nThe code chunk below will be used to import the save odbus6_9.rds into R environment.\n\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "4.1 Importing geospatial data",
    "text": "4.1 Importing geospatial data\nTwo geospatial data will be used in this exercise, they are:\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_read() function of sf package is used to import the shapefile into R as sf data frame.\nst_transform() function of sf package is used to transform the projection to crs 3414.\n\n\n\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#combining-busstop-and-mpsz",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#combining-busstop-and-mpsz",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "5.1 Combining Busstop and mpsz",
    "text": "5.1 Combining Busstop and mpsz\nCode chunk below populates the planning subzone code (i.e. SUBZONE_C) of mpsz sf data frame into busstop sf data frame.\n\n# busstop &lt;- st_transform(busstop, st_crs(mpsz))\n\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_intersection() is used to perform point and polygon overly and the output will be in point sf object.\nselect() of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.\nfive bus stops are excluded in the resultant data frame because they are outside of Singapore bpundary.\n\n\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\nBefore moving to the next step, it is wise to save the output into rds format.\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\nNext, we are going to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\n#table(duplicated(odbus6_9$ORIGIN_PT_CODE))\n#table(duplicated(busstop_mpsz$BUS_STOP_N))\n\n\n#busstop_mpsz &lt;- busstop_mpsz %&gt;% distinct(BUS_STOP_N, .keep_all = TRUE)\n\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n            #, relationship = \"many-to-many\") %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE) \n\nBefore continue, it is a good practice for us to check for duplicating records.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nIf duplicated records are found, the code chunk below will be used to retain the unique records.\n\nod_data &lt;- unique(od_data)\n\nIt will be a good practice to confirm if the duplicating records issue has been addressed fully.\nNext, we will update od_data data frame cwith the planning subzone codes.\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup() \n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nIt is time to save the output into an rds file format.\n\nwrite_rds(od_data, \"data/rds/od_data_fii.rds\")\n\n\nod_data_fii &lt;- read_rds(\"data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#removing-intra-zonal-flows",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#removing-intra-zonal-flows",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "6.1 Removing intra-zonal flows",
    "text": "6.1 Removing intra-zonal flows\nWe will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.\n\nod_data_fij &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\nwrite_rds(od_data_fij, \"data/rds/od_data_fij.rds\")\n\n\nod_data_fij &lt;- read_rds(\"data/rds/od_data_fij.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#creating-desire-lines",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#creating-desire-lines",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "6.2 Creating desire lines",
    "text": "6.2 Creating desire lines\nIn this code chunk below, od2line() of stplanr package is used to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data_fij, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\n\nwrite_rds(flowLine, \"data/rds/flowLine.rds\")\n\n\nflowLine &lt;- read_rds(\"data/rds/flowLine.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#visualising-the-desire-lines",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.1.html#visualising-the-desire-lines",
    "title": "Hands-on Exercise 10.1: Processing and Visualising Flow Data",
    "section": "6.3 Visualising the desire lines",
    "text": "6.3 Visualising the desire lines\nTo visualise the resulting desire lines, the code chunk below is used.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe patient, the rendering process takes more time because of the transparency argument (i.e. alpha)\n\n\nWhen the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "Spatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).\nThere are four main types of traditional SIMs (Wilson 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.\n\n\n\n\n\n\nNote\n\n\n\nCalibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#converting-from-sf-data.table-to-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#converting-from-sf-data.table-to-spatialpolygonsdataframe",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "5.1 Converting from sf data.table to SpatialPolygonsDataFrame",
    "text": "5.1 Converting from sf data.table to SpatialPolygonsDataFrame\nThere are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.\nFirst as.Spatial() will be used to convert mpsz from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#computing-the-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#computing-the-distance-matrix",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "5.2 Computing the distance matrix",
    "text": "5.2 Computing the distance matrix\nNext, spDists() of sp package will be used to compute the Euclidean distance between the centroids of the planning subzones.\n\n\n\n\n\n\nQ&A\n\n\n\nDo you know why the distance is calculated between two centroids of a pair of spatial polygons?\nThe reason for calculating the distance between the centroids of spatial polygons, like planning subzones, is that centroids provide a single, representative point for each polygon, simplifying the computation of distances between complex shapes. When working with spatial data, calculating distances between all boundary points of irregular polygons would be computationally expensive and unnecessarily detailed, especially when a generalized measurement is sufficient.\nUsing centroids allows for:\n\nSimplified Calculations: Instead of calculating distances between all possible points on each polygon’s boundary, using centroids reduces it to a single point per polygon.\nRepresentation of the “Center” of Each Area: The centroid serves as a good approximation of the “central” or “average” location within the subzone, making it useful for many spatial analyses, including clustering, accessibility analysis, and distance-based modeling.\nComparability: Centroid-to-centroid distances provide a consistent basis for comparison between zones, especially when calculating Euclidean distances, which are straightforward and computationally efficient.\n\n\n\n\ndist &lt;- spDists(mpsz_sp, \n                longlat = FALSE)\n\n\nhead(dist, n=c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\nNotice that the output dist is a matrix object class of R. Also notice that the column heanders and row headers are not labeled with the planning subzone codes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#labelling-column-and-row-heanders-of-a-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#labelling-column-and-row-heanders-of-a-distance-matrix",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "5.3 Labelling column and row heanders of a distance matrix",
    "text": "5.3 Labelling column and row heanders of a distance matrix\nFirst, we will create a list sorted according to the the distance matrix by planning sub-zone code.\n\nsz_names &lt;- mpsz$SUBZONE_C\n\nNext we will attach SUBZONE_C to row and column for distance matrix matching ahead\n\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#pivoting-distance-value-by-subzone_c",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#pivoting-distance-value-by-subzone_c",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "5.4 Pivoting distance value by SUBZONE_C",
    "text": "5.4 Pivoting distance value by SUBZONE_C\nNext, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\nNotice that the within zone distance is 0."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#updating-intra-zonal-distances",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#updating-intra-zonal-distances",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "5.5 Updating intra-zonal distances",
    "text": "5.5 Updating intra-zonal distances\nIn this section, we are going to append a constant value to replace the intra-zonal distance of 0.\nFirst, we will select and find out the minimum value of the distance by using summary().\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nNext, a constant distance value of 50m is added into intra-zones distance.\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\n\nThe code chunk below will be used to check the result data.frame.\n\ndistPair %&gt;%\n  summary()\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n\nThe code chunk below is used to rename the origin and destination fields.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nLastly, the code chunk below is used to save the dataframe for future use.\n\nwrite_rds(distPair, \"data/rds/distPair.rds\") \n\n\ndistPair &lt;- read_rds(\"data/rds/distPair.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#separating-intra-flow-from-passenger-volume-df",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#separating-intra-flow-from-passenger-volume-df",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "6.1 Separating intra-flow from passenger volume df",
    "text": "6.1 Separating intra-flow from passenger volume df\nCode chunk below is used to add three new fields in flow_data dataframe.\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#combining-passenger-volume-data-with-distance-value",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#combining-passenger-volume-data-with-distance-value",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "6.2 Combining passenger volume data with distance value",
    "text": "6.2 Combining passenger volume data with distance value\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ fields of flow_data dataframe into factor data type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nNow, left_join() of dplyr will be used to flow_data dataframe and distPair dataframe. The output is called flow_data1.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#importing-population-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#importing-population-data",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "7.1 Importing population data",
    "text": "7.1 Importing population data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "7.2 Geospatial data wrangling",
    "text": "7.2 Geospatial data wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c(\"PA\" = \"PLN_AREA_N\",\n                   \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#preparing-origin-attribute",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#preparing-origin-attribute",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "7.3 Preparing origin attribute",
    "text": "7.3 Preparing origin attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#preparing-destination-attribute",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#preparing-destination-attribute",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "7.4 Preparing destination attribute",
    "text": "7.4 Preparing destination attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\nWe will called the output data file SIM_data. it is in rds data file format.\n\nwrite_rds(flow_data1, \"data/rds/SIM_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#importing-the-modelling-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#importing-the-modelling-data",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.1 Importing the modelling data",
    "text": "8.1 Importing the modelling data\nFirstly, let us import the modelling data by using the code chunk below.\n\nSIM_data &lt;- read_rds(\"data/rds/SIM_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#visualising-the-dependent-variable",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#visualising-the-dependent-variable",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.2 Visualising the dependent variable",
    "text": "8.2 Visualising the dependent variable\nFirstly, let us plot the distribution of the dependent variable (i.e. TRIPS) by using histogram method by using the code chunk below.\n\nggplot(data = SIM_data,\n       aes(x = TRIPS)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nNotice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.\nNext, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.\n\nggplot(data = SIM_data,\n       aes(x = dist,\n           y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nNotice that their relationship hardly resemble linear relationship.\nOn the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.\n\nggplot(data = SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#checking-for-variables-with-zero-values",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#checking-for-variables-with-zero-values",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.3 Checking for variables with zero values",
    "text": "8.3 Checking for variables with zero values\nSince Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.\nIn the code chunk below, summary() of Base R is used to compute the summary statistics of all variables in SIM_data data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:14734       Length:14734       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    14   1st Qu.:    13.0  \n Mode  :character   Mode  :character   Median :    76   Median :    70.0  \n                                       Mean   :  1021   Mean   :   839.9  \n                                       3rd Qu.:   426   3rd Qu.:   379.0  \n                                       Max.   :232187   Max.   :148274.0  \n     offset              dist       ORIGIN_AGE7_12 ORIGIN_AGE13_24\n Min.   :0.000001   Min.   :   50   Min.   :   0   Min.   :    0  \n 1st Qu.:1.000000   1st Qu.: 3346   1st Qu.: 240   1st Qu.:  440  \n Median :1.000000   Median : 6067   Median : 700   Median : 1350  \n Mean   :0.982150   Mean   : 6880   Mean   :1032   Mean   : 2269  \n 3rd Qu.:1.000000   3rd Qu.: 9729   3rd Qu.:1480   3rd Qu.: 3260  \n Max.   :1.000000   Max.   :26136   Max.   :6340   Max.   :16380  \n ORIGIN_AGE25_64 DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :    0   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 2200   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2200  \n Median : 6810   Median : 720   Median : 1420   Median : 7030  \n Mean   :10487   Mean   :1033   Mean   : 2290   Mean   :10574  \n 3rd Qu.:15770   3rd Qu.:1500   3rd Qu.: 3260   3rd Qu.:15830  \n Max.   :74610   Max.   :6340   Max.   :16380   Max.   :74610  \n\n\nThe print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\nIn view of this, code chunk below will be used to replace zero values to 0.99.\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(\n  SIM_data$DESTIN_AGE7_12 == 0,\n  0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(\n  SIM_data$DESTIN_AGE13_24 == 0,\n  0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(\n  SIM_data$DESTIN_AGE25_64 == 0,\n  0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE7_12 == 0,\n  0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE13_24 == 0,\n  0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE25_64 == 0,\n  0.99, SIM_data$ORIGIN_AGE25_64)\n\nYou can run the summary() again.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:14734       Length:14734       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    14   1st Qu.:    13.0  \n Mode  :character   Mode  :character   Median :    76   Median :    70.0  \n                                       Mean   :  1021   Mean   :   839.9  \n                                       3rd Qu.:   426   3rd Qu.:   379.0  \n                                       Max.   :232187   Max.   :148274.0  \n     offset              dist       ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :0.000001   Min.   :   50   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1.000000   1st Qu.: 3346   1st Qu.: 240.00   1st Qu.:  440.00  \n Median :1.000000   Median : 6067   Median : 700.00   Median : 1350.00  \n Mean   :0.982150   Mean   : 6880   Mean   :1031.86   Mean   : 2268.84  \n 3rd Qu.:1.000000   3rd Qu.: 9729   3rd Qu.:1480.00   3rd Qu.: 3260.00  \n Max.   :1.000000   Max.   :26136   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.: 2200.00   1st Qu.: 240.00   1st Qu.:  460.00   1st Qu.: 2200.00  \n Median : 6810.00   Median : 720.00   Median : 1420.00   Median : 7030.00  \n Mean   :10487.62   Mean   :1033.40   Mean   : 2290.35   Mean   :10574.46  \n 3rd Qu.:15770.00   3rd Qu.:1500.00   3rd Qu.: 3260.00   3rd Qu.:15830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nNotice that all the 0 values have been replaced by 0.99."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#unconstrained-spatial-interaction-model",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#unconstrained-spatial-interaction-model",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.4 Unconstrained Spatial Interaction Model",
    "text": "8.4 Unconstrained Spatial Interaction Model\nIn this section, you will learn how to calibrate an unconstrained spatial interaction model by using glm() of Base Stats. The explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. ORIGIN_AGE25_64) and distance between origin and destination in km (i.e. dist).\nThe general formula of Unconstrained Spatial Interaction Model\n\nThe code chunk used to calibrate to model is shown below:\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(ORIGIN_AGE25_64) + \n                log(DESTIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n           10.407308              0.244859              0.009562  \n           log(dist)  \n           -0.705896  \n\nDegrees of Freedom: 14733 Total (i.e. Null);  14730 Residual\nNull Deviance:      60800000 \nResidual Deviance: 36430000     AIC: 36520000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#r-squared-function",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#r-squared-function",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.5 R-squared function",
    "text": "8.5 R-squared function\nIn order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value as shown below.\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed,estimated)\n  R2 &lt;- r^2\n  R2\n}\n\nNext, we will compute the R-squared of the unconstrained SIM by using the code chunk below.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1892576\n\n\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.400\n  adj. R2: 0.400"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#origin-production-constrained-sim",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#origin-production-constrained-sim",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.6 Origin (Production) constrained SIM",
    "text": "8.6 Origin (Production) constrained SIM\nIn this section, we will fit an origin constrained SIM by using the code3 chunk below.\nThe general formula of Origin Constrained Spatial Interaction Model\n\n\norcSIM &lt;- glm(formula = TRIPS ~ \n                 ORIGIN_SZ +\n                 log(DESTIN_AGE25_64) +\n                 log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)           1.211e+01  3.785e-03  3199.012  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       1.008e+00  4.450e-03   226.401  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       5.474e-01  4.563e-03   119.959  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -7.494e-02  5.187e-03   -14.448  &lt; 2e-16 ***\nORIGIN_SZAMSZ05      -2.006e-01  5.790e-03   -34.650  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       4.193e-01  5.130e-03    81.736  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.372e+00  9.683e-03  -141.686  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -1.022e+00  8.956e-03  -114.087  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       2.239e-01  5.408e-03    41.396  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       5.061e-01  4.716e-03   107.311  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.856e+00  1.285e-02  -144.414  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.580e+00  1.076e-02  -146.883  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.072e+00  4.345e-03   246.734  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       5.198e-01  5.079e-03   102.340  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       9.865e-01  4.490e-03   219.724  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       1.767e+00  3.894e-03   453.646  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       6.395e-01  4.546e-03   140.691  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       9.363e-01  4.543e-03   206.094  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -1.281e+00  9.558e-03  -133.991  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -1.167e+00  9.032e-03  -129.194  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -4.540e-01  6.538e-03   -69.437  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       3.736e-01  5.115e-03    73.050  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       5.841e-01  4.934e-03   118.375  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -1.177e-01  5.914e-03   -19.895  &lt; 2e-16 ***\nORIGIN_SZBKSZ05      -2.164e-01  5.832e-03   -37.115  &lt; 2e-16 ***\nORIGIN_SZBKSZ06       3.684e-03  5.873e-03     0.627  0.53048    \nORIGIN_SZBKSZ07       7.456e-01  4.426e-03   168.439  &lt; 2e-16 ***\nORIGIN_SZBKSZ08      -2.279e-02  5.348e-03    -4.261 2.04e-05 ***\nORIGIN_SZBKSZ09      -9.572e-02  5.721e-03   -16.733  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.688e+00  1.482e-02  -113.887  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -2.154e+00  1.924e-02  -111.980  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -3.249e+00  3.930e-02   -82.662  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -2.203e+00  2.306e-02   -95.557  &lt; 2e-16 ***\nORIGIN_SZBMSZ01      -1.267e-01  5.222e-03   -24.266  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.075e+00  6.742e-03  -159.386  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -4.386e-01  5.794e-03   -75.707  &lt; 2e-16 ***\nORIGIN_SZBMSZ04      -6.333e-02  5.157e-03   -12.280  &lt; 2e-16 ***\nORIGIN_SZBMSZ05      -2.256e+00  1.247e-02  -180.957  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -2.378e+00  1.618e-02  -147.029  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -4.769e-01  5.653e-03   -84.362  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -5.652e-01  5.811e-03   -97.259  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.232e+00  8.688e-03  -141.760  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.471e+00  9.130e-03  -161.131  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -7.866e-01  6.595e-03  -119.263  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.072e+00  9.149e-03  -117.206  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -1.207e-01  5.691e-03   -21.218  &lt; 2e-16 ***\nORIGIN_SZBMSZ14      -5.376e-01  6.629e-03   -81.098  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -3.253e-01  6.054e-03   -53.740  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.548e+00  9.144e-03  -169.303  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -2.169e+00  1.576e-02  -137.622  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       1.369e-01  5.553e-03    24.660  &lt; 2e-16 ***\nORIGIN_SZBPSZ02      -3.292e-02  6.462e-03    -5.094 3.50e-07 ***\nORIGIN_SZBPSZ03       1.491e-01  6.149e-03    24.241  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       3.544e-01  5.084e-03    69.711  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       5.454e-01  4.554e-03   119.764  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -1.406e+00  9.311e-03  -151.045  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -1.004e+00  8.575e-03  -117.068  &lt; 2e-16 ***\nORIGIN_SZBSSZ01      -1.625e-02  5.276e-03    -3.080  0.00207 ** \nORIGIN_SZBSSZ02       3.088e-01  4.787e-03    64.495  &lt; 2e-16 ***\nORIGIN_SZBSSZ03       2.555e-01  4.689e-03    54.487  &lt; 2e-16 ***\nORIGIN_SZBTSZ01      -6.646e-02  5.385e-03   -12.340  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -1.078e+00  7.797e-03  -138.225  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -2.284e-01  5.727e-03   -39.876  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -1.053e+00  1.019e-02  -103.339  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.647e+00  1.100e-02  -149.690  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -7.804e-01  7.181e-03  -108.682  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -2.298e+00  1.321e-02  -173.921  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.283e+00  9.394e-03  -136.560  &lt; 2e-16 ***\nORIGIN_SZCBSZ01      -1.911e+00  5.483e-02   -34.844  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -1.758e+00  1.331e-02  -132.099  &lt; 2e-16 ***\nORIGIN_SZCHSZ01      -1.236e+00  1.178e-02  -104.954  &lt; 2e-16 ***\nORIGIN_SZCHSZ02      -5.424e-01  7.940e-03   -68.307  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       4.332e-01  5.841e-03    74.153  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       1.843e-01  5.117e-03    36.007  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       6.800e-01  5.087e-03   133.672  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       8.030e-01  4.522e-03   177.574  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.298e+00  4.562e-03   284.446  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       1.011e+00  5.305e-03   190.602  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       1.262e+00  5.042e-03   250.262  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -6.805e-01  7.661e-03   -88.836  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.837e+00  1.364e-02  -134.665  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -1.001e+00  7.949e-03  -125.969  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       6.966e-01  4.460e-03   156.204  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.974e+00  1.474e-02  -133.906  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       8.585e-01  4.204e-03   204.230  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -2.974e-01  5.575e-03   -53.346  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       3.231e-01  5.802e-03    55.688  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.697e+00  1.555e-02  -109.106  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -4.061e+00  8.341e-02   -48.693  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -4.031e+00  7.381e-02   -54.618  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -3.000e+00  3.129e-02   -95.889  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.405e+00  9.192e-03  -152.876  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       2.536e-01  4.889e-03    51.880  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       2.411e-01  4.855e-03    49.649  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       8.350e-01  4.200e-03   198.826  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       6.207e-01  4.375e-03   141.857  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       2.806e-01  4.746e-03    59.121  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       4.917e-01  4.712e-03   104.351  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       2.452e-01  5.113e-03    47.952  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       9.052e-01  4.303e-03   210.358  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.170e+00  4.253e-03   275.033  &lt; 2e-16 ***\nORIGIN_SZHGSZ06      -1.016e-01  5.413e-03   -18.773  &lt; 2e-16 ***\nORIGIN_SZHGSZ07       6.984e-01  4.455e-03   156.757  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       1.005e-01  5.354e-03    18.781  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -5.390e-01  6.962e-03   -77.417  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -3.512e+00  4.211e-02   -83.388  &lt; 2e-16 ***\nORIGIN_SZJESZ01       4.022e-01  4.869e-03    82.601  &lt; 2e-16 ***\nORIGIN_SZJESZ02       2.273e-01  4.924e-03    46.158  &lt; 2e-16 ***\nORIGIN_SZJESZ03       1.829e-01  5.286e-03    34.598  &lt; 2e-16 ***\nORIGIN_SZJESZ04      -1.177e+00  9.142e-03  -128.767  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -2.065e+00  1.382e-02  -149.494  &lt; 2e-16 ***\nORIGIN_SZJESZ06       2.301e-01  4.853e-03    47.410  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.889e+00  1.183e-02  -159.599  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -1.062e+00  1.147e-02   -92.551  &lt; 2e-16 ***\nORIGIN_SZJESZ09       5.237e-01  4.959e-03   105.612  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.829e+00  1.800e-02  -101.616  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -2.023e+00  1.931e-02  -104.738  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       2.125e-01  6.405e-03    33.183  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       8.858e-01  4.521e-03   195.929  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.269e+00  4.188e-03   302.922  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       1.284e+00  4.280e-03   300.017  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.393e+00  1.252e-02  -111.339  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -1.015e+00  1.067e-02   -95.109  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.694e+00  2.751e-02   -97.911  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       1.950e+00  4.110e-03   474.430  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.831e+00  3.899e-03   469.595  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       1.636e-01  4.902e-03    33.374  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -5.156e-01  6.321e-03   -81.570  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -4.145e-01  5.949e-03   -69.666  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -2.283e+00  1.187e-02  -192.327  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -8.593e-01  8.272e-03  -103.882  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -4.709e+00  1.857e-01   -25.352  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -1.123e+00  8.408e-03  -133.615  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -1.476e+00  9.152e-03  -161.321  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -3.273e+00  3.875e-02   -84.465  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -2.615e+00  2.802e-02   -93.303  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -8.945e-01  1.035e-02   -86.389  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.998e+00  1.703e-02  -117.297  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -1.093e+00  8.367e-03  -130.656  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -5.975e-01  6.898e-03   -86.616  &lt; 2e-16 ***\nORIGIN_SZMPSZ03      -9.706e-03  5.319e-03    -1.825  0.06804 .  \nORIGIN_SZMUSZ02      -3.923e+00  1.038e-01   -37.806  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.829e+00  3.529e-02   -80.157  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -3.256e+00  2.323e-02  -140.180  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -9.865e-01  7.777e-03  -126.848  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -3.353e+00  4.964e-02   -67.546  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -3.818e+00  5.576e-02   -68.483  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       4.449e-01  4.482e-03    99.269  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -6.279e-01  6.470e-03   -97.044  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -1.212e+00  7.788e-03  -155.644  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -1.469e+00  9.091e-03  -161.543  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.628e+00  1.579e-02  -166.466  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -9.541e-01  1.223e-02   -78.035  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -5.353e-01  7.233e-03   -74.009  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       9.574e-01  4.437e-03   215.779  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.110e+00  4.417e-03   251.169  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       2.658e-01  5.758e-03    46.156  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -8.153e-01  1.044e-02   -78.119  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -1.675e+00  1.478e-02  -113.340  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -2.963e+00  3.672e-02   -80.686  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -3.279e+00  3.684e-02   -89.012  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -2.466e+00  2.245e-02  -109.864  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.411e+00  4.584e-03   307.690  &lt; 2e-16 ***\nORIGIN_SZPNSZ02      -5.043e-01  1.108e-02   -45.503  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.878e+00  1.940e-02   -96.796  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.761e+00  3.112e-02   -88.706  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -2.277e+00  2.628e-02   -86.662  &lt; 2e-16 ***\nORIGIN_SZPRSZ01      -7.934e-01  1.142e-02   -69.499  &lt; 2e-16 ***\nORIGIN_SZPRSZ02       9.414e-01  4.615e-03   203.981  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       7.674e-01  4.626e-03   165.881  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -3.771e-01  7.516e-03   -50.168  &lt; 2e-16 ***\nORIGIN_SZPRSZ05       1.327e+00  4.325e-03   306.737  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -4.081e-01  8.651e-03   -47.172  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.151e+00  1.610e-02  -133.558  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       5.293e-04  6.383e-03     0.083  0.93391    \nORIGIN_SZQTSZ01      -4.144e-01  6.846e-03   -60.539  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -7.967e-01  6.327e-03  -125.933  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -2.415e-01  5.681e-03   -42.509  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.013e+00  7.129e-03  -142.123  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -3.923e-01  5.994e-03   -65.446  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -5.662e-01  6.481e-03   -87.359  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.558e+00  9.635e-03  -161.662  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -1.577e-01  5.699e-03   -27.665  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -6.189e-01  6.633e-03   -93.312  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -4.511e-01  6.512e-03   -69.271  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.455e+00  9.800e-03  -148.421  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -1.475e+00  1.044e-02  -141.309  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -3.529e-01  6.413e-03   -55.038  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.591e+00  9.847e-03  -161.565  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -8.955e-01  1.027e-02   -87.184  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -1.375e+00  1.265e-02  -108.704  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -6.196e-01  8.475e-03   -73.116  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -3.523e+00  3.237e-02  -108.818  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -2.912e+00  2.776e-02  -104.868  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -3.145e+00  2.379e-02  -132.232  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -3.357e+00  5.567e-02   -60.309  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.438e+00  1.644e-02  -148.272  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       5.890e-01  5.529e-03   106.520  &lt; 2e-16 ***\nORIGIN_SZSBSZ02      -7.098e-01  8.213e-03   -86.432  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       9.634e-01  4.611e-03   208.943  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       7.729e-01  5.289e-03   146.136  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -9.966e-02  6.543e-03   -15.231  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.778e+00  1.719e-02  -103.427  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -1.161e+00  1.256e-02   -92.436  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -1.212e+00  1.222e-02   -99.227  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -5.783e-01  8.579e-03   -67.412  &lt; 2e-16 ***\nORIGIN_SZSESZ02       9.999e-01  4.409e-03   226.798  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.214e+00  4.164e-03   291.675  &lt; 2e-16 ***\nORIGIN_SZSESZ04       8.141e-01  4.868e-03   167.238  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -2.186e-01  5.915e-03   -36.961  &lt; 2e-16 ***\nORIGIN_SZSESZ06       7.298e-01  4.689e-03   155.641  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.543e+00  1.961e-02  -129.689  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -1.016e+00  8.550e-03  -118.869  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.120e+00  9.589e-03  -116.799  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       2.169e-01  5.167e-03    41.970  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       2.672e-01  4.792e-03    55.757  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.785e+00  1.060e-02  -168.456  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       4.017e-01  4.541e-03    88.470  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -6.303e-01  6.235e-03  -101.098  &lt; 2e-16 ***\nORIGIN_SZSKSZ01      -1.928e-01  7.765e-03   -24.826  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       3.870e-01  5.689e-03    68.026  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -6.815e-01  7.983e-03   -85.369  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -2.528e+00  2.702e-02   -93.548  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -1.370e+00  1.552e-02   -88.311  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -3.218e+00  3.058e-02  -105.238  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -6.800e-01  7.683e-03   -88.497  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -2.389e+00  1.583e-02  -150.989  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -2.183e+00  4.887e-02   -44.666  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -2.243e+00  2.243e-02  -100.025  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -2.005e+00  2.869e-02   -69.879  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -2.276e+00  1.784e-02  -127.557  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       4.015e-01  5.814e-03    69.048  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.222e+00  3.795e-03   585.568  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.412e+00  4.108e-03   343.608  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       9.106e-01  4.742e-03   192.036  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -3.259e-01  7.534e-03   -43.253  &lt; 2e-16 ***\nORIGIN_SZTNSZ01      -1.806e+00  1.038e-02  -174.076  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.741e+00  9.778e-03  -178.108  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -2.277e+00  1.338e-02  -170.199  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -7.703e-01  7.197e-03  -107.032  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -6.466e-01  6.287e-03  -102.841  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       4.633e-01  4.347e-03   106.578  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -5.186e-01  6.085e-03   -85.234  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -2.900e-01  5.779e-03   -50.190  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -2.169e-01  6.072e-03   -35.720  &lt; 2e-16 ***\nORIGIN_SZTPSZ06       3.357e-01  5.942e-03    56.486  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -2.517e-01  6.317e-03   -39.846  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -1.075e+00  9.109e-03  -118.034  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -3.708e-01  6.189e-03   -59.903  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -6.889e-01  7.634e-03   -90.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ11       7.661e-02  5.459e-03    14.033  &lt; 2e-16 ***\nORIGIN_SZTPSZ12      -5.971e-01  6.522e-03   -91.552  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -3.517e+00  4.739e-02   -74.210  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       3.022e-01  7.334e-03    41.203  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       3.730e-01  7.073e-03    52.733  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       3.610e-01  7.463e-03    48.372  &lt; 2e-16 ***\nORIGIN_SZTSSZ05      -1.103e+00  1.404e-02   -78.566  &lt; 2e-16 ***\nORIGIN_SZTSSZ06      -1.310e+00  1.718e-02   -76.286  &lt; 2e-16 ***\nORIGIN_SZWCSZ01      -1.233e-01  7.861e-03   -15.690  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -2.872e+00  3.159e-02   -90.911  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -4.138e+00  1.241e-01   -33.349  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.370e+00  4.146e-03   330.448  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       1.041e+00  4.747e-03   219.219  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       2.189e+00  4.035e-03   542.344  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.142e+00  4.963e-03   230.074  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       5.160e-01  4.998e-03   103.230  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       1.208e+00  4.611e-03   262.019  &lt; 2e-16 ***\nORIGIN_SZWDSZ07      -3.805e-01  8.034e-03   -47.365  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -4.839e-01  7.878e-03   -61.426  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.475e+00  4.401e-03   335.097  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -1.552e-01  5.643e-03   -27.496  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       8.958e-01  4.973e-03   180.144  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.757e+00  4.275e-03   411.050  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       8.439e-01  4.538e-03   185.955  &lt; 2e-16 ***\nORIGIN_SZYSSZ05      -9.995e-02  5.920e-03   -16.884  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -1.175e+00  1.079e-02  -108.835  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -1.202e+00  1.127e-02  -106.642  &lt; 2e-16 ***\nORIGIN_SZYSSZ08       1.244e-02  6.104e-03     2.039  0.04148 *  \nORIGIN_SZYSSZ09       1.385e+00  4.239e-03   326.757  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  2.298e-02  8.832e-05   260.146  &lt; 2e-16 ***\nlog(dist)            -6.947e-01  1.295e-04 -5363.438  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 26726668  on 14453  degrees of freedom\nAIC: 26818857\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4165837"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#destination-constrained",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#destination-constrained",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.7 Destination constrained",
    "text": "8.7 Destination constrained\nIn this section, we will fit a destination constrained SIM by using the code chunk below.\nThe general formula of Destination Constrained Spatial Interaction Model\n\n\ndecSIM &lt;- glm(formula = TRIPS ~ \n                DESTIN_SZ + \n                log(ORIGIN_AGE25_64) + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          10.8110189  0.0033476  3229.499  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.1775885  0.0041530    42.761  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.2064091  0.0040888    50.482  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -0.9406455  0.0060637  -155.127  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -1.1578100  0.0061804  -187.337  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -0.8861493  0.0059241  -149.584  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.7712447  0.0096070  -184.370  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -1.0707197  0.0067763  -158.009  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -0.9682250  0.0060435  -160.210  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.2612773  0.0043738    59.737  &lt; 2e-16 ***\nDESTIN_SZAMSZ11      -0.3714704  0.0086200   -43.094  &lt; 2e-16 ***\nDESTIN_SZAMSZ12       0.0250455  0.0049850     5.024 5.06e-07 ***\nDESTIN_SZBDSZ01       0.5154763  0.0037827   136.271  &lt; 2e-16 ***\nDESTIN_SZBDSZ02      -0.2843120  0.0049517   -57.417  &lt; 2e-16 ***\nDESTIN_SZBDSZ03      -0.0134646  0.0042692    -3.154  0.00161 ** \nDESTIN_SZBDSZ04       1.0014441  0.0034463   290.582  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.3721573  0.0038992    95.445  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.2013935  0.0042182    47.744  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -1.0642612  0.0092942  -114.508  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.7769370  0.0105721  -168.077  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.1944766  0.0065580  -182.141  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.2604946  0.0052044   -50.053  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.5905775  0.0055618  -106.184  &lt; 2e-16 ***\nDESTIN_SZBKSZ04      -0.0521573  0.0048274   -10.804  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.8258599  0.0057094  -144.650  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.8696763  0.0060934  -142.725  &lt; 2e-16 ***\nDESTIN_SZBKSZ07       0.2216292  0.0040334    54.949  &lt; 2e-16 ***\nDESTIN_SZBKSZ08      -1.1179375  0.0068749  -162.612  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.2888733  0.0049056   -58.886  &lt; 2e-16 ***\nDESTIN_SZBLSZ01      -0.4487061  0.0070226   -63.894  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6343096  0.0065174    97.326  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.3492337  0.0074135   181.997  &lt; 2e-16 ***\nDESTIN_SZBLSZ04      -0.0339193  0.0131568    -2.578  0.00993 ** \nDESTIN_SZBMSZ01      -0.3497912  0.0046910   -74.567  &lt; 2e-16 ***\nDESTIN_SZBMSZ02      -0.5995634  0.0048828  -122.792  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -0.8726401  0.0056851  -153.495  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -0.5350402  0.0048888  -109.442  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -0.4981814  0.0065971   -75.515  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -2.0640198  0.0123050  -167.739  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.3100988  0.0045283   -68.480  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.2748152  0.0062622  -203.573  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -2.8056325  0.0143532  -195.471  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -1.9166407  0.0089273  -214.693  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.7261160  0.0079281  -217.722  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.1495908  0.0077721  -147.912  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.5428008  0.0050824  -106.799  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.1422302  0.0076325  -149.653  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.2217517  0.0068685  -177.878  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -2.4074288  0.0107900  -223.116  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -2.6985491  0.0164771  -163.776  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.6183085  0.0054605  -113.233  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.4579175  0.0083271  -175.080  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.0775392  0.0075109  -143.463  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.6645303  0.0058070  -114.436  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.3449386  0.0039504    87.318  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.9360064  0.0077394  -120.941  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.6850065  0.0077761   -88.091  &lt; 2e-16 ***\nDESTIN_SZBSSZ01      -0.3144210  0.0045803   -68.647  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7531935  0.0051075  -147.469  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.1964072  0.0038255    51.342  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.0749897  0.0041584    18.033  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.8214254  0.0065659  -125.105  &lt; 2e-16 ***\nDESTIN_SZBTSZ03      -0.1672596  0.0047942   -34.888  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.7727273  0.0103706  -170.938  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.8162630  0.0067401  -121.105  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8159130  0.0059754  -136.546  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -2.1139258  0.0105602  -200.178  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.3565179  0.0086828  -156.231  &lt; 2e-16 ***\nDESTIN_SZCBSZ01      -4.6643129  0.3162417   -14.749  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -1.0088833  0.0080155  -125.866  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -1.1909317  0.0095262  -125.017  &lt; 2e-16 ***\nDESTIN_SZCHSZ02       0.0890035  0.0052277    17.025  &lt; 2e-16 ***\nDESTIN_SZCHSZ03       1.4883985  0.0039094   380.724  &lt; 2e-16 ***\nDESTIN_SZCKSZ01      -0.1684738  0.0047561   -35.422  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.4314614  0.0051537   -83.720  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.6413457  0.0038639   165.983  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.6370791  0.0059869  -106.412  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.4185112  0.0065348   -64.044  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.7003888  0.0045139   155.163  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.3751343  0.0047400    79.143  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -2.2913668  0.0133371  -171.804  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -1.0498490  0.0076548  -137.149  &lt; 2e-16 ***\nDESTIN_SZCLSZ04      -0.1118915  0.0044886   -24.928  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -1.3113032  0.0084067  -155.983  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.1661786  0.0040203    41.334  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.6429895  0.0052617  -122.202  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.4271702  0.0057208   -74.670  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.3882136  0.0063758    60.888  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -3.0106480  0.0348374   -86.420  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -1.4195712  0.0144110   -98.506  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -2.2368573  0.0161427  -138.567  &lt; 2e-16 ***\nDESTIN_SZGLSZ01       0.0013721  0.0051224     0.268  0.78881    \nDESTIN_SZGLSZ02      -0.3376674  0.0046195   -73.097  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.3659900  0.0038384    95.350  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.2969928  0.0038026    78.103  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.1786445  0.0038853    45.980  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.2979206  0.0038825    76.735  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.5701034  0.0051182  -111.388  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0387610  0.0061020  -170.233  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2264881  0.0043617   -51.926  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.2287090  0.0044851   -50.993  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.7896437  0.0054081  -146.010  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.2268880  0.0040336    56.249  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.4260784  0.0048967   -87.013  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.1027784  0.0051341    20.019  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -2.8571803  0.0262064  -109.026  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.0843635  0.0048222   -17.495  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.5197682  0.0051511  -100.904  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.6250311  0.0056619  -110.392  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.3937360  0.0065536   -60.080  &lt; 2e-16 ***\nDESTIN_SZJESZ05      -0.9748291  0.0097665   -99.814  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.3642736  0.0040600    89.722  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -1.1571882  0.0081557  -141.887  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.5955747  0.0078071   -76.286  &lt; 2e-16 ***\nDESTIN_SZJESZ09      -0.3629500  0.0053966   -67.256  &lt; 2e-16 ***\nDESTIN_SZJESZ10       0.7691552  0.0069348   110.912  &lt; 2e-16 ***\nDESTIN_SZJESZ11       0.9365743  0.0065801   142.335  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.4568805  0.0064536   -70.795  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.2880426  0.0051632   -55.788  &lt; 2e-16 ***\nDESTIN_SZJWSZ03       0.6680404  0.0039264   170.142  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       0.9492158  0.0037186   255.262  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.1938053  0.0060810   -31.871  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.3813164  0.0054551    69.900  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -1.2676010  0.0280038   -45.265  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.5013149  0.0044573   112.471  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.4161404  0.0033937   417.291  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.6909444  0.0051540  -134.059  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.8146023  0.0057129  -142.589  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.3956114  0.0065167  -214.161  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.9070281  0.0087370  -218.270  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -0.9293576  0.0071070  -130.766  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -2.5402234  0.0362062   -70.160  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.2017213  0.0065751  -182.769  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.6083433  0.0050916  -119.480  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -1.5186810  0.0204155   -74.389  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -1.4601772  0.0198347   -73.617  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -1.1554609  0.0111345  -103.773  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.9919337  0.0250838  -119.277  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -1.1705809  0.0077128  -151.771  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.9380957  0.0060321  -155.517  &lt; 2e-16 ***\nDESTIN_SZMPSZ03      -0.1761013  0.0046389   -37.962  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -2.4525115  0.0199630  -122.853  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -3.6605524  0.0447752   -81.754  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -2.0082021  0.0108736  -184.686  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.2387489  0.0076141  -162.691  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -1.8054361  0.0249540   -72.351  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -2.9500517  0.0428601   -68.830  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.4089022  0.0044288   -92.327  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.6865452  0.0052770  -130.102  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.7333670  0.0054243  -135.199  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -2.2095097  0.0106997  -206.503  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.8721104  0.0089058  -210.212  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -1.8756618  0.0153008  -122.586  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.9435337  0.0067224  -140.356  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.3458476  0.0040152    86.134  &lt; 2e-16 ***\nDESTIN_SZPGSZ04      -0.0271485  0.0044805    -6.059 1.37e-09 ***\nDESTIN_SZPGSZ05      -0.8920273  0.0070730  -126.117  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.2153087  0.0068270   -31.538  &lt; 2e-16 ***\nDESTIN_SZPLSZ02      -1.3646116  0.0131155  -104.046  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.0869245  0.0095838    -9.070  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -0.2574560  0.0093336   -27.584  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.7186364  0.0116835   -61.509  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       1.1326963  0.0049977   226.643  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       1.6516855  0.0064492   256.106  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       0.8504093  0.0077034   110.394  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       1.6891381  0.0075802   222.836  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       0.7402750  0.0115948    63.845  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -1.0257636  0.0084652  -121.175  &lt; 2e-16 ***\nDESTIN_SZPRSZ02      -0.2028503  0.0049839   -40.701  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.5560483  0.0038496   144.442  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.6824142  0.0079047   -86.330  &lt; 2e-16 ***\nDESTIN_SZPRSZ05       0.0316117  0.0044946     7.033 2.02e-12 ***\nDESTIN_SZPRSZ06       0.3706283  0.0052006    71.267  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.4740460  0.0117304  -125.661  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.7869180  0.0064862  -121.321  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.2790095  0.0085392  -149.781  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.4989188  0.0073423  -204.149  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -0.9334132  0.0064035  -145.765  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.0506142  0.0065335  -160.805  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -0.9765013  0.0058471  -167.006  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.2206088  0.0063560  -192.042  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6794007  0.0108727  -154.460  &lt; 2e-16 ***\nDESTIN_SZQTSZ08      -0.1214413  0.0047980   -25.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.5252607  0.0057371   -91.555  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.5981644  0.0054192  -110.378  &lt; 2e-16 ***\nDESTIN_SZQTSZ11      -0.0766021  0.0053446   -14.333  &lt; 2e-16 ***\nDESTIN_SZQTSZ12      -0.6153017  0.0070680   -87.054  &lt; 2e-16 ***\nDESTIN_SZQTSZ13      -0.1690535  0.0051315   -32.944  &lt; 2e-16 ***\nDESTIN_SZQTSZ14      -0.5398362  0.0062233   -86.744  &lt; 2e-16 ***\nDESTIN_SZQTSZ15      -0.1873015  0.0073132   -25.611  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -0.5875494  0.0071798   -81.833  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -2.0856090  0.0188789  -110.473  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.6183708  0.0162319  -161.310  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -3.1882190  0.0326141   -97.756  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.5981974  0.0135074  -192.353  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -1.9741504  0.0154961  -127.396  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -3.1547734  0.0256310  -123.084  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -0.3097949  0.0060601   -51.121  &lt; 2e-16 ***\nDESTIN_SZSBSZ02      -1.1229132  0.0076338  -147.097  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.6289715  0.0041400   151.926  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.1419430  0.0051357    27.638  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -0.9256413  0.0071963  -128.628  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -2.3487368  0.0221611  -105.984  &lt; 2e-16 ***\nDESTIN_SZSBSZ07      -0.7864630  0.0181706   -43.282  &lt; 2e-16 ***\nDESTIN_SZSBSZ08       1.3240051  0.0051598   256.599  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.8431156  0.0048330   174.449  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.2385874  0.0046618   -51.180  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.5439188  0.0036932   147.276  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.6715716  0.0054222  -123.856  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.3601932  0.0047508   -75.818  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.6088413  0.0057017  -106.782  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.9477507  0.0226797  -129.973  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.5100640  0.0058280   -87.519  &lt; 2e-16 ***\nDESTIN_SZSGSZ02      -0.0439941  0.0051633    -8.520  &lt; 2e-16 ***\nDESTIN_SZSGSZ03      -0.3700648  0.0047152   -78.483  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.3021335  0.0046865   -64.468  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -2.2253287  0.0097908  -227.288  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.2963602  0.0037948    78.097  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.5940373  0.0051371  -115.637  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -1.4528976  0.0257790   -56.360  &lt; 2e-16 ***\nDESTIN_SZSKSZ01      -0.0374952  0.0066885    -5.606 2.07e-08 ***\nDESTIN_SZSKSZ02       0.7271418  0.0050281   144.617  &lt; 2e-16 ***\nDESTIN_SZSKSZ03      -0.0640794  0.0059146   -10.834  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.5610767  0.0139676   -40.170  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.1510974  0.0104871    14.408  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.5823031  0.0083356   -69.858  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.8166665  0.0070329  -116.122  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -2.3241796  0.0127215  -182.696  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -2.8157635  0.0366840   -76.757  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -2.1005978  0.0250842   -83.742  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.1246250  0.0213690   -99.425  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.4571092  0.0150031   -97.121  &lt; 2e-16 ***\nDESTIN_SZTMSZ01      -0.1234559  0.0055152   -22.385  &lt; 2e-16 ***\nDESTIN_SZTMSZ02       1.5961628  0.0032599   489.635  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       0.6977233  0.0037138   187.875  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       0.8606606  0.0037592   228.947  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       0.3750655  0.0051281    73.140  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -1.2624562  0.0066979  -188.485  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -2.0761581  0.0096538  -215.062  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -2.1128125  0.0115717  -182.584  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -1.2417494  0.0068502  -181.271  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.7094356  0.0055768  -127.211  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.1491604  0.0037260    40.032  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.4973355  0.0054878   -90.626  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.5160395  0.0071592  -211.761  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -0.9196565  0.0056750  -162.054  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.2710649  0.0062637   -43.276  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -2.0198681  0.0116556  -173.296  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.4881412  0.0085532  -173.987  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.5901273  0.0059394   -99.358  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -1.1215711  0.0084488  -132.749  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.4837089  0.0050905   -95.022  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8653927  0.0061326  -141.113  &lt; 2e-16 ***\nDESTIN_SZTSSZ01      -0.5515103  0.0208541   -26.446  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       0.8373778  0.0093757    89.314  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.7021888  0.0064394   264.340  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.5355016  0.0067855   226.292  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       1.6932319  0.0073725   229.668  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       0.4567808  0.0137927    33.118  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       1.3967640  0.0045392   307.711  &lt; 2e-16 ***\nDESTIN_SZWCSZ02      -0.4560229  0.0122949   -37.090  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -2.0710051  0.0325121   -63.699  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.5137342  0.0034774   435.310  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.3005475  0.0055149   -54.497  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       1.2514543  0.0036112   346.550  &lt; 2e-16 ***\nDESTIN_SZWDSZ04      -0.1702528  0.0058295   -29.205  &lt; 2e-16 ***\nDESTIN_SZWDSZ05      -0.0005419  0.0053911    -0.101  0.91994    \nDESTIN_SZWDSZ06       0.5203361  0.0040318   129.058  &lt; 2e-16 ***\nDESTIN_SZWDSZ07       0.6006472  0.0061745    97.279  &lt; 2e-16 ***\nDESTIN_SZWDSZ08       0.6650867  0.0060867   109.268  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       0.6237312  0.0044830   139.132  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       1.0471638  0.0038255   273.732  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2341114  0.0048213    48.558  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0916446  0.0051335   -17.852  &lt; 2e-16 ***\nDESTIN_SZYSSZ04      -0.0085536  0.0048684    -1.757  0.07892 .  \nDESTIN_SZYSSZ05      -1.5775071  0.0100297  -157.283  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.8130307  0.0098617  -183.846  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -1.1703963  0.0111525  -104.945  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.5253514  0.0039556   132.813  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.4353435  0.0038890   111.943  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.2249135  0.0001404  1602.353  &lt; 2e-16 ***\nlog(dist)            -0.6989356  0.0001287 -5431.279  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 26208384  on 14452  degrees of freedom\nAIC: 26300575\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.4972985"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#doubly-constrained",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#doubly-constrained",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.8 Doubly constrained",
    "text": "8.8 Doubly constrained\nIn this section, we will fit a doubly constrained SIM by using the code chunk below.\nThe general formula of Doubly Constrained Spatial Interaction Model\n\n\ndbcSIM &lt;- glm(formula = TRIPS ~ \n                ORIGIN_SZ + \n                DESTIN_SZ + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     12.4165310  0.0043949  2825.242  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  0.9496891  0.0045740   207.630  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.5519174  0.0046672   118.253  &lt; 2e-16 ***\nORIGIN_SZAMSZ04  0.1028140  0.0052468    19.596  &lt; 2e-16 ***\nORIGIN_SZAMSZ05  0.0822549  0.0058663    14.022  &lt; 2e-16 ***\nORIGIN_SZAMSZ06  0.6617809  0.0052580   125.861  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.9508298  0.0097681   -97.340  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.7271779  0.0090946   -79.958  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.4896781  0.0055203    88.704  &lt; 2e-16 ***\nORIGIN_SZAMSZ10  0.4819428  0.0048175   100.040  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.7719841  0.0130695  -135.582  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.7679107  0.0108777  -162.526  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.8314812  0.0045187   184.010  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.4305836  0.0052535    81.961  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.8009370  0.0046384   172.676  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4562985  0.0040456   359.971  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.4501939  0.0046960    95.867  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.7745026  0.0047424   163.314  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -1.1784123  0.0098105  -120.117  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.9830996  0.0091135  -107.873  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.3042966  0.0067086   -45.359  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.4801541  0.0054160    88.655  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  0.7823931  0.0052007   150.440  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.1292545  0.0061735   -20.937  &lt; 2e-16 ***\nORIGIN_SZBKSZ05 -0.0258584  0.0060192    -4.296 1.74e-05 ***\nORIGIN_SZBKSZ06  0.1994719  0.0061206    32.590  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.7434860  0.0046598   159.553  &lt; 2e-16 ***\nORIGIN_SZBKSZ08  0.1625007  0.0055219    29.428  &lt; 2e-16 ***\nORIGIN_SZBKSZ09 -0.0864293  0.0059533   -14.518  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -2.1022485  0.0150316  -139.855  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.9460181  0.0195760  -150.491  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -4.9412872  0.0398540  -123.985  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.8143593  0.0239209  -117.653  &lt; 2e-16 ***\nORIGIN_SZBMSZ01 -0.0264561  0.0053639    -4.932 8.13e-07 ***\nORIGIN_SZBMSZ02 -0.8656513  0.0068511  -126.353  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.1723467  0.0059613   -28.911  &lt; 2e-16 ***\nORIGIN_SZBMSZ04  0.2169844  0.0053578    40.499  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -2.0252956  0.0126107  -160.602  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -1.7642018  0.0163931  -107.619  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.3271629  0.0058137   -56.274  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -0.2533255  0.0059335   -42.694  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -0.7712635  0.0087939   -87.704  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -1.0098048  0.0092519  -109.145  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -0.3816187  0.0067302   -56.702  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -0.6666616  0.0095680   -69.676  &lt; 2e-16 ***\nORIGIN_SZBMSZ13 -0.0076108  0.0059040    -1.289  0.19737    \nORIGIN_SZBMSZ14 -0.1682476  0.0069391   -24.246  &lt; 2e-16 ***\nORIGIN_SZBMSZ15  0.0904585  0.0062822    14.399  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -1.1808741  0.0092258  -127.997  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.7189127  0.0158408  -108.512  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.4294645  0.0058051    73.980  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.5028906  0.0068169    73.771  &lt; 2e-16 ***\nORIGIN_SZBPSZ03  0.6656178  0.0066126   100.658  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.5203612  0.0053224    97.769  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.5377769  0.0047907   112.256  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -1.2327809  0.0094950  -129.835  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.9035255  0.0088739  -101.818  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.1210027  0.0053990    22.412  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.4618449  0.0048641    94.951  &lt; 2e-16 ***\nORIGIN_SZBSSZ03  0.2160739  0.0047835    45.170  &lt; 2e-16 ***\nORIGIN_SZBTSZ01 -0.1108042  0.0055599   -19.929  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.8911221  0.0079213  -112.498  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.2203980  0.0059325   -37.151  &lt; 2e-16 ***\nORIGIN_SZBTSZ04 -0.6427946  0.0105438   -60.964  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -1.4662312  0.0111784  -131.166  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -0.6105884  0.0073456   -83.123  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -1.9041317  0.0132781  -143.404  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -1.0627939  0.0095982  -110.728  &lt; 2e-16 ***\nORIGIN_SZCBSZ01 -2.9365941  0.0548632   -53.526  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -1.5313555  0.0134599  -113.772  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -1.2034494  0.0119468  -100.734  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.8299415  0.0081984  -101.232  &lt; 2e-16 ***\nORIGIN_SZCHSZ03 -0.5143946  0.0061944   -83.042  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.2372583  0.0053612    44.255  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  0.9124836  0.0054472   167.515  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  0.7237808  0.0048401   149.539  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.6884022  0.0050169   336.540  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  1.3932005  0.0062346   223.464  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  1.0670053  0.0066112   161.394  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.8602837  0.0079240  -108.567  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.3853421  0.0137444  -100.793  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -0.8582608  0.0081177  -105.727  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.7836027  0.0046427   168.782  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -1.8121756  0.0148960  -121.655  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.8296870  0.0043909   188.955  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.2325219  0.0057432   -40.487  &lt; 2e-16 ***\nORIGIN_SZCLSZ08  0.2714336  0.0062625    43.342  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -2.2223744  0.0160946  -138.082  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -4.0704970  0.0834192   -48.796  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -3.4529031  0.0738295   -46.769  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -2.8301983  0.0313085   -90.397  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.4674986  0.0093137  -157.563  &lt; 2e-16 ***\nORIGIN_SZGLSZ02  0.2749369  0.0050051    54.931  &lt; 2e-16 ***\nORIGIN_SZGLSZ03  0.0781954  0.0049748    15.718  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.8167797  0.0043260   188.808  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.5277509  0.0044879   117.595  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.2323885  0.0048555    47.861  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.5707182  0.0048256   118.268  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.4231170  0.0052149    81.136  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.9341168  0.0044128   211.681  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.2192790  0.0043790   278.437  &lt; 2e-16 ***\nORIGIN_SZHGSZ06  0.0490041  0.0054961     8.916  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.6337041  0.0045735   138.559  &lt; 2e-16 ***\nORIGIN_SZHGSZ08  0.0312612  0.0054684     5.717 1.09e-08 ***\nORIGIN_SZHGSZ09 -0.6985397  0.0071800   -97.289  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -2.9958967  0.0422303   -70.942  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4363431  0.0051329    85.010  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.3460900  0.0051372    67.370  &lt; 2e-16 ***\nORIGIN_SZJESZ03  0.2928005  0.0055108    53.132  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.1924298  0.0093540  -127.478  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -2.0178136  0.0139479  -144.668  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.1637633  0.0050685    32.310  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.8227460  0.0119383  -152.680  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -1.1556281  0.0117870   -98.043  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4766229  0.0052813    90.248  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -2.6868992  0.0186864  -143.789  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -3.0618150  0.0199755  -153.278  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.4417418  0.0068611    64.383  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.9738087  0.0047905   203.281  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.1548028  0.0045180   255.599  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.9078417  0.0046668   194.532  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -1.7092500  0.0127422  -134.141  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.3284287  0.0109785  -121.002  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.3231549  0.0281427   -82.549  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.9386127  0.0046041   421.059  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.3987549  0.0042610   328.266  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.2617735  0.0050089    52.261  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.4325093  0.0064279   -67.286  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.2787173  0.0060380   -46.161  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -1.9432693  0.0119163  -163.076  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -0.5420067  0.0085529   -63.371  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -4.2949009  0.1857686   -23.120  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -0.8576946  0.0085178  -100.694  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -1.3840925  0.0092323  -149.918  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.8108510  0.0392356   -71.640  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -1.6745388  0.0296543   -56.469  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -0.8193738  0.0106631   -76.842  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -1.5088267  0.0172032   -87.706  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.9860154  0.0085053  -115.929  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -0.5958875  0.0070097   -85.008  &lt; 2e-16 ***\nORIGIN_SZMPSZ03 -0.0490122  0.0054582    -8.980  &lt; 2e-16 ***\nORIGIN_SZMUSZ02 -3.5233367  0.1037749   -33.952  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -2.6451541  0.0353125   -74.907  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -2.7710546  0.0232841  -119.011  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.6123404  0.0079083   -77.430  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -2.9257445  0.0496704   -58.903  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -3.3260031  0.0557966   -59.609  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.6421306  0.0046037   139.482  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.4251550  0.0065890   -64.525  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -1.0765622  0.0078766  -136.679  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -1.2289504  0.0091468  -134.358  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.3551389  0.0158219  -148.853  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.1518212  0.0154825     9.806  &lt; 2e-16 ***\nORIGIN_SZPGSZ02 -0.4062609  0.0073780   -55.064  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.8976913  0.0046122   194.636  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.1161685  0.0045850   243.437  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.4794249  0.0060213    79.621  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.8322377  0.0107898   -77.132  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.2968937  0.0149841   -86.551  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -3.2744991  0.0374541   -87.427  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -3.5423615  0.0372570   -95.079  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.4343705  0.0227807  -106.861  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  0.8052461  0.0056124   143.476  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -1.8042362  0.0128222  -140.712  &lt; 2e-16 ***\nORIGIN_SZPNSZ03 -2.6363996  0.0200058  -131.782  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -4.8427070  0.0320126  -151.275  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -3.6613775  0.0285686  -128.161  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.5645384  0.0117126   -48.199  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  0.9145886  0.0048137   189.998  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4478971  0.0048102    93.113  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.5312444  0.0079019   -67.230  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  1.1462662  0.0045250   253.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -0.7392744  0.0090347   -81.826  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -2.1667862  0.0162528  -133.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ08 -0.1327079  0.0065712   -20.195  &lt; 2e-16 ***\nORIGIN_SZQTSZ01  0.1062151  0.0071538    14.847  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.4993990  0.0064382   -77.568  &lt; 2e-16 ***\nORIGIN_SZQTSZ03  0.1161844  0.0058822    19.752  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -0.8102612  0.0072742  -111.389  &lt; 2e-16 ***\nORIGIN_SZQTSZ05 -0.0417272  0.0061917    -6.739 1.59e-11 ***\nORIGIN_SZQTSZ06 -0.2521417  0.0066449   -37.945  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.2395975  0.0097496  -127.143  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.1105467  0.0059364   -18.622  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.5078461  0.0067895   -74.798  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.3866593  0.0066995   -57.714  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -1.5264609  0.0099770  -152.998  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -1.3866518  0.0106887  -129.730  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.3764286  0.0066707   -56.430  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.4907399  0.0100120  -148.896  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -1.0552239  0.0108792   -96.994  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -1.3136074  0.0126986  -103.445  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.2418276  0.0085509   -28.281  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.9263747  0.0324968   -90.051  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -2.2980940  0.0278202   -82.605  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -2.4663765  0.0238674  -103.336  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -3.1853677  0.0556939   -57.194  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -1.5695490  0.0166684   -94.163  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.7674590  0.0061811   124.163  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.7307279  0.0084105   -86.883  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.5920074  0.0050167   118.008  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3684857  0.0058575    62.908  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.0036863  0.0068459    -0.538  0.59026    \nORIGIN_SZSBSZ06 -1.1939284  0.0181541   -65.766  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.4896579  0.0135618   -36.106  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -2.1221691  0.0127258  -166.762  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -1.2032410  0.0089611  -134.273  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.0721820  0.0045336   236.498  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.0808012  0.0042923   251.801  &lt; 2e-16 ***\nORIGIN_SZSESZ04  1.0137448  0.0050668   200.076  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.1678679  0.0060206   -27.882  &lt; 2e-16 ***\nORIGIN_SZSESZ06  0.9165834  0.0048323   189.677  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -2.2499789  0.0196327  -114.603  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.9369800  0.0087282  -107.351  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.1690716  0.0097131  -120.360  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.2604352  0.0052709    49.410  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.3468823  0.0048897    70.942  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -1.5927797  0.0106308  -149.827  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.3605651  0.0046361    77.774  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.5333873  0.0063119   -84.504  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.2706750  0.0082836   -32.676  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  0.0970953  0.0063378    15.320  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.6954342  0.0082538   -84.256  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -2.3863580  0.0284607   -83.847  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -1.5443140  0.0179059   -86.246  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.9450656  0.0307283   -95.842  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.5739349  0.0077851   -73.722  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -1.6136735  0.0160199  -100.729  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -2.6034976  0.0489378   -53.200  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -1.2770601  0.0229815   -55.569  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.0110399  0.0287527   -69.943  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.7720116  0.0180394   -98.230  &lt; 2e-16 ***\nORIGIN_SZTMSZ01  0.1254729  0.0060924    20.595  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.6667504  0.0039836   418.403  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  1.0941176  0.0042911   254.976  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.3209520  0.0050349    63.746  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -0.8155124  0.0079342  -102.785  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -1.4237298  0.0104636  -136.064  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -1.2718890  0.0098660  -128.916  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -1.7960517  0.0134675  -133.362  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.3508142  0.0073556   -47.694  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.3841699  0.0064137   -59.898  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5315265  0.0044497   119.451  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.4669723  0.0062160   -75.124  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.0617169  0.0058830   -10.491  &lt; 2e-16 ***\nORIGIN_SZTPSZ05  0.0713309  0.0062133    11.480  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.6800356  0.0069456    97.909  &lt; 2e-16 ***\nORIGIN_SZTPSZ07 -0.0432782  0.0064382    -6.722 1.79e-11 ***\nORIGIN_SZTPSZ08 -0.6976429  0.0092416   -75.490  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.3708833  0.0063548   -58.363  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -0.4063575  0.0077803   -52.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ11  0.1040282  0.0056115    18.538  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.5104672  0.0066261   -77.039  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -3.5036830  0.0487290   -71.901  &lt; 2e-16 ***\nORIGIN_SZTSSZ02 -0.0386819  0.0094886    -4.077 4.57e-05 ***\nORIGIN_SZTSSZ03 -0.3862387  0.0095139   -40.597  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.6380676  0.0099905   -63.867  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -2.7354613  0.0162414  -168.425  &lt; 2e-16 ***\nORIGIN_SZTSSZ06 -2.6310865  0.0255772  -102.868  &lt; 2e-16 ***\nORIGIN_SZWCSZ01 -1.1561047  0.0087394  -132.286  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.6956217  0.0319117   -84.471  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -4.3526889  0.1241082   -35.072  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  0.8712417  0.0043720   199.277  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.9119539  0.0050326   181.210  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.6205678  0.0045250   358.136  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  1.2081941  0.0054272   222.618  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.4284783  0.0052752    81.224  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.9018716  0.0049820   181.028  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -0.6444820  0.0084731   -76.062  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.8764983  0.0082622  -106.085  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.3292589  0.0048663   273.158  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.4780462  0.0058489   -81.733  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.9323419  0.0054402   171.380  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  2.0577240  0.0046737   440.274  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8697472  0.0047269   184.000  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.1662764  0.0060376    27.540  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.8115617  0.0109084   -74.398  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.8971248  0.0119220   -75.250  &lt; 2e-16 ***\nORIGIN_SZYSSZ08 -0.2738680  0.0063553   -43.093  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.2274518  0.0044951   273.066  &lt; 2e-16 ***\nDESTIN_SZAMSZ02 -0.0516322  0.0042829   -12.055  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.0801823  0.0041904    19.135  &lt; 2e-16 ***\nDESTIN_SZAMSZ04 -0.9282211  0.0061322  -151.368  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -1.0794168  0.0062543  -172.588  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -0.8839603  0.0060851  -145.267  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.5835093  0.0096846  -163.508  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.9756903  0.0068829  -141.756  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.0362692  0.0061651  -168.087  &lt; 2e-16 ***\nDESTIN_SZAMSZ10 -0.1227646  0.0044788   -27.410  &lt; 2e-16 ***\nDESTIN_SZAMSZ11 -0.4802374  0.0088108   -54.506  &lt; 2e-16 ***\nDESTIN_SZAMSZ12  0.2142621  0.0050653    42.300  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  0.3582789  0.0039578    90.524  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.4368229  0.0051384   -85.012  &lt; 2e-16 ***\nDESTIN_SZBDSZ03 -0.1568727  0.0044329   -35.388  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  0.6731669  0.0036215   185.882  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.3647198  0.0040496    90.062  &lt; 2e-16 ***\nDESTIN_SZBDSZ06  0.0589240  0.0044352    13.286  &lt; 2e-16 ***\nDESTIN_SZBDSZ07 -0.6648168  0.0095742   -69.438  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.7214136  0.0106600  -161.483  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.2688264  0.0067263  -188.637  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.3912129  0.0055446   -70.558  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.8663392  0.0058693  -147.605  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.1247273  0.0051254   -24.335  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.7407774  0.0059120  -125.300  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -0.9934643  0.0063345  -156.834  &lt; 2e-16 ***\nDESTIN_SZBKSZ07  0.0882230  0.0042928    20.551  &lt; 2e-16 ***\nDESTIN_SZBKSZ08 -1.1134447  0.0070752  -157.372  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.1788171  0.0051327   -34.839  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.7696433  0.0071898  -107.047  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.4076650  0.0068001    59.950  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.5398488  0.0078230   196.836  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.3499486  0.0136985   -25.546  &lt; 2e-16 ***\nDESTIN_SZBMSZ01 -0.2114705  0.0048311   -43.773  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.3316806  0.0049958   -66.391  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.5134774  0.0058534   -87.723  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.2205274  0.0051028   -43.217  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.2101165  0.0067710   -31.032  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.3832385  0.0124821  -110.818  &lt; 2e-16 ***\nDESTIN_SZBMSZ07 -0.0133462  0.0046787    -2.853  0.00434 ** \nDESTIN_SZBMSZ08 -0.9056756  0.0063868  -141.805  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -2.3175407  0.0144523  -160.358  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.3973725  0.0090463  -154.470  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.3950206  0.0080459  -173.383  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.6882789  0.0081539   -84.411  &lt; 2e-16 ***\nDESTIN_SZBMSZ13 -0.2729120  0.0052969   -51.523  &lt; 2e-16 ***\nDESTIN_SZBMSZ14 -0.7581980  0.0080215   -94.521  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.9323237  0.0071093  -131.142  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -2.0655530  0.0108490  -190.391  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -2.5124893  0.0165366  -151.935  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -0.8203274  0.0057682  -142.216  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -1.5284265  0.0087447  -174.783  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.2434382  0.0080852  -153.792  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.7778558  0.0060900  -127.727  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.1782204  0.0042331    42.101  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -0.6758807  0.0079728   -84.773  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.5029450  0.0081151   -61.976  &lt; 2e-16 ***\nDESTIN_SZBSSZ01 -0.1269916  0.0046949   -27.049  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.7536917  0.0051895  -145.233  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.2747969  0.0039115    70.254  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.1708577  0.0043381    39.385  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.6820190  0.0067243  -101.427  &lt; 2e-16 ***\nDESTIN_SZBTSZ03  0.0610599  0.0049825    12.255  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -1.3199639  0.0107063  -123.288  &lt; 2e-16 ***\nDESTIN_SZBTSZ05 -0.4174991  0.0069221   -60.314  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.5260242  0.0061145   -86.029  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.6678047  0.0106335  -156.844  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.7999935  0.0089175   -89.711  &lt; 2e-16 ***\nDESTIN_SZCBSZ01 -5.6321332  0.3162476   -17.809  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.9342781  0.0081409  -114.763  &lt; 2e-16 ***\nDESTIN_SZCHSZ01 -1.2808546  0.0096774  -132.355  &lt; 2e-16 ***\nDESTIN_SZCHSZ02  0.0067332  0.0054322     1.239  0.21516    \nDESTIN_SZCHSZ03  1.0988838  0.0041378   265.570  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.3192235  0.0050632   -63.048  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.7776453  0.0055279  -140.676  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.2772358  0.0042541    65.170  &lt; 2e-16 ***\nDESTIN_SZCKSZ04 -1.3842048  0.0065159  -212.436  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.2051808  0.0076814  -156.897  &lt; 2e-16 ***\nDESTIN_SZCKSZ06  0.1321955  0.0061568    21.472  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.1942449  0.0049977    38.867  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -2.0828648  0.0134597  -154.749  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.8823728  0.0078307  -112.681  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.2311432  0.0047194   -48.977  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -1.0113430  0.0085536  -118.237  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.0694682  0.0042166    16.475  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4953961  0.0054184   -91.429  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.3849563  0.0061404   -62.693  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.4201808  0.0067112    62.609  &lt; 2e-16 ***\nDESTIN_SZDTSZ02 -2.6513032  0.0348725   -76.029  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -1.5192228  0.0144477  -105.153  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -2.2041951  0.0161726  -136.292  &lt; 2e-16 ***\nDESTIN_SZGLSZ01 -0.0139744  0.0052464    -2.664  0.00773 ** \nDESTIN_SZGLSZ02 -0.2850816  0.0047467   -60.059  &lt; 2e-16 ***\nDESTIN_SZGLSZ03  0.3511872  0.0039473    88.969  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.2909117  0.0039436    73.769  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.1845361  0.0040011    46.121  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.1418382  0.0039875    35.571  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.7233151  0.0052374  -138.105  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.1918463  0.0062129  -191.834  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.4380360  0.0044839   -97.691  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5671024  0.0046427  -122.149  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.8271411  0.0054935  -150.566  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.0721800  0.0041589    17.356  &lt; 2e-16 ***\nDESTIN_SZHGSZ08 -0.4297429  0.0050021   -85.913  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.2085461  0.0052544   -39.690  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -2.9169699  0.0262698  -111.039  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.2822473  0.0051166   -55.163  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.6761389  0.0053635  -126.063  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.7371756  0.0058983  -124.980  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -0.4593491  0.0067970   -67.581  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -1.1418012  0.0099049  -115.277  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.1759680  0.0042791    41.123  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -1.2260587  0.0082714  -148.229  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.8547001  0.0080417  -106.283  &lt; 2e-16 ***\nDESTIN_SZJESZ09 -0.4306353  0.0057006   -75.542  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.6584971  0.0073664    89.392  &lt; 2e-16 ***\nDESTIN_SZJESZ11  0.9661208  0.0070491   137.056  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -0.9128436  0.0069529  -131.290  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.7285851  0.0054839  -132.859  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.2601455  0.0043215    60.198  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.6860274  0.0041135   166.775  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -0.4684576  0.0062875   -74.506  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.2459774  0.0057575   -42.723  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -1.8854234  0.0287721   -65.529  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.5523308  0.0051054  -108.186  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.8818747  0.0037800   233.301  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.5814386  0.0052711  -110.308  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.7090577  0.0058161  -121.914  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -1.2191910  0.0065984  -184.772  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.6961428  0.0087866  -193.038  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.6927144  0.0073574   -94.153  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -2.2967464  0.0362605   -63.340  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.9536980  0.0066777  -142.819  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.4565596  0.0051736   -88.249  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -1.7277135  0.0207336   -83.329  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.7155417  0.0210080   -81.661  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -1.3694928  0.0114174  -119.948  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -2.7183729  0.0252678  -107.582  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.8051991  0.0078564  -102.490  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.7627000  0.0061386  -124.246  &lt; 2e-16 ***\nDESTIN_SZMPSZ03 -0.0649484  0.0047787   -13.591  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -1.9549128  0.0200160   -97.667  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -3.3048398  0.0448053   -73.760  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.6454847  0.0109337  -150.497  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -1.1389723  0.0077396  -147.161  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -2.0264109  0.0250226   -80.983  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.3496282  0.0428989   -78.082  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.3407614  0.0045493   -74.905  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.4987695  0.0053942   -92.465  &lt; 2e-16 ***\nDESTIN_SZNVSZ03 -0.4936107  0.0055158   -89.491  &lt; 2e-16 ***\nDESTIN_SZNVSZ04 -1.9141281  0.0107557  -177.964  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -1.5378263  0.0089577  -171.677  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -1.7744485  0.0194346   -91.304  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -0.9282918  0.0069006  -134.523  &lt; 2e-16 ***\nDESTIN_SZPGSZ03  0.0885025  0.0042145    21.000  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.3879375  0.0046862   -82.784  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -0.9649873  0.0074625  -129.311  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.6159175  0.0070845   -86.939  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.7551386  0.0133081  -131.885  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.1378379  0.0098704   -13.965  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -0.1411200  0.0096446   -14.632  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.8483196  0.0119048   -71.259  &lt; 2e-16 ***\nDESTIN_SZPNSZ01 -0.1579087  0.0057330   -27.544  &lt; 2e-16 ***\nDESTIN_SZPNSZ02  1.0243480  0.0076680   133.587  &lt; 2e-16 ***\nDESTIN_SZPNSZ03  0.0451598  0.0081444     5.545 2.94e-08 ***\nDESTIN_SZPNSZ04  1.8941928  0.0087479   216.530  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  1.0341581  0.0130830    79.046  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.4038513  0.0086911  -161.527  &lt; 2e-16 ***\nDESTIN_SZPRSZ02 -0.4942539  0.0052403   -94.319  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.4219510  0.0040281   104.751  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.4841099  0.0083498   -57.979  &lt; 2e-16 ***\nDESTIN_SZPRSZ05 -0.2988481  0.0047512   -62.899  &lt; 2e-16 ***\nDESTIN_SZPRSZ06  0.0012333  0.0054530     0.226  0.82108    \nDESTIN_SZPRSZ07 -1.1417482  0.0118845   -96.070  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.8259249  0.0066757  -123.720  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -1.2134330  0.0089222  -136.002  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -1.2397956  0.0074512  -166.388  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.7448659  0.0066511  -111.992  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.6243112  0.0066812   -93.443  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.6102589  0.0060458  -100.940  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.9164592  0.0065095  -140.788  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -1.4600643  0.0109976  -132.762  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.0004582  0.0050178     0.091  0.92724    \nDESTIN_SZQTSZ09 -0.5226213  0.0058901   -88.728  &lt; 2e-16 ***\nDESTIN_SZQTSZ10 -0.3867082  0.0055876   -69.208  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.0260589  0.0055065     4.732 2.22e-06 ***\nDESTIN_SZQTSZ12 -0.3387634  0.0072779   -46.547  &lt; 2e-16 ***\nDESTIN_SZQTSZ13 -0.0512118  0.0053664    -9.543  &lt; 2e-16 ***\nDESTIN_SZQTSZ14 -0.2555346  0.0063792   -40.057  &lt; 2e-16 ***\nDESTIN_SZQTSZ15 -0.1820651  0.0077537   -23.481  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.4641196  0.0072515   -64.003  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -2.0929548  0.0189106  -110.676  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.7885682  0.0163492  -109.398  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -3.1669721  0.0326320   -97.051  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -2.0306835  0.0135749  -149.591  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.5113470  0.0155637   -97.107  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -2.3683855  0.0259334   -91.326  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -0.5841063  0.0068588   -85.162  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -1.0777704  0.0078288  -137.667  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.4734371  0.0045880   103.190  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.0546094  0.0057517     9.494  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -0.9588198  0.0075242  -127.431  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -1.8528944  0.0234040   -79.170  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -1.8403768  0.0195878   -93.955  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  0.9205969  0.0055698   165.285  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.5166486  0.0051939    99.472  &lt; 2e-16 ***\nDESTIN_SZSESZ02 -0.5728211  0.0048270  -118.669  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.2554787  0.0038335    66.645  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -0.8982794  0.0056698  -158.432  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.4661655  0.0048578   -95.962  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.8392849  0.0059198  -141.777  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.2182325  0.0227089  -141.717  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.2751206  0.0059581   -46.176  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.2951806  0.0052515   -56.209  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4469508  0.0048181   -92.766  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.2842809  0.0047961   -59.274  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -2.0643753  0.0098252  -210.109  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.2501247  0.0038873    64.343  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.5743750  0.0052184  -110.067  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -1.1030669  0.0259113   -42.571  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.5462538  0.0071443   -76.460  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.2965180  0.0056707    52.290  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.4521490  0.0062177   -72.719  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -0.6665145  0.0148252   -44.958  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.1474142  0.0121958   -12.087  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.8855715  0.0084587  -104.693  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -1.1787840  0.0071355  -165.200  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.6435064  0.0128822  -127.580  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -3.4388625  0.0367651   -93.536  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.5809435  0.0256853  -100.483  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -2.4887189  0.0214441  -116.056  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -1.7965101  0.0152160  -118.067  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.3251891  0.0058067   -56.002  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.1558743  0.0034703   333.080  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.4525619  0.0039244   115.319  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  0.8223271  0.0040060   205.274  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.3880619  0.0054308    71.456  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.9533112  0.0067853  -140.496  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.5909451  0.0097396  -163.348  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.6470771  0.0116598  -141.261  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -1.0686173  0.0069848  -152.993  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.5180183  0.0056886   -91.063  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.2160781  0.0038283    56.443  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.2479956  0.0056651   -43.776  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5015463  0.0072444  -207.271  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -0.9551144  0.0057981  -164.729  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.4846634  0.0074621   -64.950  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -1.9753440  0.0118295  -166.984  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.3455063  0.0086909  -154.817  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.3556620  0.0061296   -58.024  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -1.3213501  0.0085951  -153.733  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.3877006  0.0052409   -73.977  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7064020  0.0062472  -113.075  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -0.8827157  0.0218327   -40.431  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.6067055  0.0115514   -52.522  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.4380259  0.0086774    50.479  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4902124  0.0089922    54.515  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.4336278  0.0093410   153.477  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  0.9223573  0.0209024    44.127  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  1.1559309  0.0051787   223.208  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -1.2664455  0.0126131  -100.407  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -2.7360882  0.0325753   -83.993  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  0.8193492  0.0037301   219.657  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -0.7852474  0.0058655  -133.875  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.5742422  0.0041884   137.104  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.8391525  0.0065075  -128.951  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.3510692  0.0057253   -61.319  &lt; 2e-16 ***\nDESTIN_SZWDSZ06  0.1358804  0.0043968    30.905  &lt; 2e-16 ***\nDESTIN_SZWDSZ07 -0.2207379  0.0066369   -33.259  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.0264655  0.0065065    -4.068 4.75e-05 ***\nDESTIN_SZWDSZ09 -0.2065828  0.0050524   -40.888  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.7467996  0.0040979   182.238  &lt; 2e-16 ***\nDESTIN_SZYSSZ02 -0.3002718  0.0053434   -56.195  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -1.1087686  0.0057219  -193.778  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.3748076  0.0051481   -72.805  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.7909654  0.0102064  -175.475  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.8519179  0.0099601  -185.933  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.9246626  0.0118101   -78.294  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.4403129  0.0041268   106.697  &lt; 2e-16 ***\nDESTIN_SZYSSZ09  0.0267012  0.0041393     6.451 1.11e-10 ***\nlog(dist)       -0.6721961  0.0001353 -4969.566  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 20988409  on 14175  degrees of freedom\nAIC: 21081154\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.5739638\n\n\nNotice that there is a relatively greater improvement in the R^2 value."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#model-comparison",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#model-comparison",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.9 Model comparison",
    "text": "8.9 Model comparison\nAnother useful model performance measure for continuous dependent variable is Root Mean Squared Error. In this sub-section, you will learn how to use compare_performance() of performance package\nFirst of all, let us create a list called model_list by using the code chun below.\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\nNext, we will compute the RMSE of all the models in model_list file by using the code chunk below.\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 4288.012\noriginConstrained      |   glm | 3659.954\ndestinationConstrained |   glm | 3389.556\ndoublyConstrained      |   glm | 3252.297\n\n\nThe print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 3252.297."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#visualising-fitted-values",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.2.html#visualising-fitted-values",
    "title": "Hands-on Exercise 10.2: Calibrating Spatial Interaction Models with R",
    "section": "8.10 Visualising fitted values",
    "text": "8.10 Visualising fitted values\nIn this section, you will learn how to visualise the observed values and the fitted values.\nFirstly we will extract the fitted values from each model by using the code chunk below.\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nNext, we will join the values to SIM_data data frame.\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\nRepeat the same step by for Origin Constrained SIM (i.e. orcSIM)\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = \"orcSIM$fitted.values\")\n\nRepeat the same step by for Destination Constrained SIM (i.e. decSIM)\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = \"decSIM$fitted.values\")\n\nRepeat the same step by for Doubly Constrained SIM (i.e. dbcSIM)\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = \"dbcSIM$fitted.values\")\n\n\nunc_p &lt;- ggplot(data = SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nNow, we will put all the graphs into a single visual for better comparison by using the code chunk below.\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "title": "In-class Ex 10: Working with Open Government Data",
    "section": "",
    "text": "1. Loading the R package\n\npacman::p_load(tmap, sf, DT, stplanr, tidyverse, httr, performance)\n\n\n\n2. Importing data\nThe code chunk below imports multiple csv files in a specified folder and append them into a single tibble data frame.\n\nfolder_path &lt;- \"data/aspatial\"\nfile_list &lt;- list.files(path = folder_path, \n                        pattern = \"^realis.*\\\\.csv$\", \n                        full.names = TRUE)\n\nrealis_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)\n\n\n\n3. Wrangling data\n\nThe TaskThe Code\n\n\nWrite a code chunk to perform the followings: - converting values in Sale Date field from character to numerical date format, and - extracting resale and condominium transaction records.\n\n\n\ncondo_resale &lt;- realis_data %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %&gt;%\n  filter(`Type of Sale` == \"Resale\" &\n           `Property Type` == \"Condominium\")\n\n\n\n\n\n\n4. Geocoding\n\nPreparing dataThe Code\n\n\n\npostcode &lt;- unique(condo_resale$`Postal Code`)\n\n\n\n\nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound &lt;- data.frame()\nnot_found &lt;- data.frame()\n\nfor (postcode in postcode){\n  query &lt;- list('searchVal'=postcode, 'returnGeom'='Y', \n                'getAddrDetails'='Y', 'pageNum'='1')\n  res &lt;- GET(url, query=query)\n  if ((content(res)$found)!=0){\n    found &lt;- rbind(found, data.frame(content(res))[4:13])\n  } else {not_found = data.frame(postcode)\n  }\n}\n\n\n\n\n\n\n5. Tidying field names\n\nfound &lt;- found %&gt;%\n  select(c(6:8)) %&gt;%\n  rename(POSTAL = `results.POSTAL`,\n         XCOORD = `results.X`,\n         YCOORD = `results.Y`)\n\n\n\n6. Converting to Point Feature Data Frame\n\nThe tasksJoining tablesCovering to sf\n\n\n\nWrite a code chunk to join condo_resale and found. Name the output condo_resale_geocoded.\nWrite a code chunk to convert condo_resale_geocoded from tibble data frame to sf point feature data frame.\n\n\n\n\ncondo_resale_geocoded = left_join(\n  condo_resale, found, \n  by = c('Postal Code' = 'POSTAL'))\n\n\n\n\ncondo_resale_sf &lt;- st_as_sf(condo_resale_geocoded, \n                            coords = c(\"XCOORD\",\n                                       \"YCOORD\"),\n                            crs=3414)\n\n\n\n\n\n\n7. Cleaning Spatial Data\n\nChecking for overlapping point featuresSpatial jittering\n\n\nThe code chunk below is used to check if there are overlapping point features.\n\noverlapping_points &lt;- condo_resale_sf %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\n\n\nIn the code code chunk below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  st_jitter(amount = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex10/data/geospatial/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Take Home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "",
    "text": "According to Wikipedia, financial inclusion is the availability and equality of opportunities to access financial services. It refers to processes by which individuals and businesses can access appropriate, affordable, and timely financial products and services - which include banking, loan, equity, and insurance products. It provides paths to enhance inclusiveness in economic growth by enabling the unbanked population to access the means for savings, investment, and insurance towards improving household income and reducing income inequality."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#importing-geospatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#importing-geospatial-data",
    "title": "Take Home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "5.1 Importing geospatial data",
    "text": "5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called geoBoundaries-UGA-ADM2. It is in ESRI shapefile format. The shapefile consists of Uganda district level boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import geoBoundaries-UGA-ADM2 shapefile by using st_read() of sf packages.\n\n# Load district level boundary GIS data\n\nboundaries2 &lt;- st_read(dsn = \"data/rawdata/geoBoundaries-UGA-ADM2-all\", \n                layer = \"geoBoundaries-UGA-ADM2\")\n\nReading layer `geoBoundaries-UGA-ADM2' from data source \n  `C:\\Users\\user\\OneDrive - Singapore Management University\\MITB\\6. Geospatial Analytics and Applications\\jeffleesl\\ISSS626-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\rawdata\\geoBoundaries-UGA-ADM2-all' \n  using driver `ESRI Shapefile'\nSimple feature collection with 151 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29.56838 ymin: -1.4732 xmax: 35.02676 ymax: 4.228399\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#updating-crs-information",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#updating-crs-information",
    "title": "Take Home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "5.1.1 Updating CRS Information",
    "text": "5.1.1 Updating CRS Information\nUganda is located in southeast Africa between 1º S and 4º N latitude, and between 30º E and 35º E longitude.\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 32736).\n\n# Transform to the correct ESPG Code\n\nboundaries &lt;- st_transform(boundaries2, 32736)\n\n\n# Verify the newly transformed boundaries\n\nst_crs(boundaries)\n\nCoordinate Reference System:\n  User input: EPSG:32736 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 36S\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 36S\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",33,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",10000000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 30°E and 36°E, southern hemisphere between 80°S and equator, onshore and offshore. Burundi. Eswatini (Swaziland). Kenya. Malawi. Mozambique. Rwanda. South Africa. Tanzania. Uganda. Zambia. Zimbabwe.\"],\n        BBOX[-80,30,0,36]],\n    ID[\"EPSG\",32736]]\n\n\n\nst_bbox(boundaries) #view extent\n\n      xmin       ymin       xmax       ymax \n  117997.3  9836930.8   725449.1 10467443.7 \n\n\n\ntm_shape(boundaries) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n## Convert to multipolygon to individual polygon\nboundaries_sf &lt;- boundaries %&gt;% \n  st_cast(\"POLYGON\") %&gt;% \n  mutate(area = st_area(.))\n\nWarning in st_cast.sf(., \"POLYGON\"): repeating attributes for all\nsub-geometries for which they may not be constant\n\n\n\n## Group by the unique name and select the largest polygon by area\nboundaries_cleaned &lt;- boundaries_sf %&gt;% \n  group_by(shapeName) %&gt;% \n  filter(area == max(area)) %&gt;% \n  ungroup() %&gt;% \n  select(-area) %&gt;% \n  select(shapeName) %&gt;% \n  rename(\n  county_name = shapeName \n  )\n\n\ntm_shape(boundaries_cleaned) +\n  tm_polygons()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#importing-the-aspatial-data-finscope-uganda",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#importing-the-aspatial-data-finscope-uganda",
    "title": "Take Home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "5.2 Importing the aspatial data, FinScope Uganda",
    "text": "5.2 Importing the aspatial data, FinScope Uganda\nThe FinScope-2023_Dataset_Final is in csv file format. The codes chunk below uses read_csv() function of readr package to import FinScope-2023_Dataset_Final into R as a tibble data frame called uganda_data.\n\nuganda_data &lt;- read_csv(\"data/rawdata/FinScope-2023_Dataset_Final.csv\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 3176 Columns: 686\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (25): HH_ID, Interview_ID, ea_name, District, Region, Subregion, Rural_...\ndbl (638): ea_code, age, disabled, Pweight, Lhhid, Enum_code, InterviewDate,...\nlgl  (23): f3_2_14, f3_2_15, f3_3_14, f3_3_15, f3_5_14, f3_5_15, g12_2_1, g1...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n5.2.1 Variables to Consider for Financial Inclusion\n\ncolnames(uganda_data) # Displays all column names in the dataset\n\nTo determine factors affecting financial inclusion, consider including the following types of variables:\n\nDemographic VariablesEconomic VariablesGeographic VariablesAccess VariablesFinancial Services VariablesOther\n\n\n• Age and Age Band • Gender • Education Level • Mobile User\n\n\n• Income Level • Employment Status\n\n\n• Urban vs. rural status\n\n\n• Distance to nearest bank or financial institution from Home (Commerical Nank, SACCO and Mobile Money)\n\n\n• Financail Advice • Save Money and the channel (Commerical Nank, SACCO and Mobile Money) • Last amount saved • Borrow Money and the channel (Commerical Nank, SACCO and Mobile Money) • Last amount borrowed • Last amount sent • Last amount received\n\n\n• Documentation for KYC (National Identification Card, Passport, Utilities and Pay Slip) • Self Sustaining\n\n\n\n\nuganda_data_new &lt;- uganda_data %&gt;%\n  select(-c(2:4, 6:7, 9, 11:17, 20, 23:28, 30:34, 36:37, 40:43, 45:63, 65, 67:90, 93:94, 96, 98:167, 169:230, 232:234, 236:238, 240:241, 243:342, 344:364, 366:384, 386:438, 440:444, 446, 448:674, 677:679, 681:686)) %&gt;% \n  rename(\n    age_band = c1,\n    gender = c2,\n    education_level = c4,\n    employment_status = c5,\n    mobile_user = c7_1_1,\n    national_ic_doc = c8_1a,\n    passport_doc = c8_1d,\n    utilities_bill_doc = c8_1e,\n    pay_slip_doc = c8_1j,\n    self_sustaining = e1_1,\n    financial_advice = e3_1,\n    save_money = f2_1,\n    save_money_commercial_bank = f3_1_1,\n    save_money_SACCO = f3_1_4,\n    save_money_mobile_money = f3_1_6,\n    last_amt_saved = f6_1,\n    last_amt_borrowed = g3_3,\n    borrow_money_commercial_bank = g6_1_1,\n    borrow_money_SACCO = g6_1_5,\n    borrow_money_mobile_money = g6_1_8,\n    last_amt_sent = hpp3_2,\n    last_amt_received = hpp6_2,\n    own_insurance = j1,\n    distance_commerical_bank = k1_1_1,\n    distance_SACCOS = k1_1_7,\n    distance_mobile_money = k1_1_9,\n    latitude = hh_gps_latitude,\n    longitude = hh_gps_longitude,\n    county_name = s1aq2b\n  )\n\n\nhead(uganda_data_new$longitude) #see the data in XCOORD column\n\n[1] 33.65414 33.65328 33.65403 33.65586 33.65472 33.65549\n\n\n\nhead(uganda_data_new$latitude) #see the data in YCOORD column\n\n[1] 2.677662 2.675690 2.673339 2.671343 2.671923 2.672423\n\n\nNext, summary() of base R is used to display the summary statistics of uganda_data tibble data frame.\n\nsummary(uganda_data_new)\n\n    HH_ID                age            Region          Rural_Urban       \n Length:3176        Min.   : 16.00   Length:3176        Length:3176       \n Class :character   1st Qu.: 25.00   Class :character   Class :character  \n Mode  :character   Median : 34.00   Mode  :character   Mode  :character  \n                    Mean   : 37.86                                        \n                    3rd Qu.: 48.00                                        \n                    Max.   :100.00                                        \n                                                                          \n    age_band         gender      education_level employment_status\n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : 1.00    \n 1st Qu.:3.000   1st Qu.:1.000   1st Qu.:2.000   1st Qu.: 1.00    \n Median :4.000   Median :2.000   Median :3.000   Median : 2.00    \n Mean   :3.986   Mean   :1.552   Mean   :3.169   Mean   : 3.67    \n 3rd Qu.:5.000   3rd Qu.:2.000   3rd Qu.:4.000   3rd Qu.: 5.00    \n Max.   :7.000   Max.   :2.000   Max.   :9.000   Max.   :99.00    \n                                                                  \n  mobile_user    national_ic_doc  passport_doc  utilities_bill_doc\n Min.   :1.000   Min.   :1.000   Min.   :1.00   Min.   :1.000     \n 1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2.00   1st Qu.:2.000     \n Median :1.000   Median :1.000   Median :2.00   Median :2.000     \n Mean   :1.273   Mean   :1.171   Mean   :1.96   Mean   :1.926     \n 3rd Qu.:2.000   3rd Qu.:1.000   3rd Qu.:2.00   3rd Qu.:2.000     \n Max.   :2.000   Max.   :2.000   Max.   :2.00   Max.   :2.000     \n                                                                  \n  pay_slip_doc   self_sustaining financial_advice   save_money  \n Min.   :1.000   Min.   :1.000   Min.   :1.000    Min.   :1.00  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:1.000    1st Qu.:1.00  \n Median :2.000   Median :2.000   Median :1.000    Median :1.00  \n Mean   :1.964   Mean   :1.846   Mean   :1.401    Mean   :1.36  \n 3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:2.000    3rd Qu.:2.00  \n Max.   :2.000   Max.   :2.000   Max.   :2.000    Max.   :2.00  \n                                                                \n save_money_commercial_bank save_money_SACCO save_money_mobile_money\n Min.   :1.000              Min.   :1.000    Min.   :1.000          \n 1st Qu.:2.000              1st Qu.:2.000    1st Qu.:1.000          \n Median :2.000              Median :2.000    Median :2.000          \n Mean   :1.837              Mean   :1.842    Mean   :1.591          \n 3rd Qu.:2.000              3rd Qu.:2.000    3rd Qu.:2.000          \n Max.   :2.000              Max.   :2.000    Max.   :2.000          \n NA's   :1143               NA's   :1143     NA's   :1143           \n last_amt_saved  last_amt_borrowed borrow_money_commercial_bank\n Min.   :1.000   Min.   :  1.00    Min.   :1.000               \n 1st Qu.:1.000   1st Qu.:  1.00    1st Qu.:2.000               \n Median :1.000   Median :  2.00    Median :2.000               \n Mean   :2.198   Mean   : 88.72    Mean   :1.899               \n 3rd Qu.:3.000   3rd Qu.:  3.00    3rd Qu.:2.000               \n Max.   :9.000   Max.   :998.00    Max.   :2.000               \n NA's   :1143    NA's   :1877      NA's   :2629                \n borrow_money_SACCO borrow_money_mobile_money last_amt_sent   \n Min.   :1.00       Min.   :1.000             Min.   :  1.00  \n 1st Qu.:2.00       1st Qu.:2.000             1st Qu.:  1.00  \n Median :2.00       Median :2.000             Median :  1.00  \n Mean   :1.87       Mean   :1.832             Mean   : 65.63  \n 3rd Qu.:2.00       3rd Qu.:2.000             3rd Qu.:  2.00  \n Max.   :2.00       Max.   :2.000             Max.   :998.00  \n NA's   :2629       NA's   :2629              NA's   :1762    \n last_amt_received own_insurance   distance_commerical_bank distance_SACCOS\n Min.   :  1.00    Min.   :1.000   Min.   :1.000            Min.   :1.000  \n 1st Qu.:  1.00    1st Qu.:2.000   1st Qu.:2.000            1st Qu.:2.000  \n Median :  1.00    Median :2.000   Median :4.000            Median :2.000  \n Mean   : 80.83    Mean   :1.974   Mean   :3.176            Mean   :2.508  \n 3rd Qu.:  3.00    3rd Qu.:2.000   3rd Qu.:4.000            3rd Qu.:4.000  \n Max.   :998.00    Max.   :2.000   Max.   :4.000            Max.   :4.000  \n NA's   :1489                                                              \n distance_mobile_money    latitude         longitude     county_name       \n Min.   :1.000         Min.   :-1.4128   Min.   : 0.00   Length:3176       \n 1st Qu.:1.000         1st Qu.: 0.2393   1st Qu.:30.99   Class :character  \n Median :1.000         Median : 0.7726   Median :32.54   Mode  :character  \n Mean   :1.655         Mean   : 0.9945   Mean   :31.53                     \n 3rd Qu.:2.000         3rd Qu.: 1.9143   3rd Qu.:33.52                     \n Max.   :4.000         Max.   : 3.6876   Max.   :34.96"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#converting-aspatial-data-frame-into-a-sf-object",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#converting-aspatial-data-frame-into-a-sf-object",
    "title": "Take Home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "5.3 Converting aspatial data frame into a sf object",
    "text": "5.3 Converting aspatial data frame into a sf object\nCurrently, the uganda_data tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts uganda_data data frame into a simple feature data frame by using st_as_sf() of sf packages."
  }
]